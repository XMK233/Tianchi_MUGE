{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f06e2f11-82f1-48a7-b096-7dc082babe33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:12<00:00,  6.40s/it]\n"
     ]
    }
   ],
   "source": [
    "!python ../plan_4/0-vlm_t2i_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e559dc81-79b0-402a-b7ed-ca34acb835c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaf9e1b-773d-46fa-95bf-d82a23bdd9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce0aa28e-da8d-45bf-8d6f-a736f985c203",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "已放开 BERT 的最后1层 encoder 和 pooler 进行训练\n",
      "已加载 text_encoder 参数\n",
      "已加载模型，历史已训练 epoch 数: 3\n",
      "上一轮 (2) Loss: 0.128941\n",
      "已检测到现有模型，加载并续训: /mnt/d/forCoding_data/Tianchi_MUGE/plan_3/trained_models/5_贲-基于4_去掉标签_model.pth\n",
      "30it [00:01, 21.50it/s]\n",
      "30it [00:00, 38.06it/s]\n",
      "30it [00:00, 38.91it/s]\n",
      "30it [00:00, 38.53it/s]\n",
      "30it [00:00, 39.31it/s]\n",
      "30it [00:00, 37.98it/s]\n",
      "30it [00:00, 39.40it/s]\n",
      "30it [00:00, 38.04it/s]\n",
      "30it [00:00, 36.54it/s]\n",
      "30it [00:00, 38.75it/s]\n",
      "30it [00:00, 39.46it/s]\n",
      "30it [00:00, 38.84it/s]\n",
      "30it [00:00, 38.97it/s]\n",
      "30it [00:00, 38.31it/s]\n",
      "30it [00:00, 36.03it/s]\n",
      "30it [00:00, 33.14it/s]\n",
      "30it [00:00, 31.34it/s]\n",
      "30it [00:01, 29.19it/s]\n",
      "30it [00:01, 29.07it/s]\n",
      "30it [00:00, 33.48it/s]\n",
      "30it [00:00, 33.85it/s]\n",
      "30it [00:00, 35.71it/s]\n",
      "30it [00:00, 33.70it/s]\n",
      "30it [00:00, 33.93it/s]\n",
      "30it [00:00, 34.09it/s]\n",
      "30it [00:00, 33.30it/s]\n",
      "30it [00:00, 34.73it/s]\n",
      "30it [00:00, 35.28it/s]\n",
      "30it [00:00, 34.98it/s]\n",
      "30it [00:00, 558.15it/s]\n",
      "30it [00:00, 37.89it/s]\n",
      "30it [00:01, 19.54it/s]\n",
      "30it [00:00, 34.46it/s]\n",
      "30it [00:00, 33.93it/s]\n",
      "30it [00:00, 35.59it/s]\n",
      "30it [00:00, 35.50it/s]\n",
      "30it [00:00, 35.13it/s]\n",
      "30it [00:00, 32.97it/s]\n",
      "30it [00:00, 34.52it/s]\n",
      "30it [00:00, 38.20it/s]\n",
      "30it [00:00, 33.76it/s]\n",
      "30it [00:00, 35.70it/s]\n",
      "30it [00:00, 35.77it/s]\n",
      "30it [00:00, 37.81it/s]\n",
      "30it [00:00, 36.86it/s]\n",
      "30it [00:00, 36.90it/s]\n",
      "30it [00:00, 37.46it/s]\n",
      "30it [00:00, 36.05it/s]\n",
      "30it [00:00, 37.17it/s]\n",
      "30it [00:00, 37.60it/s]\n",
      "30it [00:00, 37.52it/s]\n",
      "30it [00:00, 36.80it/s]\n",
      "30it [00:00, 36.70it/s]\n",
      "30it [00:00, 35.57it/s]\n",
      "30it [00:00, 36.31it/s]\n",
      "30it [00:00, 37.15it/s]\n",
      "30it [00:00, 37.50it/s]\n",
      "30it [00:00, 36.56it/s]\n",
      "30it [00:00, 35.38it/s]\n",
      "30it [00:00, 35.69it/s]\n",
      "30it [00:00, 35.67it/s]\n",
      "30it [00:00, 36.53it/s]\n",
      "30it [00:00, 36.83it/s]\n",
      "30it [00:00, 36.64it/s]\n",
      "30it [00:00, 37.77it/s]\n",
      "30it [00:00, 37.58it/s]\n",
      "30it [00:00, -1933.84it/s]\n",
      "30it [00:00, 36.55it/s]\n",
      "30it [00:00, 35.89it/s]\n",
      "30it [00:00, 36.66it/s]\n",
      "30it [00:00, 36.36it/s]\n",
      "30it [00:00, 38.23it/s]\n",
      "30it [00:00, 38.10it/s]\n",
      "30it [00:00, 35.48it/s]\n",
      "30it [00:00, 36.94it/s]\n",
      "30it [00:00, 36.19it/s]\n",
      "30it [00:00, 35.70it/s]\n",
      "30it [00:00, 35.76it/s]\n",
      "30it [00:00, 35.05it/s]\n",
      "30it [00:00, 36.88it/s]\n",
      "30it [00:00, 37.28it/s]\n",
      "30it [00:00, 36.69it/s]\n",
      "30it [00:00, 36.21it/s]\n",
      "30it [00:00, 35.75it/s]\n",
      "30it [00:00, 36.57it/s]\n",
      "30it [00:00, 36.28it/s]\n",
      "30it [00:00, 34.52it/s]\n",
      "30it [00:00, 36.11it/s]\n",
      "30it [00:00, 36.62it/s]\n",
      "30it [00:00, 35.57it/s]\n",
      "30it [00:00, 36.95it/s]\n",
      "30it [00:00, 37.07it/s]\n",
      "30it [00:00, 36.72it/s]\n",
      "30it [00:00, 35.58it/s]\n",
      "30it [00:00, 34.55it/s]\n",
      "30it [00:00, 34.56it/s]\n",
      "30it [00:00, 35.24it/s]\n",
      "30it [00:00, 35.54it/s]\n",
      "30it [00:00, 37.20it/s]\n",
      "30it [00:00, 34.67it/s]\n",
      "30it [00:00, 35.25it/s]\n",
      "30it [00:00, 36.36it/s]\n",
      "30it [00:00, 35.49it/s]\n",
      "30it [00:00, 2540.62it/s]\n",
      "30it [00:00, 36.87it/s]\n",
      "30it [00:00, 36.84it/s]\n",
      "30it [00:00, 36.70it/s]\n",
      "30it [00:00, 35.50it/s]\n",
      "30it [00:00, 36.89it/s]\n",
      "30it [00:00, 34.99it/s]\n",
      "30it [00:00, 35.48it/s]\n",
      "30it [00:00, 36.05it/s]\n",
      "30it [00:00, 36.18it/s]\n",
      "30it [00:00, 35.49it/s]\n",
      "30it [00:00, 36.31it/s]\n",
      "30it [00:00, 35.89it/s]\n",
      "30it [00:00, 35.75it/s]\n",
      "30it [00:00, 37.22it/s]\n",
      "30it [00:00, 37.67it/s]\n",
      "30it [00:00, 36.07it/s]\n",
      "30it [00:00, 37.34it/s]\n",
      "30it [00:00, 36.74it/s]\n",
      "30it [00:00, 36.25it/s]\n",
      "30it [00:00, 36.34it/s]\n",
      "30it [00:00, 38.00it/s]\n",
      "30it [00:00, 37.43it/s]\n",
      "30it [00:00, 37.20it/s]\n",
      "30it [00:00, 35.20it/s]\n",
      "30it [00:00, 36.73it/s]\n",
      "30it [00:00, 36.64it/s]\n",
      "30it [00:00, 36.68it/s]\n",
      "30it [00:00, 36.90it/s]\n",
      "30it [00:00, 36.20it/s]\n",
      "30it [00:00, 37.21it/s]\n",
      "30it [00:00, 37.12it/s]\n",
      "30it [00:00, 37.58it/s]\n",
      "30it [00:00, 37.25it/s]\n",
      "30it [00:00, 39.27it/s]\n",
      "30it [00:00, 38.15it/s]\n",
      "30it [00:00, 37.95it/s]\n",
      "30it [00:00, 37.72it/s]\n",
      "30it [00:00, -2961.03it/s]\n",
      "30it [00:00, 37.80it/s]\n",
      "30it [00:00, 38.65it/s]\n",
      "30it [00:00, 36.91it/s]\n",
      "30it [00:00, 38.21it/s]\n",
      "30it [00:00, 37.97it/s]\n",
      "30it [00:00, 37.70it/s]\n",
      "30it [00:00, 37.52it/s]\n",
      "30it [00:00, 37.85it/s]\n",
      "30it [00:00, 37.74it/s]\n",
      "30it [00:00, 36.51it/s]\n",
      "30it [00:00, 37.48it/s]\n",
      "30it [00:00, 36.63it/s]\n",
      "30it [00:00, 38.06it/s]\n",
      "30it [00:00, 37.84it/s]\n",
      "30it [00:00, 36.68it/s]\n",
      "30it [00:00, 38.11it/s]\n",
      "30it [00:00, 37.11it/s]\n",
      "30it [00:00, 37.54it/s]\n",
      "30it [00:00, 37.35it/s]\n",
      "30it [00:00, 38.05it/s]\n",
      "30it [00:00, 35.38it/s]\n",
      "30it [00:00, 36.88it/s]\n",
      "30it [00:00, 36.38it/s]\n",
      "30it [00:00, 37.44it/s]\n",
      "30it [00:00, 37.87it/s]\n",
      "30it [00:00, 37.26it/s]\n",
      "30it [00:00, 37.64it/s]\n",
      "30it [00:00, 37.50it/s]\n",
      "30it [00:00, 37.69it/s]\n",
      "30it [00:00, 37.56it/s]\n",
      "30it [00:00, 36.55it/s]\n",
      "30it [00:00, 36.27it/s]\n",
      "30it [00:00, 35.78it/s]\n",
      "30it [00:00, 37.17it/s]\n",
      "30it [00:00, 37.34it/s]\n",
      "30it [00:00, 37.51it/s]\n",
      "30it [00:00, 37.02it/s]\n",
      "30it [00:00, 37.24it/s]\n",
      "30it [00:00, 679.05it/s]\n",
      "30it [00:00, 36.44it/s]\n",
      "30it [00:00, 36.05it/s]\n",
      "30it [00:00, 38.61it/s]\n",
      "30it [00:00, 36.76it/s]\n",
      "30it [00:00, 37.27it/s]\n",
      "30it [00:00, 36.13it/s]\n",
      "30it [00:00, 36.29it/s]\n",
      "30it [00:00, 36.69it/s]\n",
      "30it [00:00, 36.48it/s]\n",
      "30it [00:00, 35.31it/s]\n",
      "30it [00:00, 35.78it/s]\n",
      "30it [00:00, 36.59it/s]\n",
      "30it [00:00, 37.23it/s]\n",
      "30it [00:00, 36.52it/s]\n",
      "30it [00:00, 37.73it/s]\n",
      "30it [00:00, 39.03it/s]\n",
      "30it [00:00, 38.42it/s]\n",
      "30it [00:00, 37.19it/s]\n",
      "30it [00:00, 37.95it/s]\n",
      "Inception v3模型加载成功\n",
      "\n",
      "=== 计算FID分数 ===\n",
      "FID分数: 24.7027\n"
     ]
    }
   ],
   "source": [
    "!python 5_贲-基于4_去掉标签.py --n_epochs 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c487283-5125-4c23-bd5c-9211ae9b1528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aebec7f-6d12-48cf-9745-d2738191749e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "已放开 BERT 的最后1层 encoder 和 pooler 进行训练\n",
      "已加载 text_encoder 参数\n",
      "已加载模型，历史已训练 epoch 数: 250\n",
      "上一轮 (249) Loss: 0.050299\n",
      "已检测到现有模型，加载并续训: /mnt/d/forCoding_data/Tianchi_MUGE/plan_3/trained_models/4_噬嗑-基于3_加入fid模块_model.pth\n",
      "30it [00:01, 23.96it/s]\n",
      "30it [00:00, 30.73it/s]\n",
      "30it [00:00, 31.34it/s]\n",
      "30it [00:00, 30.66it/s]\n",
      "30it [00:00, 31.97it/s]\n",
      "30it [00:00, 32.25it/s]\n",
      "30it [00:00, 37.32it/s]\n",
      "30it [00:00, 41.64it/s]\n",
      "30it [00:00, 41.15it/s]\n",
      "30it [00:00, 41.19it/s]\n",
      "30it [00:00, 42.47it/s]\n",
      "30it [00:00, 41.31it/s]\n",
      "30it [00:00, 41.36it/s]\n",
      "30it [00:00, 41.54it/s]\n",
      "30it [00:00, 41.52it/s]\n",
      "30it [00:00, 41.90it/s]\n",
      "30it [00:00, 42.10it/s]\n",
      "30it [00:00, 41.80it/s]\n",
      "30it [00:00, 42.32it/s]\n",
      "30it [00:00, 41.99it/s]\n",
      "30it [00:00, 41.43it/s]\n",
      "30it [00:00, 42.18it/s]\n",
      "30it [00:00, 42.14it/s]\n",
      "30it [00:00, 42.66it/s]\n",
      "30it [00:00, 41.56it/s]\n",
      "30it [00:00, 39.89it/s]\n",
      "30it [00:00, 41.43it/s]\n",
      "30it [00:00, 41.40it/s]\n",
      "30it [00:00, 41.55it/s]\n",
      "30it [00:00, 41.84it/s]\n",
      "30it [00:00, 41.84it/s]\n",
      "30it [00:00, 41.93it/s]\n",
      "30it [00:00, 41.91it/s]\n",
      "30it [00:00, 41.79it/s]\n",
      "30it [00:00, 42.05it/s]\n",
      "30it [00:00, 40.61it/s]\n",
      "30it [00:00, 42.36it/s]\n",
      "30it [00:00, 41.99it/s]\n",
      "30it [00:00, 42.56it/s]\n",
      "30it [00:00, 42.10it/s]\n",
      "30it [00:00, 41.19it/s]\n",
      "30it [00:00, 41.75it/s]\n",
      "30it [00:00, 41.96it/s]\n",
      "30it [00:00, 42.00it/s]\n",
      "30it [00:00, 41.10it/s]\n",
      "30it [00:00, 41.76it/s]\n",
      "30it [00:00, 41.61it/s]\n",
      "30it [00:00, 41.10it/s]\n",
      "30it [00:00, 41.38it/s]\n",
      "30it [00:00, 41.21it/s]\n",
      "30it [00:00, 40.34it/s]\n",
      "30it [00:00, 41.02it/s]\n",
      "30it [00:00, 41.21it/s]\n",
      "30it [00:00, 41.14it/s]\n",
      "30it [00:00, 40.79it/s]\n",
      "30it [00:00, 41.29it/s]\n",
      "30it [00:00, 40.12it/s]\n",
      "30it [00:00, 40.59it/s]\n",
      "30it [00:00, 40.73it/s]\n",
      "30it [00:00, 40.71it/s]\n",
      "30it [00:00, 40.65it/s]\n",
      "30it [00:00, 40.05it/s]\n",
      "30it [00:00, 40.43it/s]\n",
      "30it [00:00, 40.25it/s]\n",
      "30it [00:00, 41.44it/s]\n",
      "30it [00:00, 41.23it/s]\n",
      "30it [00:00, 41.98it/s]\n",
      "30it [00:00, 42.69it/s]\n",
      "30it [00:00, 42.43it/s]\n",
      "30it [00:00, 40.84it/s]\n",
      "30it [00:00, 42.10it/s]\n",
      "30it [00:00, 42.87it/s]\n",
      "30it [00:00, 41.52it/s]\n",
      "30it [00:00, 41.34it/s]\n",
      "30it [00:00, 42.27it/s]\n",
      "30it [00:00, 41.82it/s]\n",
      "30it [00:00, 42.13it/s]\n",
      "30it [00:00, 41.85it/s]\n",
      "30it [00:00, 41.18it/s]\n",
      "30it [00:00, 41.73it/s]\n",
      "30it [00:00, 40.92it/s]\n",
      "30it [00:00, 40.94it/s]\n",
      "30it [00:00, 41.82it/s]\n",
      "30it [00:00, 41.29it/s]\n",
      "30it [00:00, 41.37it/s]\n",
      "30it [00:00, 40.54it/s]\n",
      "30it [00:00, 39.89it/s]\n",
      "30it [00:00, 39.46it/s]\n",
      "30it [00:00, 40.18it/s]\n",
      "30it [00:00, 40.77it/s]\n",
      "30it [00:00, 40.89it/s]\n",
      "30it [00:00, 40.05it/s]\n",
      "30it [00:00, 40.11it/s]\n",
      "30it [00:00, 38.76it/s]\n",
      "30it [00:00, 39.26it/s]\n",
      "30it [00:00, 41.25it/s]\n",
      "30it [00:00, 40.70it/s]\n",
      "30it [00:00, 41.12it/s]\n",
      "30it [00:00, 40.62it/s]\n",
      "30it [00:00, 40.81it/s]\n",
      "30it [00:00, 39.58it/s]\n",
      "30it [00:00, 40.92it/s]\n",
      "30it [00:00, 40.44it/s]\n",
      "30it [00:00, 40.22it/s]\n",
      "30it [00:00, 41.28it/s]\n",
      "30it [00:00, 39.68it/s]\n",
      "30it [00:00, 39.69it/s]\n",
      "30it [00:00, 41.53it/s]\n",
      "30it [00:00, 41.38it/s]\n",
      "30it [00:00, 42.10it/s]\n",
      "30it [00:00, 41.10it/s]\n",
      "30it [00:00, 41.56it/s]\n",
      "30it [00:00, 41.76it/s]\n",
      "30it [00:00, 42.41it/s]\n",
      "30it [00:00, 42.36it/s]\n",
      "30it [00:00, 40.83it/s]\n",
      "30it [00:00, 40.11it/s]\n",
      "30it [00:00, 39.42it/s]\n",
      "30it [00:00, 40.82it/s]\n",
      "30it [00:00, 41.64it/s]\n",
      "30it [00:00, 41.03it/s]\n",
      "30it [00:00, 41.17it/s]\n",
      "30it [00:00, 40.95it/s]\n",
      "30it [00:00, 40.99it/s]\n",
      "30it [00:00, 41.61it/s]\n",
      "30it [00:00, 42.12it/s]\n",
      "30it [00:00, 40.96it/s]\n",
      "30it [00:00, 41.73it/s]\n",
      "30it [00:00, 41.04it/s]\n",
      "30it [00:00, 40.85it/s]\n",
      "30it [00:00, 41.47it/s]\n",
      "30it [00:00, 42.08it/s]\n",
      "30it [00:00, 42.11it/s]\n",
      "30it [00:00, 41.96it/s]\n",
      "30it [00:00, 40.69it/s]\n",
      "30it [00:00, 42.02it/s]\n",
      "30it [00:00, 40.83it/s]\n",
      "30it [00:00, 40.25it/s]\n",
      "30it [00:00, 40.91it/s]\n",
      "30it [00:00, 41.32it/s]\n",
      "30it [00:00, 41.52it/s]\n",
      "30it [00:00, 41.43it/s]\n",
      "30it [00:00, 40.58it/s]\n",
      "30it [00:00, 40.21it/s]\n",
      "30it [00:00, 40.18it/s]\n",
      "30it [00:00, 40.97it/s]\n",
      "30it [00:00, 40.49it/s]\n",
      "30it [00:00, 41.38it/s]\n",
      "30it [00:00, 40.51it/s]\n",
      "30it [00:00, 40.81it/s]\n",
      "30it [00:00, 39.25it/s]\n",
      "30it [00:00, 40.22it/s]\n",
      "30it [00:00, 41.39it/s]\n",
      "30it [00:00, 40.76it/s]\n",
      "30it [00:00, 39.88it/s]\n",
      "30it [00:00, 40.46it/s]\n",
      "30it [00:00, 40.53it/s]\n",
      "30it [00:00, 40.32it/s]\n",
      "30it [00:00, 40.65it/s]\n",
      "30it [00:00, 40.25it/s]\n",
      "30it [00:00, 40.67it/s]\n",
      "30it [00:00, 40.52it/s]\n",
      "30it [00:00, 42.32it/s]\n",
      "30it [00:00, 41.10it/s]\n",
      "30it [00:00, 41.31it/s]\n",
      "30it [00:00, 42.02it/s]\n",
      "30it [00:00, 41.99it/s]\n",
      "30it [00:00, 41.82it/s]\n",
      "30it [00:00, 42.01it/s]\n",
      "30it [00:00, 41.04it/s]\n",
      "30it [00:00, 41.77it/s]\n",
      "30it [00:00, 42.10it/s]\n",
      "30it [00:00, 41.72it/s]\n",
      "30it [00:00, 40.68it/s]\n",
      "30it [00:00, 40.62it/s]\n",
      "30it [00:00, 39.40it/s]\n",
      "30it [00:00, 40.29it/s]\n",
      "30it [00:00, 40.08it/s]\n",
      "30it [00:00, 39.75it/s]\n",
      "30it [00:00, 40.78it/s]\n",
      "30it [00:00, 40.88it/s]\n",
      "30it [00:00, 40.39it/s]\n",
      "30it [00:00, 39.74it/s]\n",
      "30it [00:00, 40.47it/s]\n",
      "30it [00:00, 41.56it/s]\n",
      "30it [00:00, 40.69it/s]\n",
      "30it [00:00, 38.95it/s]\n",
      "30it [00:00, 38.29it/s]\n",
      "30it [00:00, 40.13it/s]\n",
      "30it [00:00, 40.90it/s]\n",
      "30it [00:00, 40.17it/s]\n",
      "30it [00:00, 39.87it/s]\n",
      "30it [00:00, 39.77it/s]\n",
      "30it [00:00, 39.88it/s]\n",
      "30it [00:00, 40.95it/s]\n",
      "30it [00:00, 40.97it/s]\n",
      "30it [00:00, 40.80it/s]\n",
      "30it [00:00, 40.79it/s]\n",
      "30it [00:00, 41.38it/s]\n",
      "30it [00:00, 41.37it/s]\n",
      "Inception v3模型加载成功\n",
      "\n",
      "=== 计算FID分数 ===\n",
      "FID分数: 1.3966\n"
     ]
    }
   ],
   "source": [
    "!python 4_噬嗑-基于3_加入fid模块.py --n_epochs 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fbb3ec-9d9b-4842-adf1-3aa1767c3910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fe8275-336b-4e0d-8129-ff27cd011ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb738e4-aabd-4e5d-82f3-9da08a1c7a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810e7b87-7b67-4545-96e9-89c608224a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e44efef7-bc1e-41d1-8bfc-20b8a7bc772e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "已放开 BERT 的最后1层 encoder 和 pooler 进行训练\n",
      "已加载 text_encoder 参数\n",
      "已加载模型，历史已训练 epoch 数: 245\n",
      "上一轮 (244) Loss: 0.043053\n",
      "已检测到现有模型，加载并续训: /mnt/d/forCoding_data/Tianchi_MUGE/plan_3/trained_models/3_观-基于1_放开部分bert的层来训练_model.pth\n",
      "100%|█████████████████████████████████████████| 835/835 [03:48<00:00,  3.66it/s]\n",
      "Finished epoch 245. Average of the last 100 loss values: 0.039205\n",
      "100%|█████████████████████████████████████████| 835/835 [03:46<00:00,  3.68it/s]\n",
      "Finished epoch 246. Average of the last 100 loss values: 0.044903\n",
      "100%|█████████████████████████████████████████| 835/835 [03:46<00:00,  3.68it/s]\n",
      "Finished epoch 247. Average of the last 100 loss values: 0.042928\n",
      "100%|█████████████████████████████████████████| 835/835 [03:48<00:00,  3.66it/s]\n",
      "Finished epoch 248. Average of the last 100 loss values: 0.049663\n",
      "100%|█████████████████████████████████████████| 835/835 [03:44<00:00,  3.72it/s]\n",
      "Finished epoch 249. Average of the last 100 loss values: 0.050299\n",
      "60it [01:11,  1.19s/it]\n",
      "30it [00:00, 37.97it/s]\n",
      "30it [00:00, 37.41it/s]\n",
      "30it [00:00, 37.24it/s]\n",
      "30it [00:00, 36.10it/s]\n",
      "30it [00:00, 36.72it/s]\n",
      "30it [00:00, 37.66it/s]\n",
      "30it [00:00, 36.90it/s]\n",
      "30it [00:00, 37.04it/s]\n",
      "30it [-1:59:59, -18.43it/s]\n",
      "30it [00:00, 37.51it/s]\n",
      "30it [00:00, 36.69it/s]\n",
      "30it [00:00, 36.81it/s]\n",
      "30it [00:00, 35.97it/s]\n",
      "30it [00:00, 36.46it/s]\n",
      "30it [00:00, 35.77it/s]\n",
      "30it [00:00, 36.95it/s]\n",
      "30it [00:00, 35.93it/s]\n",
      "30it [00:00, 36.82it/s]\n",
      "30it [00:00, 35.32it/s]\n",
      "30it [00:00, 37.51it/s]\n",
      "30it [00:00, 36.36it/s]\n",
      "30it [00:00, 36.05it/s]\n",
      "30it [00:00, 36.04it/s]\n",
      "30it [00:00, 36.36it/s]\n",
      "30it [00:00, 36.51it/s]\n",
      "30it [00:00, 36.21it/s]\n",
      "30it [00:00, 36.78it/s]\n",
      "30it [00:00, 36.08it/s]\n",
      "30it [00:00, 34.95it/s]\n",
      "30it [00:00, 35.71it/s]\n",
      "30it [00:00, 37.17it/s]\n",
      "30it [00:00, 36.60it/s]\n",
      "30it [00:00, 36.10it/s]\n",
      "30it [00:00, 35.71it/s]\n",
      "30it [00:00, 37.55it/s]\n",
      "30it [00:00, 36.01it/s]\n",
      "30it [00:00, 36.16it/s]\n",
      "30it [00:00, 34.69it/s]\n",
      "30it [00:00, 36.40it/s]\n",
      "30it [00:00, 37.35it/s]\n",
      "30it [00:00, 36.83it/s]\n",
      "30it [00:00, 36.20it/s]\n",
      "30it [00:00, 35.79it/s]\n",
      "30it [00:00, 36.47it/s]\n",
      "30it [00:00, 36.79it/s]\n",
      "30it [-1:59:59, -18.12it/s]\n",
      "30it [00:00, 35.39it/s]\n",
      "30it [00:00, 36.97it/s]\n",
      "30it [00:00, 35.95it/s]\n",
      "30it [00:00, 35.59it/s]\n"
     ]
    }
   ],
   "source": [
    "!python 3_观-基于1_放开部分bert的层来训练.py --n_epochs 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a9a356-37d8-449b-830a-7e534b52ffea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13835e8a-3bba-48d0-94ad-7507f0af2275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a60526-d856-4910-b60d-55f325761b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9b8c31-8763-403f-bf30-14e0f7f4dbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188312ee-90d5-4d52-8ff7-70d7fdd84893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b90626-a007-453c-904c-26c40f81bf71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97b2e00-6b28-4e25-bef0-6b3cb4a3a8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecff2b0f-bc3b-4eb6-a934-1c41fe93c3bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "已加载模型，历史已训练 epoch 数: 10\n",
      "上一轮 (9) Loss: 0.086336\n",
      "已检测到现有模型，加载并续训: /mnt/d/forCoding_data/Tianchi_MUGE/plan_3/trained_models/1_蛊-基于0_增加text的embedding_model.pth\n",
      "100%|█████████████████████████████████████████| 835/835 [03:37<00:00,  3.83it/s]\n",
      "Finished epoch 10. Average of the last 100 loss values: 0.080327\n",
      "  9%|███▉                                      | 79/835 [00:19<03:32,  3.56it/s]^C\n",
      " 10%|████                                      | 80/835 [00:20<03:09,  3.99it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_3/1_蛊-基于0_增加text的embedding.py\", line 374, in <module>\n",
      "    pred = net(noisy_x, timesteps, y, text_emb)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_3/1_蛊-基于0_增加text的embedding.py\", line 291, in forward\n",
      "    se = blk(se)\n",
      "         ^^^^^^^\n",
      "  File \"/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_3/1_蛊-基于0_增加text的embedding.py\", line 159, in forward\n",
      "    x = x + self.attn(self.norm1(x), self.norm1(x), self.norm1(x))[0]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 1488, in forward\n",
      "    attn_output, attn_output_weights = F.multi_head_attention_forward(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/nn/functional.py\", line 6307, in multi_head_attention_forward\n",
      "    q, k, v = _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/nn/functional.py\", line 5733, in _in_projection_packed\n",
      "    return linear(q, w_q, b_q), linear(k, w_k, b_k), linear(v, w_v, b_v)\n",
      "                                ^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# !python 1_蛊-基于0_增加text的embedding.py --n_epochs 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc43af0a-ed57-4d90-829f-eee956cb126b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e431bf0-c321-4e11-8bc4-cba3324eb35d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed0baa-b245-47e0-9200-8d6fbc6816ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07e5666-5a96-4bd7-b4f1-6015dfc93d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3b7744a-b1f5-45b6-9302-4f6fa526c82b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "已加载模型，历史已训练 epoch 数: 250\n",
      "上一轮 (249) Loss: 0.041502\n",
      "已检测到现有模型，加载并续训: /mnt/d/forCoding_data/Tianchi_MUGE/plan_3/trained_models/0-baseline_改造为适配本次数据_model.pth\n",
      "100%|█████████████████████████████████████████| 835/835 [01:59<00:00,  6.98it/s]\n",
      "Finished epoch 250. Average of the last 100 loss values: 0.054452\n",
      "100%|█████████████████████████████████████████| 835/835 [01:59<00:00,  7.00it/s]\n",
      "Finished epoch 251. Average of the last 100 loss values: 0.040768\n",
      "100%|█████████████████████████████████████████| 835/835 [02:00<00:00,  6.94it/s]\n",
      "Finished epoch 252. Average of the last 100 loss values: 0.041090\n",
      "100%|█████████████████████████████████████████| 835/835 [02:26<00:00,  5.71it/s]\n",
      "Finished epoch 253. Average of the last 100 loss values: 0.041674\n",
      "100%|█████████████████████████████████████████| 835/835 [01:59<00:00,  7.01it/s]\n",
      "Finished epoch 254. Average of the last 100 loss values: 0.045790\n",
      "60it [00:08,  7.07it/s]\n",
      "100%|█████████████████████████████████████████| 835/835 [02:02<00:00,  6.84it/s]\n",
      "Finished epoch 255. Average of the last 100 loss values: 0.044454\n",
      "100%|█████████████████████████████████████████| 835/835 [02:02<00:00,  6.81it/s]\n",
      "Finished epoch 256. Average of the last 100 loss values: 0.046447\n",
      "100%|█████████████████████████████████████████| 835/835 [02:02<00:00,  6.81it/s]\n",
      "Finished epoch 257. Average of the last 100 loss values: 0.046758\n",
      "100%|█████████████████████████████████████████| 835/835 [02:02<00:00,  6.80it/s]\n",
      "Finished epoch 258. Average of the last 100 loss values: 0.046488\n",
      "100%|█████████████████████████████████████████| 835/835 [02:05<00:00,  6.68it/s]\n",
      "Finished epoch 259. Average of the last 100 loss values: 0.045718\n",
      "60it [00:08,  6.93it/s]\n",
      "100%|█████████████████████████████████████████| 835/835 [01:59<00:00,  6.96it/s]\n",
      "Finished epoch 260. Average of the last 100 loss values: 0.056678\n",
      "100%|█████████████████████████████████████████| 835/835 [02:01<00:00,  6.89it/s]\n",
      "Finished epoch 261. Average of the last 100 loss values: 0.048100\n",
      " 10%|████▏                                     | 83/835 [00:12<01:55,  6.54it/s]^C\n",
      " 10%|████▏                                     | 83/835 [00:12<01:54,  6.59it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_3/0-baseline_改造为适配本次数据.py\", line 359, in <module>\n",
      "    loss.backward()\n",
      "  File \"/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/_tensor.py\", line 625, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/autograd/graph.py\", line 841, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python 0-baseline_改造为适配本次数据.py --n_epochs 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b56f3-9805-4e23-954f-be2b54ed1c5b",
   "metadata": {},
   "source": [
    "改造计划：\n",
    "* ~~能够调用valid数据集的coarse_label做生成。~~\n",
    "* 能够计算fid。\n",
    "* 计算fid的过程中，抽检fid特征，以图直知也。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735a0f39-d2ec-4ac3-b6a0-237e10fedfa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0a8cef-046c-42ff-a48b-1e4dede24af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0d0f7f-3eeb-4299-8684-602d85227f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a1e1f30-4b4d-4095-9756-27a56017df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir /mnt/d/forCoding_data/Tianchi_MUGE/plan_3/trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c16c6e0-e65a-4887-abf8-3f86f99c1366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp 0-baseline_改造为适配本次数据_model.pth /mnt/d/forCoding_data/Tianchi_MUGE/plan_3/trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98766f03-3ee4-4b3a-b892-667f61c6ef99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
