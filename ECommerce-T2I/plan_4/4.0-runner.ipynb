{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5ed63ab-4fef-4ea0-a255-e66a89da96a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf /mnt/d/forCoding_data/Tianchi_MUGE/plan_3/trained_models/4.6_剥-基于5_改为qwen+lora_model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0383975c-d68f-4ad3-9aba-d767ac92d433",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !python 4.6_剥-基于5_改为qwen+lora.py --n_epochs 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbd9f780-4e6e-4261-b0cb-7e6d8eb64d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf /mnt/d/forCoding_data/Tianchi_MUGE/plan_3/trained_models/4.6_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c3f171a-5071-4f96-b811-7b52a3c2833a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-baseline_改造为适配本次数据_model.pth\n",
      "1_蛊-基于0_增加text的embedding_model.pth\n",
      "2_临-基于0_为缩短epoch_潜在扩散模型_model.pth\n",
      "3_观-基于1_放开部分bert的层来训练_model.pth\n",
      "4_噬嗑-基于3_加入fid模块_model.pth\n",
      "5_贲-基于4_去掉标签_model.pth\n",
      "_3_观-基于1_放开部分bert的层来训练_model.pth\n"
     ]
    }
   ],
   "source": [
    "!ls /mnt/d/forCoding_data/Tianchi_MUGE/plan_3/trained_models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878cc586-ce10-45e1-a328-b47e064adaca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10f84536-4d0c-4ade-8cad-b389c7a656e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:12<00:00,  6.17s/it]\n",
      "已开启 text_encoder 梯度检查点 (Gradient Checkpointing)\n",
      "使用 Qwen 文本编码器并应用 LoRA，隐藏维度为 2048\n",
      "已加载 text_encoder 参数\n",
      "已加载 scaler 状态\n",
      "断点位置 epoch=1, step=3336, loss=0.703673\n",
      "已检测到现有模型，加载并续训: /mnt/d/forCoding_data/Tianchi_MUGE/plan_4/trained_models/4.7_复-基于6_混合精度尝试_model.pth\n",
      " 98%|████████████████████████████████████ | 3256/3337 [00:03<00:00, 1200.02it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "100%|██████████████████████████████████████| 3337/3337 [00:05<00:00, 603.63it/s]\n",
      "100%|███████████████████████████████████████| 3337/3337 [16:38<00:00,  3.34it/s]\n",
      "Finished epoch 2. Average of the last 100 loss values: 0.195840\n",
      " 84%|████████████████████████████████▋      | 2793/3337 [18:32<03:00,  3.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3337/3337 [40:04<00:00,  1.39it/s]\n",
      "Finished epoch 3. Average of the last 100 loss values: 0.143852\n",
      "100%|███████████████████████████████████████| 3337/3337 [17:01<00:00,  3.27it/s]\n",
      "Finished epoch 4. Average of the last 100 loss values: 0.130850\n",
      "60it [00:18,  3.25it/s]\n",
      "100%|███████████████████████████████████████| 3337/3337 [19:21<00:00,  2.87it/s]\n",
      "Finished epoch 5. Average of the last 100 loss values: 0.087696\n",
      "100%|███████████████████████████████████████| 3337/3337 [18:26<00:00,  3.02it/s]\n",
      "Finished epoch 6. Average of the last 100 loss values: 0.103682\n",
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "30it [00:00, 33.64it/s]\n",
      "30it [00:00, 36.71it/s]\n",
      "30it [00:00, 36.80it/s]\n",
      "30it [00:00, 36.81it/s]\n",
      "30it [00:00, 36.63it/s]\n",
      "30it [00:00, 36.63it/s]\n",
      "30it [00:00, 36.30it/s]\n",
      "30it [00:00, 36.17it/s]\n",
      "30it [00:00, 36.00it/s]\n",
      "30it [00:00, 36.61it/s]\n",
      "30it [00:00, 36.09it/s]\n",
      "30it [00:00, 35.63it/s]\n",
      "30it [00:00, 36.76it/s]\n",
      "30it [00:00, 36.13it/s]\n",
      "30it [00:00, 35.50it/s]\n",
      "30it [00:00, 36.42it/s]\n",
      "30it [00:00, 36.02it/s]\n",
      "30it [00:00, 34.35it/s]\n",
      "30it [00:00, 35.61it/s]\n",
      "30it [00:00, 36.35it/s]\n",
      "30it [00:00, 36.18it/s]\n",
      "30it [00:00, 36.44it/s]\n",
      "30it [00:00, 550.72it/s]\n",
      "30it [00:00, 36.55it/s]\n",
      "30it [00:00, 36.29it/s]\n",
      "30it [00:00, 36.47it/s]\n",
      "30it [00:00, 35.75it/s]\n",
      "30it [00:00, 36.16it/s]\n",
      "30it [00:00, 36.32it/s]\n",
      "30it [00:00, 35.09it/s]\n",
      "30it [00:00, 34.62it/s]\n",
      "30it [00:00, 35.37it/s]\n",
      "30it [00:00, 35.12it/s]\n",
      "30it [00:00, 34.56it/s]\n",
      "30it [00:00, 35.72it/s]\n",
      "30it [00:00, 35.97it/s]\n",
      "30it [00:00, 35.62it/s]\n",
      "30it [00:00, 35.83it/s]\n",
      "30it [00:00, 35.80it/s]\n",
      "30it [00:00, 35.54it/s]\n",
      "30it [00:00, 35.34it/s]\n",
      "30it [00:00, 35.64it/s]\n",
      "30it [00:00, 33.96it/s]\n",
      "30it [00:00, 34.70it/s]\n",
      "30it [00:00, 36.09it/s]\n",
      "30it [00:00, 36.21it/s]\n",
      "30it [00:00, 35.75it/s]\n",
      "30it [00:00, 35.74it/s]\n",
      "30it [00:00, 36.47it/s]\n",
      "30it [00:00, 35.78it/s]\n",
      "30it [00:00, 36.15it/s]\n",
      "30it [00:00, 36.29it/s]\n",
      "30it [00:00, 36.10it/s]\n",
      "30it [00:00, 35.99it/s]\n",
      "30it [00:00, 36.18it/s]\n",
      "30it [00:00, 36.06it/s]\n",
      "30it [00:00, 36.01it/s]\n",
      "30it [00:00, 36.31it/s]\n",
      "30it [00:00, -247.05it/s]\n",
      "30it [00:00, 36.53it/s]\n",
      "30it [00:00, 36.21it/s]\n",
      "30it [00:00, 36.25it/s]\n",
      "30it [00:00, 36.63it/s]\n",
      "30it [00:00, 36.02it/s]\n",
      "30it [00:00, 36.02it/s]\n",
      "30it [00:00, 36.38it/s]\n",
      "30it [00:00, 36.73it/s]\n",
      "30it [00:00, 36.35it/s]\n",
      "30it [00:00, 35.78it/s]\n",
      "30it [00:00, 34.20it/s]\n",
      "30it [00:00, 35.13it/s]\n",
      "30it [00:00, 35.80it/s]\n",
      "30it [00:00, 35.64it/s]\n",
      "30it [00:00, 36.02it/s]\n",
      "30it [00:00, 36.15it/s]\n",
      "30it [00:00, 35.89it/s]\n",
      "30it [00:00, 35.84it/s]\n",
      "30it [00:00, 35.99it/s]\n",
      "30it [00:00, 36.13it/s]\n",
      "30it [00:00, 35.94it/s]\n",
      "30it [00:00, 36.27it/s]\n",
      "30it [00:00, 36.17it/s]\n",
      "30it [00:00, 35.97it/s]\n",
      "30it [00:00, 35.56it/s]\n",
      "30it [00:00, 35.65it/s]\n",
      "30it [00:00, 35.55it/s]\n",
      "30it [00:00, 34.88it/s]\n",
      "30it [00:00, 35.25it/s]\n",
      "30it [00:00, 36.08it/s]\n",
      "30it [00:00, 36.07it/s]\n",
      "30it [00:00, 35.97it/s]\n",
      "30it [00:00, 36.24it/s]\n",
      "30it [00:00, 36.23it/s]\n",
      "30it [00:00, 35.98it/s]\n",
      "30it [00:00, 4167.77it/s]\n",
      "30it [00:00, 36.07it/s]\n",
      "30it [00:00, 36.46it/s]\n",
      "30it [00:00, 35.90it/s]\n",
      "30it [00:00, 35.71it/s]\n",
      "30it [00:00, 35.67it/s]\n",
      "30it [00:00, 36.00it/s]\n",
      "30it [00:00, 36.41it/s]\n",
      "30it [00:00, 36.54it/s]\n",
      "30it [00:00, 36.64it/s]\n",
      "30it [00:00, 35.50it/s]\n",
      "30it [00:00, 35.74it/s]\n",
      "30it [00:00, 35.33it/s]\n",
      "30it [00:00, 35.72it/s]\n",
      "30it [00:00, 35.56it/s]\n",
      "30it [00:00, 34.55it/s]\n",
      "30it [00:00, 34.43it/s]\n",
      "30it [00:00, 35.18it/s]\n",
      "30it [00:00, 36.00it/s]\n",
      "30it [00:00, 34.58it/s]\n",
      "30it [00:00, 35.87it/s]\n",
      "30it [00:00, 36.38it/s]\n",
      "30it [00:00, 35.99it/s]\n",
      "30it [00:00, 36.16it/s]\n",
      "30it [00:00, 35.43it/s]\n",
      "30it [00:00, 35.76it/s]\n",
      "30it [00:00, 35.87it/s]\n",
      "30it [00:00, 36.50it/s]\n",
      "30it [00:00, 36.34it/s]\n",
      "30it [00:00, 36.27it/s]\n",
      "30it [00:00, 35.96it/s]\n",
      "30it [00:00, 36.08it/s]\n",
      "30it [00:00, 36.65it/s]\n",
      "30it [00:00, 34.50it/s]\n",
      "30it [00:00, 35.24it/s]\n",
      "30it [00:00, -382.16it/s]\n",
      "30it [00:00, 36.38it/s]\n",
      "30it [00:00, 36.66it/s]\n",
      "30it [00:00, 36.32it/s]\n",
      "30it [00:00, 36.82it/s]\n",
      "30it [00:00, 37.14it/s]\n",
      "30it [00:00, 35.77it/s]\n",
      "30it [00:00, 36.34it/s]\n",
      "30it [00:00, 36.95it/s]\n",
      "30it [00:00, 36.29it/s]\n",
      "30it [00:00, 36.61it/s]\n",
      "30it [00:00, 36.30it/s]\n",
      "30it [00:00, 35.13it/s]\n",
      "30it [00:00, 35.52it/s]\n",
      "30it [00:00, 35.54it/s]\n",
      "30it [00:00, 35.87it/s]\n",
      "30it [00:00, 36.34it/s]\n",
      "30it [00:00, 34.72it/s]\n",
      "30it [00:00, 35.79it/s]\n",
      "30it [00:00, 36.30it/s]\n",
      "30it [00:00, 36.16it/s]\n",
      "30it [00:00, 34.90it/s]\n",
      "30it [00:00, 35.50it/s]\n",
      "30it [00:00, 33.97it/s]\n",
      "30it [00:00, 35.39it/s]\n",
      "30it [00:00, 35.70it/s]\n",
      "30it [00:00, 35.53it/s]\n",
      "30it [00:00, 36.27it/s]\n",
      "30it [00:00, 36.14it/s]\n",
      "30it [00:00, 36.18it/s]\n",
      "30it [00:00, 35.09it/s]\n",
      "30it [00:00, 35.31it/s]\n",
      "30it [00:00, 36.00it/s]\n",
      "30it [00:00, 35.91it/s]\n",
      "30it [00:00, 35.92it/s]\n",
      "30it [00:00, 35.92it/s]\n",
      "30it [00:00, -1159.69it/s]\n",
      "30it [00:00, 34.93it/s]\n",
      "30it [00:00, 35.66it/s]\n",
      "30it [00:00, 36.06it/s]\n",
      "30it [00:00, 36.35it/s]\n",
      "30it [00:00, 36.23it/s]\n",
      "30it [00:00, 35.94it/s]\n",
      "30it [00:00, 35.88it/s]\n",
      "30it [00:00, 34.78it/s]\n",
      "30it [00:00, 35.77it/s]\n",
      "30it [00:00, 35.31it/s]\n",
      "30it [00:00, 35.38it/s]\n",
      "30it [00:00, 35.97it/s]\n",
      "30it [00:00, 36.14it/s]\n",
      "30it [00:00, 35.89it/s]\n",
      "30it [00:00, 35.95it/s]\n",
      "30it [00:00, 35.17it/s]\n",
      "30it [00:00, 35.59it/s]\n",
      "30it [00:00, 35.87it/s]\n",
      "30it [00:00, 36.29it/s]\n",
      "30it [00:00, 35.99it/s]\n",
      "30it [00:00, 36.17it/s]\n",
      "30it [00:00, 35.95it/s]\n",
      "30it [00:00, 35.94it/s]\n",
      "30it [00:00, 34.82it/s]\n",
      "30it [00:00, 35.38it/s]\n",
      "30it [00:00, 35.01it/s]\n",
      "30it [00:00, 35.41it/s]\n",
      "30it [00:00, 36.17it/s]\n",
      "30it [00:00, 36.15it/s]\n",
      "30it [00:00, 36.16it/s]\n",
      "30it [00:00, 34.90it/s]\n",
      "30it [00:00, 35.15it/s]\n",
      "30it [00:00, 35.35it/s]\n",
      "30it [00:00, 36.28it/s]\n",
      "Inception v3模型加载成功\n",
      "\n",
      "=== 计算FID分数 ===\n",
      "FID分数: 27.8034\n",
      "[W114 23:02:15.725757544 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
     ]
    }
   ],
   "source": [
    "!python 4.7_复-基于6_混合精度尝试.py --n_epochs 7 --train_mode resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3a200c-f8af-449c-bca1-751fa3740024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9160216b-2fde-4557-91dc-05770845e559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b171cae-9968-4819-99d8-f512c431dce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfe15ea0-fd7e-4cad-8fff-9a40a9e69524",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !python 4.8_无妄-基于7_使用预训练的ddpm去微调.py --n_epochs 1 --train_mode fresh\n",
    "# ## FID分数: 11.8168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46a9ac07-9658-4afe-bc52-f190eb166769",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !python 4.8_无妄-基于7_使用预训练的ddpm去微调.py --n_epochs 2\n",
    "# FID分数: 三十大几。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af46ccf4-a204-4426-a1f1-b799ad26ee9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.49s/it]\n",
      "已开启 text_encoder 梯度检查点 (Gradient Checkpointing)\n",
      "使用 Qwen 文本编码器并应用 LoRA，隐藏维度为 2048\n",
      "/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4/4.8_无妄-基于7_使用预训练的ddpm去微调.py:418: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "已加载 text_encoder 参数\n",
      "已加载 scaler 状态\n",
      "断点位置 epoch=5, step=3336, loss=0.044723\n",
      "已检测到现有模型，加载并续训: /mnt/d/forCoding_data/Tianchi_MUGE/plan_4/trained_models/4.8_无妄-基于7_使用预训练的ddpm去微调_model.pth\n",
      " 99%|████████████████████████████████████▌| 3299/3337 [00:02<00:00, 1486.93it/s]/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4/4.8_无妄-基于7_使用预训练的ddpm去微调.py:506: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "100%|██████████████████████████████████████| 3337/3337 [00:04<00:00, 802.18it/s]\n",
      "100%|███████████████████████████████████████| 3337/3337 [15:36<00:00,  3.56it/s]\n",
      "Finished epoch 6. Average of the last 100 loss values: 0.031854\n",
      "100%|███████████████████████████████████████| 3337/3337 [15:42<00:00,  3.54it/s]\n",
      "Finished epoch 7. Average of the last 100 loss values: 0.050859\n",
      "100%|███████████████████████████████████████| 3337/3337 [15:46<00:00,  3.53it/s]\n",
      "Finished epoch 8. Average of the last 100 loss values: 0.067454\n",
      "100%|███████████████████████████████████████| 3337/3337 [15:51<00:00,  3.51it/s]\n",
      "Finished epoch 9. Average of the last 100 loss values: 0.063770\n",
      "60it [01:54,  1.91s/it]\n",
      "生成图片中(总共200张): 0it [00:00, ?it/s]/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "生成图片中(总共200张): 200it [16:20,  4.90s/it]\n",
      "Inception v3模型加载成功\n",
      "\n",
      "=== 计算FID分数 ===\n",
      "FID分数: 6.0404\n",
      "[W115 17:56:40.336130398 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
     ]
    }
   ],
   "source": [
    "# !python 4.8_无妄-基于7_使用预训练的ddpm去微调.py --n_epochs 10\n",
    "# FID分数: 6.0404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4036686b-0ea6-4e61-ad02-925f92bc0983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.17s/it]\n",
      "已开启 text_encoder 梯度检查点 (Gradient Checkpointing)\n",
      "使用 Qwen 文本编码器并应用 LoRA，隐藏维度为 2048\n",
      "/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4/4.8_无妄-基于7_使用预训练的ddpm去微调.py:418: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "已加载 text_encoder 参数\n",
      "已加载 scaler 状态\n",
      "断点位置 epoch=9, step=3336, loss=0.063770\n",
      "已检测到现有模型，加载并续训: /mnt/d/forCoding_data/Tianchi_MUGE/plan_4/trained_models/4.8_无妄-基于7_使用预训练的ddpm去微调_model.pth\n",
      " 98%|████████████████████████████████████▏| 3266/3337 [00:02<00:00, 1547.89it/s]/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4/4.8_无妄-基于7_使用预训练的ddpm去微调.py:506: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "100%|██████████████████████████████████████| 3337/3337 [00:05<00:00, 660.06it/s]\n",
      "60it [01:55,  1.92s/it]\n",
      "100%|███████████████████████████████████████| 3337/3337 [15:36<00:00,  3.56it/s]\n",
      "Finished epoch 10. Average of the last 100 loss values: 0.050610\n",
      "100%|███████████████████████████████████████| 3337/3337 [15:39<00:00,  3.55it/s]\n",
      "Finished epoch 11. Average of the last 100 loss values: 0.030219\n",
      "100%|███████████████████████████████████████| 3337/3337 [15:36<00:00,  3.56it/s]\n",
      "Finished epoch 12. Average of the last 100 loss values: 0.041323\n",
      "100%|███████████████████████████████████████| 3337/3337 [15:32<00:00,  3.58it/s]\n",
      "Finished epoch 13. Average of the last 100 loss values: 0.041454\n",
      "100%|███████████████████████████████████████| 3337/3337 [15:39<00:00,  3.55it/s]\n",
      "Finished epoch 14. Average of the last 100 loss values: 0.031957\n",
      "60it [01:55,  1.92s/it]\n",
      "生成图片中(总共200张): 0it [00:00, ?it/s]/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "生成图片中(总共200张): 200it [16:19,  4.90s/it]\n",
      "Inception v3模型加载成功\n",
      "\n",
      "=== 计算FID分数 ===\n",
      "FID分数: 10.9519\n",
      "[W115 21:03:50.492090132 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
     ]
    }
   ],
   "source": [
    "!python 4.8_无妄-基于7_使用预训练的ddpm去微调.py --n_epochs 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f748a3-974d-4509-bc73-a8b4b07bc4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a209f030-7481-4927-b9cf-535b35cb9137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34283bae-de59-4412-82f3-d70bbfec95da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6585eb5-709b-4bfc-9395-7d35ffff6be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
