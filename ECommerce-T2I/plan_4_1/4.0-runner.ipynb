{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "907a8f6c-4947-49b2-9746-68516d4fe332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.65s/it]\n",
      "已开启 text_encoder 梯度检查点 (Gradient Checkpointing)\n",
      "使用 Qwen 文本编码器并应用 LoRA，隐藏维度为 2048\n",
      "/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.9_大畜-基于8_文本利用率提升_增加额外通道.py:281: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "检测到 train_mode=fresh，忽略已有模型并从头开始训练。\n",
      "  0%|                                                   | 0/260 [00:00<?, ?it/s]/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.9_大畜-基于8_文本利用率提升_增加额外通道.py:369: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.47it/s]\n",
      "Finished epoch 0. Average of the last 100 loss values: 0.092706\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.50it/s]\n",
      "Finished epoch 1. Average of the last 100 loss values: 0.097020\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.54it/s]\n",
      "Finished epoch 2. Average of the last 100 loss values: 0.092458\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.56it/s]\n",
      "Finished epoch 3. Average of the last 100 loss values: 0.069333\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.53it/s]\n",
      "Finished epoch 4. Average of the last 100 loss values: 0.067253\n",
      "60it [01:54,  1.91s/it]\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.57it/s]\n",
      "Finished epoch 5. Average of the last 100 loss values: 0.062755\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.52it/s]\n",
      "Finished epoch 6. Average of the last 100 loss values: 0.065804\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.50it/s]\n",
      "Finished epoch 7. Average of the last 100 loss values: 0.050862\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.50it/s]\n",
      "Finished epoch 8. Average of the last 100 loss values: 0.053162\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.57it/s]\n",
      "Finished epoch 9. Average of the last 100 loss values: 0.053239\n",
      "60it [01:54,  1.91s/it]\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.55it/s]\n",
      "Finished epoch 10. Average of the last 100 loss values: 0.053765\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.55it/s]\n",
      "Finished epoch 11. Average of the last 100 loss values: 0.088561\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.53it/s]\n",
      "Finished epoch 12. Average of the last 100 loss values: 0.042018\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.49it/s]\n",
      "Finished epoch 13. Average of the last 100 loss values: 0.063604\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.53it/s]\n",
      "Finished epoch 14. Average of the last 100 loss values: 0.047190\n",
      "60it [01:54,  1.91s/it]\n",
      "100%|█████████████████████████████████████████| 260/260 [01:15<00:00,  3.46it/s]\n",
      "Finished epoch 15. Average of the last 100 loss values: 0.046186\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.59it/s]\n",
      "Finished epoch 16. Average of the last 100 loss values: 0.043377\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.48it/s]\n",
      "Finished epoch 17. Average of the last 100 loss values: 0.037548\n",
      "100%|█████████████████████████████████████████| 260/260 [01:15<00:00,  3.47it/s]\n",
      "Finished epoch 18. Average of the last 100 loss values: 0.039567\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.52it/s]\n",
      "Finished epoch 19. Average of the last 100 loss values: 0.045500\n",
      "60it [01:55,  1.93s/it]\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.51it/s]\n",
      "Finished epoch 20. Average of the last 100 loss values: 0.045356\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.49it/s]\n",
      "Finished epoch 21. Average of the last 100 loss values: 0.044061\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.53it/s]\n",
      "Finished epoch 22. Average of the last 100 loss values: 0.038676\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.56it/s]\n",
      "Finished epoch 23. Average of the last 100 loss values: 0.049528\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.50it/s]\n",
      "Finished epoch 24. Average of the last 100 loss values: 0.036739\n",
      "60it [01:54,  1.91s/it]\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.49it/s]\n",
      "Finished epoch 25. Average of the last 100 loss values: 0.049493\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.54it/s]\n",
      "Finished epoch 26. Average of the last 100 loss values: 0.046892\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.54it/s]\n",
      "Finished epoch 27. Average of the last 100 loss values: 0.035118\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.57it/s]\n",
      "Finished epoch 28. Average of the last 100 loss values: 0.046704\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.48it/s]\n",
      "Finished epoch 29. Average of the last 100 loss values: 0.052135\n",
      "60it [01:55,  1.92s/it]\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.58it/s]\n",
      "Finished epoch 30. Average of the last 100 loss values: 0.038289\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.49it/s]\n",
      "Finished epoch 31. Average of the last 100 loss values: 0.054909\n",
      " 93%|██████████████████████████████████████▏  | 242/260 [01:08<00:05,  3.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成图片中(总共400张): 60it [04:52,  4.88s/it]\n",
      "Inception v3模型加载成功\n",
      "\n",
      "=== 计算FID分数 ===\n",
      "FID分数: 0.3826\n",
      "[W210 18:12:03.766929169 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
     ]
    }
   ],
   "source": [
    "!python 4.9_大畜-基于8_文本利用率提升_增加额外通道.py --n_epochs 40 --train_mode fresh\n",
    "# !python 4.9_大畜-基于8_文本利用率提升_增加额外通道.py --n_epochs 2 # --train_mode \n",
    "# !python 4.9_大畜-基于8_文本利用率提升_增加额外通道.py --n_epochs 2 # --train_mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab637b85-23cc-4566-ad19-b6e8a5fd6e10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:12<00:00,  6.21s/it]\n",
      "已开启 text_encoder 梯度检查点 (Gradient Checkpointing)\n",
      "使用 Qwen 文本编码器并应用 LoRA，隐藏维度为 2048\n",
      "/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.10_颐-基于9_txt和img用attn融合.py:348: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "检测到 train_mode=fresh，忽略已有模型并从头开始训练。\n",
      "  0%|                                                   | 0/260 [00:00<?, ?it/s]/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.10_颐-基于9_txt和img用attn融合.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "100%|█████████████████████████████████████████| 260/260 [01:15<00:00,  3.45it/s]\n",
      "Finished epoch 0. Average of the last 100 loss values: 0.092587\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.53it/s]\n",
      "Finished epoch 1. Average of the last 100 loss values: 0.078761\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.49it/s]\n",
      "Finished epoch 2. Average of the last 100 loss values: 0.071886\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.55it/s]\n",
      "Finished epoch 3. Average of the last 100 loss values: 0.072520\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.53it/s]\n",
      "Finished epoch 4. Average of the last 100 loss values: 0.057426\n",
      "60it [01:56,  1.95s/it]\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.50it/s]\n",
      "Finished epoch 5. Average of the last 100 loss values: 0.080584\n",
      "100%|█████████████████████████████████████████| 260/260 [01:15<00:00,  3.43it/s]\n",
      "Finished epoch 6. Average of the last 100 loss values: 0.077906\n",
      "100%|█████████████████████████████████████████| 260/260 [01:16<00:00,  3.42it/s]\n",
      "Finished epoch 7. Average of the last 100 loss values: 0.071767\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.52it/s]\n",
      "Finished epoch 8. Average of the last 100 loss values: 0.042149\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.49it/s]\n",
      "Finished epoch 9. Average of the last 100 loss values: 0.050186\n",
      "60it [01:56,  1.94s/it]\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.51it/s]\n",
      "Finished epoch 10. Average of the last 100 loss values: 0.061626\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.50it/s]\n",
      "Finished epoch 11. Average of the last 100 loss values: 0.035977\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.48it/s]\n",
      "Finished epoch 12. Average of the last 100 loss values: 0.047619\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.48it/s]\n",
      "Finished epoch 13. Average of the last 100 loss values: 0.049241\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.51it/s]\n",
      "Finished epoch 14. Average of the last 100 loss values: 0.070706\n",
      "60it [01:56,  1.94s/it]\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.47it/s]\n",
      "Finished epoch 15. Average of the last 100 loss values: 0.036722\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.47it/s]\n",
      "Finished epoch 16. Average of the last 100 loss values: 0.054194\n",
      "100%|█████████████████████████████████████████| 260/260 [01:15<00:00,  3.42it/s]\n",
      "Finished epoch 17. Average of the last 100 loss values: 0.057187\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.48it/s]\n",
      "Finished epoch 18. Average of the last 100 loss values: 0.044422\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.51it/s]\n",
      "Finished epoch 19. Average of the last 100 loss values: 0.059819\n",
      "60it [01:56,  1.94s/it]\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.51it/s]\n",
      "Finished epoch 20. Average of the last 100 loss values: 0.057404\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.48it/s]\n",
      "Finished epoch 21. Average of the last 100 loss values: 0.043040\n",
      "100%|█████████████████████████████████████████| 260/260 [01:15<00:00,  3.45it/s]\n",
      "Finished epoch 22. Average of the last 100 loss values: 0.062495\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.51it/s]\n",
      "Finished epoch 23. Average of the last 100 loss values: 0.035414\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.47it/s]\n",
      "Finished epoch 24. Average of the last 100 loss values: 0.040892\n",
      "60it [01:57,  1.96s/it]\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.51it/s]\n",
      "Finished epoch 25. Average of the last 100 loss values: 0.034976\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.48it/s]\n",
      "Finished epoch 26. Average of the last 100 loss values: 0.040574\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.50it/s]\n",
      "Finished epoch 27. Average of the last 100 loss values: 0.046400\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.50it/s]\n",
      "Finished epoch 28. Average of the last 100 loss values: 0.033042\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.49it/s]\n",
      "Finished epoch 29. Average of the last 100 loss values: 0.040615\n",
      "60it [01:56,  1.94s/it]\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.47it/s]\n",
      "Finished epoch 30. Average of the last 100 loss values: 0.056148\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.47it/s]\n",
      "Finished epoch 31. Average of the last 100 loss values: 0.038851\n",
      "100%|█████████████████████████████████████████| 260/260 [01:15<00:00,  3.46it/s]\n",
      "Finished epoch 32. Average of the last 100 loss values: 0.028642\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.51it/s]\n",
      "Finished epoch 33. Average of the last 100 loss values: 0.027971\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.54it/s]\n",
      "Finished epoch 34. Average of the last 100 loss values: 0.040250\n",
      "60it [01:56,  1.94s/it]\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.47it/s]\n",
      "Finished epoch 35. Average of the last 100 loss values: 0.045942\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.47it/s]\n",
      "Finished epoch 36. Average of the last 100 loss values: 0.038706\n",
      "100%|█████████████████████████████████████████| 260/260 [01:15<00:00,  3.45it/s]\n",
      "Finished epoch 37. Average of the last 100 loss values: 0.036950\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.48it/s]\n",
      "Finished epoch 38. Average of the last 100 loss values: 0.034029\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.47it/s]\n",
      "Finished epoch 39. Average of the last 100 loss values: 0.028491\n",
      "60it [01:57,  1.96s/it]\n",
      "生成图片中(总共400张): 0it [00:00, ?it/s]/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "生成图片中(总共400张): 60it [04:55,  4.92s/it]\n",
      "Inception v3模型加载成功\n",
      "\n",
      "=== 计算FID分数 ===\n",
      "FID分数: 1.8099\n",
      "[W210 19:53:08.263072996 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
     ]
    }
   ],
   "source": [
    "!python 4.10_颐-基于9_txt和img用attn融合.py --n_epochs 40 --train_mode fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9885077e-e153-4665-b097-02a7a096dea5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.60s/it]\n",
      "已开启 text_encoder 梯度检查点 (Gradient Checkpointing)\n",
      "使用 Qwen 文本编码器并应用 LoRA，隐藏维度为 2048\n",
      "/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.11_大过-基于9-去掉ema.py:285: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "检测到 train_mode=fresh，忽略已有模型并从头开始训练。\n",
      "  0%|                                                   | 0/260 [00:00<?, ?it/s]/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.11_大过-基于9-去掉ema.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.47it/s]\n",
      "Finished epoch 0. Average of the last 100 loss values: 0.087048\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.59it/s]\n",
      "Finished epoch 1. Average of the last 100 loss values: 0.097638\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.60it/s]\n",
      "Finished epoch 2. Average of the last 100 loss values: 0.084765\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.59it/s]\n",
      "Finished epoch 3. Average of the last 100 loss values: 0.065735\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.58it/s]\n",
      "Finished epoch 4. Average of the last 100 loss values: 0.060004\n",
      "60it [01:55,  1.93s/it]\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.59it/s]\n",
      "Finished epoch 5. Average of the last 100 loss values: 0.051020\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.58it/s]\n",
      "Finished epoch 6. Average of the last 100 loss values: 0.051145\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.61it/s]\n",
      "Finished epoch 7. Average of the last 100 loss values: 0.046033\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.58it/s]\n",
      "Finished epoch 8. Average of the last 100 loss values: 0.065604\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.59it/s]\n",
      "Finished epoch 9. Average of the last 100 loss values: 0.061667\n",
      "60it [01:54,  1.91s/it]\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.55it/s]\n",
      "Finished epoch 10. Average of the last 100 loss values: 0.073602\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.63it/s]\n",
      "Finished epoch 11. Average of the last 100 loss values: 0.057431\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.62it/s]\n",
      "Finished epoch 12. Average of the last 100 loss values: 0.060647\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.49it/s]\n",
      "Finished epoch 13. Average of the last 100 loss values: 0.051890\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.55it/s]\n",
      "Finished epoch 14. Average of the last 100 loss values: 0.049326\n",
      "60it [01:55,  1.93s/it]\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.60it/s]\n",
      "Finished epoch 15. Average of the last 100 loss values: 0.067767\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.57it/s]\n",
      "Finished epoch 16. Average of the last 100 loss values: 0.043564\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.50it/s]\n",
      "Finished epoch 17. Average of the last 100 loss values: 0.039575\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.50it/s]\n",
      "Finished epoch 18. Average of the last 100 loss values: 0.038163\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.55it/s]\n",
      "Finished epoch 19. Average of the last 100 loss values: 0.040243\n",
      "60it [01:54,  1.91s/it]\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.58it/s]\n",
      "Finished epoch 20. Average of the last 100 loss values: 0.040279\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.63it/s]\n",
      "Finished epoch 21. Average of the last 100 loss values: 0.033933\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.63it/s]\n",
      "Finished epoch 22. Average of the last 100 loss values: 0.034023\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.54it/s]\n",
      "Finished epoch 23. Average of the last 100 loss values: 0.032126\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.56it/s]\n",
      "Finished epoch 24. Average of the last 100 loss values: 0.047996\n",
      "60it [01:55,  1.93s/it]\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.62it/s]\n",
      "Finished epoch 25. Average of the last 100 loss values: 0.037566\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.62it/s]\n",
      "Finished epoch 26. Average of the last 100 loss values: 0.039852\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.55it/s]\n",
      "Finished epoch 27. Average of the last 100 loss values: 0.050299\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.53it/s]\n",
      "Finished epoch 28. Average of the last 100 loss values: 0.059554\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.54it/s]\n",
      "Finished epoch 29. Average of the last 100 loss values: 0.043388\n",
      "60it [01:54,  1.91s/it]\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.53it/s]\n",
      "Finished epoch 30. Average of the last 100 loss values: 0.032473\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.53it/s]\n",
      "Finished epoch 31. Average of the last 100 loss values: 0.036220\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.61it/s]\n",
      "Finished epoch 32. Average of the last 100 loss values: 0.032571\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.61it/s]\n",
      "Finished epoch 33. Average of the last 100 loss values: 0.044428\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.59it/s]\n",
      "Finished epoch 34. Average of the last 100 loss values: 0.052364\n",
      "60it [01:54,  1.91s/it]\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.54it/s]\n",
      "Finished epoch 35. Average of the last 100 loss values: 0.035612\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.56it/s]\n",
      "Finished epoch 36. Average of the last 100 loss values: 0.038545\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.59it/s]\n",
      "Finished epoch 37. Average of the last 100 loss values: 0.034215\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.52it/s]\n",
      "Finished epoch 38. Average of the last 100 loss values: 0.040233\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.53it/s]\n",
      "Finished epoch 39. Average of the last 100 loss values: 0.031337\n",
      "60it [01:55,  1.92s/it]\n",
      "生成图片中(总共400张): 0it [00:00, ?it/s]/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "生成图片中(总共400张): 60it [04:52,  4.88s/it]\n",
      "Inception v3模型加载成功\n",
      "\n",
      "=== 计算FID分数 ===\n",
      "FID分数: 1.0587\n",
      "[W210 21:32:21.910066754 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
     ]
    }
   ],
   "source": [
    "!python 4.11_大过-基于9-去掉ema.py --n_epochs 40 --train_mode fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4235a524-1b9d-4461-b6ff-558e2da14e2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:12<00:00,  6.07s/it]\n",
      "已开启 text_encoder 梯度检查点 (Gradient Checkpointing)\n",
      "使用 Qwen 文本编码器并应用 LoRA，隐藏维度为 2048\n",
      "/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.12_坎-基于9-去掉snr.py:282: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "检测到 train_mode=fresh，忽略已有模型并从头开始训练。\n",
      "  0%|                                                   | 0/260 [00:00<?, ?it/s]/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.12_坎-基于9-去掉snr.py:370: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "100%|█████████████████████████████████████████| 260/260 [01:10<00:00,  3.70it/s]\n",
      "Finished epoch 0. Average of the last 100 loss values: 0.091716\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.65it/s]\n",
      "Finished epoch 1. Average of the last 100 loss values: 0.067068\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.65it/s]\n",
      "Finished epoch 2. Average of the last 100 loss values: 0.080262\n",
      "100%|█████████████████████████████████████████| 260/260 [01:18<00:00,  3.31it/s]\n",
      "Finished epoch 3. Average of the last 100 loss values: 0.066085\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.58it/s]\n",
      "Finished epoch 4. Average of the last 100 loss values: 0.052907\n",
      "100%|█████████████████████████████████████████| 260/260 [01:07<00:00,  3.84it/s]\n",
      "Finished epoch 5. Average of the last 100 loss values: 0.058021\n",
      "100%|█████████████████████████████████████████| 260/260 [01:10<00:00,  3.68it/s]\n",
      "Finished epoch 6. Average of the last 100 loss values: 0.052590\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.65it/s]\n",
      "Finished epoch 7. Average of the last 100 loss values: 0.057007\n",
      "100%|█████████████████████████████████████████| 260/260 [01:19<00:00,  3.27it/s]\n",
      "Finished epoch 8. Average of the last 100 loss values: 0.058219\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.60it/s]\n",
      "Finished epoch 9. Average of the last 100 loss values: 0.050433\n",
      "100%|█████████████████████████████████████████| 260/260 [01:07<00:00,  3.83it/s]\n",
      "Finished epoch 10. Average of the last 100 loss values: 0.045648\n",
      "100%|█████████████████████████████████████████| 260/260 [01:10<00:00,  3.67it/s]\n",
      "Finished epoch 11. Average of the last 100 loss values: 0.042414\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.64it/s]\n",
      "Finished epoch 12. Average of the last 100 loss values: 0.050697\n",
      "100%|█████████████████████████████████████████| 260/260 [01:20<00:00,  3.23it/s]\n",
      "Finished epoch 13. Average of the last 100 loss values: 0.045228\n",
      "100%|█████████████████████████████████████████| 260/260 [01:09<00:00,  3.76it/s]\n",
      "Finished epoch 14. Average of the last 100 loss values: 0.045665\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.65it/s]\n",
      "Finished epoch 15. Average of the last 100 loss values: 0.039967\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.64it/s]\n",
      "Finished epoch 16. Average of the last 100 loss values: 0.049695\n",
      "100%|█████████████████████████████████████████| 260/260 [01:09<00:00,  3.72it/s]\n",
      "Finished epoch 17. Average of the last 100 loss values: 0.049225\n",
      "100%|█████████████████████████████████████████| 260/260 [01:21<00:00,  3.17it/s]\n",
      "Finished epoch 18. Average of the last 100 loss values: 0.038072\n",
      "100%|█████████████████████████████████████████| 260/260 [01:09<00:00,  3.77it/s]\n",
      "Finished epoch 19. Average of the last 100 loss values: 0.038342\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.62it/s]\n",
      "Finished epoch 20. Average of the last 100 loss values: 0.036259\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.63it/s]\n",
      "Finished epoch 21. Average of the last 100 loss values: 0.039051\n",
      "100%|█████████████████████████████████████████| 260/260 [01:15<00:00,  3.43it/s]\n",
      "Finished epoch 22. Average of the last 100 loss values: 0.042443\n",
      "100%|█████████████████████████████████████████| 260/260 [01:17<00:00,  3.37it/s]\n",
      "Finished epoch 23. Average of the last 100 loss values: 0.038470\n",
      "100%|█████████████████████████████████████████| 260/260 [01:09<00:00,  3.75it/s]\n",
      "Finished epoch 24. Average of the last 100 loss values: 0.040135\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.65it/s]\n",
      "Finished epoch 25. Average of the last 100 loss values: 0.043178\n",
      "100%|█████████████████████████████████████████| 260/260 [01:08<00:00,  3.81it/s]\n",
      "Finished epoch 26. Average of the last 100 loss values: 0.032951\n",
      "100%|█████████████████████████████████████████| 260/260 [01:18<00:00,  3.33it/s]\n",
      "Finished epoch 27. Average of the last 100 loss values: 0.033579\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.52it/s]\n",
      "Finished epoch 28. Average of the last 100 loss values: 0.032388\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.64it/s]\n",
      "Finished epoch 29. Average of the last 100 loss values: 0.035569\n",
      "100%|█████████████████████████████████████████| 260/260 [01:10<00:00,  3.66it/s]\n",
      "Finished epoch 30. Average of the last 100 loss values: 0.031479\n",
      "100%|█████████████████████████████████████████| 260/260 [01:08<00:00,  3.82it/s]\n",
      "Finished epoch 31. Average of the last 100 loss values: 0.039753\n",
      "100%|█████████████████████████████████████████| 260/260 [01:18<00:00,  3.29it/s]\n",
      "Finished epoch 32. Average of the last 100 loss values: 0.037859\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.57it/s]\n",
      "Finished epoch 33. Average of the last 100 loss values: 0.036415\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.65it/s]\n",
      "Finished epoch 34. Average of the last 100 loss values: 0.032464\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.65it/s]\n",
      "Finished epoch 35. Average of the last 100 loss values: 0.035309\n",
      "100%|█████████████████████████████████████████| 260/260 [01:08<00:00,  3.80it/s]\n",
      "Finished epoch 36. Average of the last 100 loss values: 0.036926\n",
      "100%|█████████████████████████████████████████| 260/260 [01:19<00:00,  3.26it/s]\n",
      "Finished epoch 37. Average of the last 100 loss values: 0.037173\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.55it/s]\n",
      "Finished epoch 38. Average of the last 100 loss values: 0.040160\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.64it/s]\n",
      "Finished epoch 39. Average of the last 100 loss values: 0.039204\n",
      "生成图片中(总共400张): 0it [00:00, ?it/s]/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "生成图片中(总共400张): 60it [04:53,  4.89s/it]\n",
      "Inception v3模型加载成功\n",
      "\n",
      "=== 计算FID分数 ===\n",
      "FID分数: 0.5329\n",
      "[W211 11:32:10.270549865 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
     ]
    }
   ],
   "source": [
    "!python 4.12_坎-基于9-去掉snr.py --n_epochs 40 --train_mode fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f85a6db6-93cd-4e18-95fb-fcfa5c8d74d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:12<00:00,  6.35s/it]\n",
      "已开启 text_encoder 梯度检查点 (Gradient Checkpointing)\n",
      "使用 Qwen 文本编码器并应用 LoRA，隐藏维度为 2048\n",
      "/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.13_离-基于9-损失函数不用velocity.py:282: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "检测到 train_mode=fresh，忽略已有模型并从头开始训练。\n",
      "  0%|                                                   | 0/260 [00:00<?, ?it/s]/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.13_离-基于9-损失函数不用velocity.py:370: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.54it/s]\n",
      "Finished epoch 0. Average of the last 100 loss values: 0.041362\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.63it/s]\n",
      "Finished epoch 1. Average of the last 100 loss values: 0.029994\n",
      "100%|█████████████████████████████████████████| 260/260 [01:17<00:00,  3.34it/s]\n",
      "Finished epoch 2. Average of the last 100 loss values: 0.028832\n",
      "100%|█████████████████████████████████████████| 260/260 [01:14<00:00,  3.50it/s]\n",
      "Finished epoch 3. Average of the last 100 loss values: 0.026786\n",
      "100%|█████████████████████████████████████████| 260/260 [01:08<00:00,  3.78it/s]\n",
      "Finished epoch 4. Average of the last 100 loss values: 0.021972\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.61it/s]\n",
      "Finished epoch 5. Average of the last 100 loss values: 0.028706\n",
      "100%|█████████████████████████████████████████| 260/260 [01:09<00:00,  3.77it/s]\n",
      "Finished epoch 6. Average of the last 100 loss values: 0.023772\n",
      "100%|█████████████████████████████████████████| 260/260 [01:21<00:00,  3.20it/s]\n",
      "Finished epoch 7. Average of the last 100 loss values: 0.030602\n",
      "100%|█████████████████████████████████████████| 260/260 [01:10<00:00,  3.67it/s]\n",
      "Finished epoch 8. Average of the last 100 loss values: 0.020517\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.64it/s]\n",
      "Finished epoch 9. Average of the last 100 loss values: 0.025336\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.59it/s]\n",
      "Finished epoch 10. Average of the last 100 loss values: 0.024942\n",
      "100%|█████████████████████████████████████████| 260/260 [01:09<00:00,  3.75it/s]\n",
      "Finished epoch 11. Average of the last 100 loss values: 0.023063\n",
      "100%|█████████████████████████████████████████| 260/260 [01:22<00:00,  3.15it/s]\n",
      "Finished epoch 12. Average of the last 100 loss values: 0.022017\n",
      "100%|█████████████████████████████████████████| 260/260 [01:10<00:00,  3.68it/s]\n",
      "Finished epoch 13. Average of the last 100 loss values: 0.023499\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.64it/s]\n",
      "Finished epoch 14. Average of the last 100 loss values: 0.014905\n",
      "100%|█████████████████████████████████████████| 260/260 [01:09<00:00,  3.72it/s]\n",
      "Finished epoch 15. Average of the last 100 loss values: 0.023674\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.55it/s]\n",
      "Finished epoch 16. Average of the last 100 loss values: 0.018687\n",
      "100%|█████████████████████████████████████████| 260/260 [01:18<00:00,  3.30it/s]\n",
      "Finished epoch 17. Average of the last 100 loss values: 0.021467\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.60it/s]\n",
      "Finished epoch 18. Average of the last 100 loss values: 0.013311\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.65it/s]\n",
      "Finished epoch 19. Average of the last 100 loss values: 0.027778\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.61it/s]\n",
      "Finished epoch 20. Average of the last 100 loss values: 0.017088\n",
      "100%|█████████████████████████████████████████| 260/260 [01:19<00:00,  3.27it/s]\n",
      "Finished epoch 21. Average of the last 100 loss values: 0.021122\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.54it/s]\n",
      "Finished epoch 22. Average of the last 100 loss values: 0.016947\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.59it/s]\n",
      "Finished epoch 23. Average of the last 100 loss values: 0.020332\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.55it/s]\n",
      "Finished epoch 24. Average of the last 100 loss values: 0.023428\n",
      "100%|█████████████████████████████████████████| 260/260 [01:10<00:00,  3.71it/s]\n",
      "Finished epoch 25. Average of the last 100 loss values: 0.016376\n",
      "100%|█████████████████████████████████████████| 260/260 [01:20<00:00,  3.22it/s]\n",
      "Finished epoch 26. Average of the last 100 loss values: 0.020096\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.59it/s]\n",
      "Finished epoch 27. Average of the last 100 loss values: 0.012135\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.57it/s]\n",
      "Finished epoch 28. Average of the last 100 loss values: 0.015457\n",
      "100%|█████████████████████████████████████████| 260/260 [01:09<00:00,  3.75it/s]\n",
      "Finished epoch 29. Average of the last 100 loss values: 0.015916\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.52it/s]\n",
      "Finished epoch 30. Average of the last 100 loss values: 0.022853\n",
      "100%|█████████████████████████████████████████| 260/260 [01:15<00:00,  3.45it/s]\n",
      "Finished epoch 31. Average of the last 100 loss values: 0.016428\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.61it/s]\n",
      "Finished epoch 32. Average of the last 100 loss values: 0.016602\n",
      "100%|█████████████████████████████████████████| 260/260 [01:09<00:00,  3.75it/s]\n",
      "Finished epoch 33. Average of the last 100 loss values: 0.019938\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.60it/s]\n",
      "Finished epoch 34. Average of the last 100 loss values: 0.012892\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.54it/s]\n",
      "Finished epoch 35. Average of the last 100 loss values: 0.014451\n",
      "100%|█████████████████████████████████████████| 260/260 [01:20<00:00,  3.23it/s]\n",
      "Finished epoch 36. Average of the last 100 loss values: 0.010655\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.64it/s]\n",
      "Finished epoch 37. Average of the last 100 loss values: 0.013470\n",
      "100%|█████████████████████████████████████████| 260/260 [01:08<00:00,  3.80it/s]\n",
      "Finished epoch 38. Average of the last 100 loss values: 0.020407\n",
      "100%|█████████████████████████████████████████| 260/260 [01:12<00:00,  3.60it/s]\n",
      "Finished epoch 39. Average of the last 100 loss values: 0.015342\n",
      "生成图片中(总共400张): 0it [00:00, ?it/s]/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "生成图片中(总共400张): 60it [04:53,  4.89s/it]\n",
      "Inception v3模型加载成功\n",
      "\n",
      "=== 计算FID分数 ===\n",
      "FID分数: 0.6308\n",
      "[W211 12:27:48.427687348 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
     ]
    }
   ],
   "source": [
    "!python 4.13_离-基于9-损失函数不用velocity.py --n_epochs 40 --train_mode fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6deb02f0-8227-4b06-8142-6690b398eb0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:13<00:00,  6.99s/it]\n",
      "已开启 text_encoder 梯度检查点 (Gradient Checkpointing)\n",
      "使用 Qwen 文本编码器并应用 LoRA，隐藏维度为 2048\n",
      "/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.14_咸-基于9-将预训练DDPM改为UViT.py:387: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "检测到 train_mode=fresh，忽略已有模型并从头开始训练。\n",
      "  0%|                                                   | 0/260 [00:00<?, ?it/s]/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.14_咸-基于9-将预训练DDPM改为UViT.py:475: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "100%|█████████████████████████████████████████| 260/260 [01:23<00:00,  3.12it/s]\n",
      "Finished epoch 0. Average of the last 100 loss values: 0.471759\n",
      "100%|█████████████████████████████████████████| 260/260 [01:07<00:00,  3.87it/s]\n",
      "Finished epoch 1. Average of the last 100 loss values: 0.255763\n",
      "100%|█████████████████████████████████████████| 260/260 [01:07<00:00,  3.86it/s]\n",
      "Finished epoch 2. Average of the last 100 loss values: 0.171995\n",
      "100%|█████████████████████████████████████████| 260/260 [01:08<00:00,  3.78it/s]\n",
      "Finished epoch 3. Average of the last 100 loss values: 0.125087\n",
      "100%|█████████████████████████████████████████| 260/260 [01:07<00:00,  3.87it/s]\n",
      "Finished epoch 4. Average of the last 100 loss values: 0.141127\n",
      "100%|█████████████████████████████████████████| 260/260 [01:20<00:00,  3.24it/s]\n",
      "Finished epoch 5. Average of the last 100 loss values: 0.151856\n",
      "100%|█████████████████████████████████████████| 260/260 [01:11<00:00,  3.61it/s]\n",
      "Finished epoch 6. Average of the last 100 loss values: 0.189067\n",
      "100%|█████████████████████████████████████████| 260/260 [01:03<00:00,  4.08it/s]\n",
      "Finished epoch 7. Average of the last 100 loss values: 0.138728\n",
      "100%|█████████████████████████████████████████| 260/260 [01:06<00:00,  3.93it/s]\n",
      "Finished epoch 8. Average of the last 100 loss values: 0.188606\n",
      "100%|█████████████████████████████████████████| 260/260 [01:08<00:00,  3.82it/s]\n",
      "Finished epoch 9. Average of the last 100 loss values: 0.102825\n",
      "100%|█████████████████████████████████████████| 260/260 [01:16<00:00,  3.39it/s]\n",
      "Finished epoch 10. Average of the last 100 loss values: 0.158483\n",
      "100%|█████████████████████████████████████████| 260/260 [01:13<00:00,  3.53it/s]\n",
      "Finished epoch 11. Average of the last 100 loss values: 0.099125\n",
      "100%|█████████████████████████████████████████| 260/260 [01:04<00:00,  4.04it/s]\n",
      "Finished epoch 12. Average of the last 100 loss values: 0.135638\n",
      "100%|█████████████████████████████████████████| 260/260 [01:07<00:00,  3.85it/s]\n",
      "Finished epoch 13. Average of the last 100 loss values: 0.103236\n",
      "100%|█████████████████████████████████████████| 260/260 [01:06<00:00,  3.89it/s]\n",
      "Finished epoch 14. Average of the last 100 loss values: 0.100203\n",
      "100%|█████████████████████████████████████████| 260/260 [01:16<00:00,  3.40it/s]\n",
      "Finished epoch 15. Average of the last 100 loss values: 0.095110\n",
      "100%|█████████████████████████████████████████| 260/260 [01:16<00:00,  3.38it/s]\n",
      "Finished epoch 16. Average of the last 100 loss values: 0.079841\n",
      "100%|█████████████████████████████████████████| 260/260 [01:06<00:00,  3.89it/s]\n",
      "Finished epoch 17. Average of the last 100 loss values: 0.144230\n",
      "100%|█████████████████████████████████████████| 260/260 [01:04<00:00,  4.05it/s]\n",
      "Finished epoch 18. Average of the last 100 loss values: 0.122061\n",
      "100%|█████████████████████████████████████████| 260/260 [01:07<00:00,  3.86it/s]\n",
      "Finished epoch 19. Average of the last 100 loss values: 0.090249\n",
      "100%|█████████████████████████████████████████| 260/260 [01:23<00:00,  3.13it/s]\n",
      "Finished epoch 20. Average of the last 100 loss values: 0.068452\n",
      "100%|█████████████████████████████████████████| 260/260 [01:08<00:00,  3.82it/s]\n",
      "Finished epoch 21. Average of the last 100 loss values: 0.082677\n",
      "100%|█████████████████████████████████████████| 260/260 [01:03<00:00,  4.07it/s]\n",
      "Finished epoch 22. Average of the last 100 loss values: 0.080389\n",
      "100%|█████████████████████████████████████████| 260/260 [01:08<00:00,  3.82it/s]\n",
      "Finished epoch 23. Average of the last 100 loss values: 0.096993\n",
      "100%|█████████████████████████████████████████| 260/260 [01:08<00:00,  3.82it/s]\n",
      "Finished epoch 24. Average of the last 100 loss values: 0.096818\n",
      "100%|█████████████████████████████████████████| 260/260 [01:20<00:00,  3.22it/s]\n",
      "Finished epoch 25. Average of the last 100 loss values: 0.083611\n",
      "100%|█████████████████████████████████████████| 260/260 [01:10<00:00,  3.69it/s]\n",
      "Finished epoch 26. Average of the last 100 loss values: 0.087969\n",
      "100%|█████████████████████████████████████████| 260/260 [01:07<00:00,  3.87it/s]\n",
      "Finished epoch 27. Average of the last 100 loss values: 0.090077\n",
      "100%|█████████████████████████████████████████| 260/260 [01:05<00:00,  3.99it/s]\n",
      "Finished epoch 28. Average of the last 100 loss values: 0.064628\n",
      "100%|█████████████████████████████████████████| 260/260 [01:07<00:00,  3.83it/s]\n",
      "Finished epoch 29. Average of the last 100 loss values: 0.060582\n",
      "100%|█████████████████████████████████████████| 260/260 [01:17<00:00,  3.34it/s]\n",
      "Finished epoch 30. Average of the last 100 loss values: 0.069792\n",
      "100%|█████████████████████████████████████████| 260/260 [01:10<00:00,  3.67it/s]\n",
      "Finished epoch 31. Average of the last 100 loss values: 0.090981\n",
      "100%|█████████████████████████████████████████| 260/260 [01:08<00:00,  3.82it/s]\n",
      "Finished epoch 32. Average of the last 100 loss values: 0.079857\n",
      "100%|█████████████████████████████████████████| 260/260 [01:05<00:00,  3.97it/s]\n",
      "Finished epoch 33. Average of the last 100 loss values: 0.085798\n",
      "100%|█████████████████████████████████████████| 260/260 [01:07<00:00,  3.86it/s]\n",
      "Finished epoch 34. Average of the last 100 loss values: 0.120330\n",
      "100%|█████████████████████████████████████████| 260/260 [01:19<00:00,  3.29it/s]\n",
      "Finished epoch 35. Average of the last 100 loss values: 0.076307\n",
      "100%|█████████████████████████████████████████| 260/260 [01:15<00:00,  3.43it/s]\n",
      "Finished epoch 36. Average of the last 100 loss values: 0.108202\n",
      "100%|█████████████████████████████████████████| 260/260 [01:07<00:00,  3.85it/s]\n",
      "Finished epoch 37. Average of the last 100 loss values: 0.089609\n",
      "100%|█████████████████████████████████████████| 260/260 [01:04<00:00,  4.04it/s]\n",
      "Finished epoch 38. Average of the last 100 loss values: 0.072892\n",
      "100%|█████████████████████████████████████████| 260/260 [01:07<00:00,  3.85it/s]\n",
      "Finished epoch 39. Average of the last 100 loss values: 0.082048\n",
      "生成图片中(总共400张): 0it [00:00, ?it/s]/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "生成图片中(总共400张): 60it [00:57,  1.04it/s]\n",
      "Inception v3模型加载成功\n",
      "\n",
      "=== 计算FID分数 ===\n",
      "FID分数: 0.5061\n",
      "[W212 16:20:18.155271262 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
     ]
    }
   ],
   "source": [
    "!python 4.14_咸-基于9-将预训练DDPM改为UViT.py --n_epochs 40 --train_mode fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1812aa65-1e3e-4331-89bf-86dfc30acb8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.82s/it]\n",
      "已开启 text_encoder 梯度检查点 (Gradient Checkpointing)\n",
      "使用 Qwen 文本编码器并应用 LoRA，隐藏维度为 2048\n",
      "/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.15_恒-基于14-去掉其中的MoE架构.py:374: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "检测到 train_mode=fresh，忽略已有模型并从头开始训练。\n",
      "  0%|                                                   | 0/260 [00:00<?, ?it/s]/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.15_恒-基于14-去掉其中的MoE架构.py:462: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "100%|█████████████████████████████████████████| 260/260 [00:47<00:00,  5.47it/s]\n",
      "Finished epoch 0. Average of the last 100 loss values: 0.422430\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.22it/s]\n",
      "Finished epoch 1. Average of the last 100 loss values: 0.291420\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.81it/s]\n",
      "Finished epoch 2. Average of the last 100 loss values: 0.175022\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.21it/s]\n",
      "Finished epoch 3. Average of the last 100 loss values: 0.154376\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.83it/s]\n",
      "Finished epoch 4. Average of the last 100 loss values: 0.227475\n",
      "100%|█████████████████████████████████████████| 260/260 [00:48<00:00,  5.40it/s]\n",
      "Finished epoch 5. Average of the last 100 loss values: 0.233818\n",
      "100%|█████████████████████████████████████████| 260/260 [00:53<00:00,  4.88it/s]\n",
      "Finished epoch 6. Average of the last 100 loss values: 0.150210\n",
      "100%|█████████████████████████████████████████| 260/260 [00:46<00:00,  5.58it/s]\n",
      "Finished epoch 7. Average of the last 100 loss values: 0.113329\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.15it/s]\n",
      "Finished epoch 8. Average of the last 100 loss values: 0.177640\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.84it/s]\n",
      "Finished epoch 9. Average of the last 100 loss values: 0.120549\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.81it/s]\n",
      "Finished epoch 10. Average of the last 100 loss values: 0.088642\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.29it/s]\n",
      "Finished epoch 11. Average of the last 100 loss values: 0.108592\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.83it/s]\n",
      "Finished epoch 12. Average of the last 100 loss values: 0.088853\n",
      "100%|█████████████████████████████████████████| 260/260 [00:48<00:00,  5.31it/s]\n",
      "Finished epoch 13. Average of the last 100 loss values: 0.101337\n",
      "100%|█████████████████████████████████████████| 260/260 [00:50<00:00,  5.11it/s]\n",
      "Finished epoch 14. Average of the last 100 loss values: 0.093083\n",
      "100%|█████████████████████████████████████████| 260/260 [00:46<00:00,  5.60it/s]\n",
      "Finished epoch 15. Average of the last 100 loss values: 0.114830\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.22it/s]\n",
      "Finished epoch 16. Average of the last 100 loss values: 0.073574\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.90it/s]\n",
      "Finished epoch 17. Average of the last 100 loss values: 0.121489\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.24it/s]\n",
      "Finished epoch 18. Average of the last 100 loss values: 0.070768\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.71it/s]\n",
      "Finished epoch 19. Average of the last 100 loss values: 0.079336\n",
      "100%|█████████████████████████████████████████| 260/260 [00:51<00:00,  5.05it/s]\n",
      "Finished epoch 20. Average of the last 100 loss values: 0.122322\n",
      "100%|█████████████████████████████████████████| 260/260 [00:53<00:00,  4.91it/s]\n",
      "Finished epoch 21. Average of the last 100 loss values: 0.114055\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.27it/s]\n",
      "Finished epoch 22. Average of the last 100 loss values: 0.101880\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.84it/s]\n",
      "Finished epoch 23. Average of the last 100 loss values: 0.106194\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.31it/s]\n",
      "Finished epoch 24. Average of the last 100 loss values: 0.074326\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.84it/s]\n",
      "Finished epoch 25. Average of the last 100 loss values: 0.093341\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.22it/s]\n",
      "Finished epoch 26. Average of the last 100 loss values: 0.130714\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.81it/s]\n",
      "Finished epoch 27. Average of the last 100 loss values: 0.111119\n",
      "100%|█████████████████████████████████████████| 260/260 [00:51<00:00,  5.07it/s]\n",
      "Finished epoch 28. Average of the last 100 loss values: 0.085917\n",
      "100%|█████████████████████████████████████████| 260/260 [00:49<00:00,  5.21it/s]\n",
      "Finished epoch 29. Average of the last 100 loss values: 0.071618\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.84it/s]\n",
      "Finished epoch 30. Average of the last 100 loss values: 0.081668\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.16it/s]\n",
      "Finished epoch 31. Average of the last 100 loss values: 0.081593\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.86it/s]\n",
      "Finished epoch 32. Average of the last 100 loss values: 0.079081\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.29it/s]\n",
      "Finished epoch 33. Average of the last 100 loss values: 0.069518\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.87it/s]\n",
      "Finished epoch 34. Average of the last 100 loss values: 0.098481\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.81it/s]\n",
      "Finished epoch 35. Average of the last 100 loss values: 0.086802\n",
      "100%|█████████████████████████████████████████| 260/260 [00:52<00:00,  4.92it/s]\n",
      "Finished epoch 36. Average of the last 100 loss values: 0.085797\n",
      "100%|█████████████████████████████████████████| 260/260 [00:49<00:00,  5.29it/s]\n",
      "Finished epoch 37. Average of the last 100 loss values: 0.056234\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.73it/s]\n",
      "Finished epoch 38. Average of the last 100 loss values: 0.099344\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.25it/s]\n",
      "Finished epoch 39. Average of the last 100 loss values: 0.110156\n",
      "生成图片中(总共400张): 0it [00:00, ?it/s]/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "生成图片中(总共400张): 60it [00:26,  2.26it/s]\n",
      "Inception v3模型加载成功\n",
      "\n",
      "=== 计算FID分数 ===\n",
      "FID分数: 0.6071\n",
      "[W212 16:53:04.861847934 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
     ]
    }
   ],
   "source": [
    "!python 4.15_恒-基于14-去掉其中的MoE架构.py --n_epochs 40 --train_mode fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5a5a948-8de2-4808-af6d-d865fa287332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:22<00:00, 11.45s/it]\n",
      "已开启 text_encoder 梯度检查点 (Gradient Checkpointing)\n",
      "使用 Qwen 文本编码器并应用 LoRA，隐藏维度为 2048\n",
      "/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.16_遁-基于14-将UViT改为普通结构.py:343: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "检测到 train_mode=fresh，忽略已有模型并从头开始训练。\n",
      "  0%|                                                   | 0/260 [00:00<?, ?it/s]/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.16_遁-基于14-将UViT改为普通结构.py:431: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.96it/s]\n",
      "Finished epoch 0. Average of the last 100 loss values: 0.452278\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.69it/s]\n",
      "Finished epoch 1. Average of the last 100 loss values: 0.248043\n",
      "100%|█████████████████████████████████████████| 260/260 [00:52<00:00,  4.95it/s]\n",
      "Finished epoch 2. Average of the last 100 loss values: 0.245537\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.17it/s]\n",
      "Finished epoch 3. Average of the last 100 loss values: 0.184240\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.16it/s]\n",
      "Finished epoch 4. Average of the last 100 loss values: 0.113677\n",
      "100%|█████████████████████████████████████████| 260/260 [00:38<00:00,  6.78it/s]\n",
      "Finished epoch 5. Average of the last 100 loss values: 0.266563\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.26it/s]\n",
      "Finished epoch 6. Average of the last 100 loss values: 0.151054\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.23it/s]\n",
      "Finished epoch 7. Average of the last 100 loss values: 0.131088\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.64it/s]\n",
      "Finished epoch 8. Average of the last 100 loss values: 0.119962\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.98it/s]\n",
      "Finished epoch 9. Average of the last 100 loss values: 0.120281\n",
      "100%|█████████████████████████████████████████| 260/260 [00:50<00:00,  5.19it/s]\n",
      "Finished epoch 10. Average of the last 100 loss values: 0.154543\n",
      "100%|█████████████████████████████████████████| 260/260 [00:48<00:00,  5.35it/s]\n",
      "Finished epoch 11. Average of the last 100 loss values: 0.101471\n",
      "100%|█████████████████████████████████████████| 260/260 [00:38<00:00,  6.72it/s]\n",
      "Finished epoch 12. Average of the last 100 loss values: 0.110859\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.28it/s]\n",
      "Finished epoch 13. Average of the last 100 loss values: 0.197893\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.42it/s]\n",
      "Finished epoch 14. Average of the last 100 loss values: 0.085561\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.61it/s]\n",
      "Finished epoch 15. Average of the last 100 loss values: 0.085908\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.31it/s]\n",
      "Finished epoch 16. Average of the last 100 loss values: 0.111800\n",
      "100%|█████████████████████████████████████████| 260/260 [00:38<00:00,  6.76it/s]\n",
      "Finished epoch 17. Average of the last 100 loss values: 0.082228\n",
      "100%|█████████████████████████████████████████| 260/260 [00:50<00:00,  5.17it/s]\n",
      "Finished epoch 18. Average of the last 100 loss values: 0.093931\n",
      "100%|█████████████████████████████████████████| 260/260 [00:47<00:00,  5.44it/s]\n",
      "Finished epoch 19. Average of the last 100 loss values: 0.096703\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.62it/s]\n",
      "Finished epoch 20. Average of the last 100 loss values: 0.087997\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.36it/s]\n",
      "Finished epoch 21. Average of the last 100 loss values: 0.102368\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.40it/s]\n",
      "Finished epoch 22. Average of the last 100 loss values: 0.119465\n",
      "100%|█████████████████████████████████████████| 260/260 [00:38<00:00,  6.84it/s]\n",
      "Finished epoch 23. Average of the last 100 loss values: 0.073524\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.31it/s]\n",
      "Finished epoch 24. Average of the last 100 loss values: 0.116536\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.31it/s]\n",
      "Finished epoch 25. Average of the last 100 loss values: 0.064469\n",
      "100%|█████████████████████████████████████████| 260/260 [00:52<00:00,  4.97it/s]\n",
      "Finished epoch 26. Average of the last 100 loss values: 0.097454\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.70it/s]\n",
      "Finished epoch 27. Average of the last 100 loss values: 0.061313\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.29it/s]\n",
      "Finished epoch 28. Average of the last 100 loss values: 0.090825\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.66it/s]\n",
      "Finished epoch 29. Average of the last 100 loss values: 0.065987\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.42it/s]\n",
      "Finished epoch 30. Average of the last 100 loss values: 0.123552\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.31it/s]\n",
      "Finished epoch 31. Average of the last 100 loss values: 0.070831\n",
      "100%|█████████████████████████████████████████| 260/260 [00:38<00:00,  6.79it/s]\n",
      "Finished epoch 32. Average of the last 100 loss values: 0.131995\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.26it/s]\n",
      "Finished epoch 33. Average of the last 100 loss values: 0.071960\n",
      "100%|█████████████████████████████████████████| 260/260 [00:48<00:00,  5.38it/s]\n",
      "Finished epoch 34. Average of the last 100 loss values: 0.070273\n",
      "100%|█████████████████████████████████████████| 260/260 [00:50<00:00,  5.16it/s]\n",
      "Finished epoch 35. Average of the last 100 loss values: 0.077816\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.60it/s]\n",
      "Finished epoch 36. Average of the last 100 loss values: 0.093128\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.11it/s]\n",
      "Finished epoch 37. Average of the last 100 loss values: 0.059826\n",
      "100%|█████████████████████████████████████████| 260/260 [00:38<00:00,  6.83it/s]\n",
      "Finished epoch 38. Average of the last 100 loss values: 0.099340\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.28it/s]\n",
      "Finished epoch 39. Average of the last 100 loss values: 0.090365\n",
      "生成图片中(总共400张): 0it [00:00, ?it/s]/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "生成图片中(总共400张): 60it [00:21,  2.75it/s]\n",
      "Inception v3模型加载成功\n",
      "\n",
      "=== 计算FID分数 ===\n",
      "FID分数: 2.1363\n",
      "[W212 17:23:38.084839766 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
     ]
    }
   ],
   "source": [
    "!python 4.16_遁-基于14-将UViT改为普通结构.py --n_epochs 40 --train_mode fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00147c2b-97c2-4ace-a34d-ec016a851d9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:19<00:00,  9.94s/it]\n",
      "已开启 text_encoder 梯度检查点 (Gradient Checkpointing)\n",
      "使用 Qwen 文本编码器并应用 LoRA，隐藏维度为 2048\n",
      "/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.17_大壮-基于14-去掉MoE和UViT.py:343: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "检测到 train_mode=fresh，忽略已有模型并从头开始训练。\n",
      "  0%|                                                   | 0/260 [00:00<?, ?it/s]/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.17_大壮-基于14-去掉MoE和UViT.py:431: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.09it/s]\n",
      "Finished epoch 0. Average of the last 100 loss values: 0.452184\n",
      "100%|█████████████████████████████████████████| 260/260 [00:48<00:00,  5.40it/s]\n",
      "Finished epoch 1. Average of the last 100 loss values: 0.309221\n",
      "100%|█████████████████████████████████████████| 260/260 [00:48<00:00,  5.34it/s]\n",
      "Finished epoch 2. Average of the last 100 loss values: 0.291173\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.62it/s]\n",
      "Finished epoch 3. Average of the last 100 loss values: 0.161143\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.24it/s]\n",
      "Finished epoch 4. Average of the last 100 loss values: 0.193502\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.31it/s]\n",
      "Finished epoch 5. Average of the last 100 loss values: 0.180283\n",
      "100%|█████████████████████████████████████████| 260/260 [00:38<00:00,  6.76it/s]\n",
      "Finished epoch 6. Average of the last 100 loss values: 0.073144\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.09it/s]\n",
      "Finished epoch 7. Average of the last 100 loss values: 0.109054\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.59it/s]\n",
      "Finished epoch 8. Average of the last 100 loss values: 0.113330\n",
      "100%|█████████████████████████████████████████| 260/260 [00:51<00:00,  5.05it/s]\n",
      "Finished epoch 9. Average of the last 100 loss values: 0.133301\n",
      "100%|█████████████████████████████████████████| 260/260 [00:48<00:00,  5.32it/s]\n",
      "Finished epoch 10. Average of the last 100 loss values: 0.142757\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.10it/s]\n",
      "Finished epoch 11. Average of the last 100 loss values: 0.119580\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.62it/s]\n",
      "Finished epoch 12. Average of the last 100 loss values: 0.100054\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.27it/s]\n",
      "Finished epoch 13. Average of the last 100 loss values: 0.135326\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.23it/s]\n",
      "Finished epoch 14. Average of the last 100 loss values: 0.114825\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.57it/s]\n",
      "Finished epoch 15. Average of the last 100 loss values: 0.140476\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.21it/s]\n",
      "Finished epoch 16. Average of the last 100 loss values: 0.092763\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.71it/s]\n",
      "Finished epoch 17. Average of the last 100 loss values: 0.078690\n",
      "100%|█████████████████████████████████████████| 260/260 [00:50<00:00,  5.17it/s]\n",
      "Finished epoch 18. Average of the last 100 loss values: 0.098110\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.09it/s]\n",
      "Finished epoch 19. Average of the last 100 loss values: 0.082917\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.13it/s]\n",
      "Finished epoch 20. Average of the last 100 loss values: 0.068699\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.25it/s]\n",
      "Finished epoch 21. Average of the last 100 loss values: 0.095639\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.48it/s]\n",
      "Finished epoch 22. Average of the last 100 loss values: 0.100016\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.29it/s]\n",
      "Finished epoch 23. Average of the last 100 loss values: 0.089528\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.99it/s]\n",
      "Finished epoch 24. Average of the last 100 loss values: 0.078892\n",
      "100%|█████████████████████████████████████████| 260/260 [00:49<00:00,  5.21it/s]\n",
      "Finished epoch 25. Average of the last 100 loss values: 0.061572\n",
      "100%|█████████████████████████████████████████| 260/260 [00:46<00:00,  5.54it/s]\n",
      "Finished epoch 26. Average of the last 100 loss values: 0.106215\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.14it/s]\n",
      "Finished epoch 27. Average of the last 100 loss values: 0.076853\n",
      "100%|█████████████████████████████████████████| 260/260 [00:38<00:00,  6.69it/s]\n",
      "Finished epoch 28. Average of the last 100 loss values: 0.070972\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.27it/s]\n",
      "Finished epoch 29. Average of the last 100 loss values: 0.092921\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.19it/s]\n",
      "Finished epoch 30. Average of the last 100 loss values: 0.081701\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.66it/s]\n",
      "Finished epoch 31. Average of the last 100 loss values: 0.115383\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.17it/s]\n",
      "Finished epoch 32. Average of the last 100 loss values: 0.094444\n",
      "100%|█████████████████████████████████████████| 260/260 [00:51<00:00,  5.08it/s]\n",
      "Finished epoch 33. Average of the last 100 loss values: 0.064039\n",
      "100%|█████████████████████████████████████████| 260/260 [00:49<00:00,  5.25it/s]\n",
      "Finished epoch 34. Average of the last 100 loss values: 0.080664\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.15it/s]\n",
      "Finished epoch 35. Average of the last 100 loss values: 0.084168\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.12it/s]\n",
      "Finished epoch 36. Average of the last 100 loss values: 0.080639\n",
      "100%|█████████████████████████████████████████| 260/260 [00:38<00:00,  6.82it/s]\n",
      "Finished epoch 37. Average of the last 100 loss values: 0.105850\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.09it/s]\n",
      "Finished epoch 38. Average of the last 100 loss values: 0.063325\n",
      "100%|█████████████████████████████████████████| 260/260 [00:38<00:00,  6.76it/s]\n",
      "Finished epoch 39. Average of the last 100 loss values: 0.065248\n",
      "生成图片中(总共400张): 0it [00:00, ?it/s]/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "生成图片中(总共400张): 60it [00:24,  2.46it/s]\n",
      "Inception v3模型加载成功\n",
      "\n",
      "=== 计算FID分数 ===\n",
      "FID分数: 1.0081\n",
      "[W212 17:54:35.852275579 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
     ]
    }
   ],
   "source": [
    "!python 4.17_大壮-基于14-去掉MoE和UViT.py --n_epochs 40 --train_mode fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6ea6c26-821b-430b-9b43-3fbeaedb0c8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "已放开 BERT 的最后1层 encoder 和 pooler 进行训练\n",
      "/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.18_晋-基于9-文本编码器改为普通bert且不SFT.py:243: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "检测到 train_mode=fresh，忽略已有模型并从头开始训练。\n",
      "  0%|                                                   | 0/260 [00:00<?, ?it/s]/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.18_晋-基于9-文本编码器改为普通bert且不SFT.py:331: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.85it/s]\n",
      "Finished epoch 0. Average of the last 100 loss values: 0.084997\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.38it/s]\n",
      "Finished epoch 1. Average of the last 100 loss values: 0.079530\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  6.04it/s]\n",
      "Finished epoch 2. Average of the last 100 loss values: 0.060546\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.43it/s]\n",
      "Finished epoch 3. Average of the last 100 loss values: 0.087198\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  6.04it/s]\n",
      "Finished epoch 4. Average of the last 100 loss values: 0.071509\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.96it/s]\n",
      "Finished epoch 5. Average of the last 100 loss values: 0.061368\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.51it/s]\n",
      "Finished epoch 6. Average of the last 100 loss values: 0.073936\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.05it/s]\n",
      "Finished epoch 7. Average of the last 100 loss values: 0.039508\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.35it/s]\n",
      "Finished epoch 8. Average of the last 100 loss values: 0.048020\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.99it/s]\n",
      "Finished epoch 9. Average of the last 100 loss values: 0.050140\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.39it/s]\n",
      "Finished epoch 10. Average of the last 100 loss values: 0.040281\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.92it/s]\n",
      "Finished epoch 11. Average of the last 100 loss values: 0.050826\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.05it/s]\n",
      "Finished epoch 12. Average of the last 100 loss values: 0.061307\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.46it/s]\n",
      "Finished epoch 13. Average of the last 100 loss values: 0.046521\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  6.00it/s]\n",
      "Finished epoch 14. Average of the last 100 loss values: 0.049922\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.52it/s]\n",
      "Finished epoch 15. Average of the last 100 loss values: 0.040525\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  6.03it/s]\n",
      "Finished epoch 16. Average of the last 100 loss values: 0.034786\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.34it/s]\n",
      "Finished epoch 17. Average of the last 100 loss values: 0.042715\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.95it/s]\n",
      "Finished epoch 18. Average of the last 100 loss values: 0.044998\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  6.00it/s]\n",
      "Finished epoch 19. Average of the last 100 loss values: 0.046238\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.38it/s]\n",
      "Finished epoch 20. Average of the last 100 loss values: 0.053326\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  6.03it/s]\n",
      "Finished epoch 21. Average of the last 100 loss values: 0.046050\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.42it/s]\n",
      "Finished epoch 22. Average of the last 100 loss values: 0.052822\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.05it/s]\n",
      "Finished epoch 23. Average of the last 100 loss values: 0.057645\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.52it/s]\n",
      "Finished epoch 24. Average of the last 100 loss values: 0.042760\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.93it/s]\n",
      "Finished epoch 25. Average of the last 100 loss values: 0.035769\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.99it/s]\n",
      "Finished epoch 26. Average of the last 100 loss values: 0.051455\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.37it/s]\n",
      "Finished epoch 27. Average of the last 100 loss values: 0.047387\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.97it/s]\n",
      "Finished epoch 28. Average of the last 100 loss values: 0.037449\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.46it/s]\n",
      "Finished epoch 29. Average of the last 100 loss values: 0.031427\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  6.00it/s]\n",
      "Finished epoch 30. Average of the last 100 loss values: 0.030663\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.43it/s]\n",
      "Finished epoch 31. Average of the last 100 loss values: 0.032668\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.08it/s]\n",
      "Finished epoch 32. Average of the last 100 loss values: 0.026443\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.99it/s]\n",
      "Finished epoch 33. Average of the last 100 loss values: 0.049641\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.36it/s]\n",
      "Finished epoch 34. Average of the last 100 loss values: 0.053372\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.92it/s]\n",
      "Finished epoch 35. Average of the last 100 loss values: 0.038863\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.46it/s]\n",
      "Finished epoch 36. Average of the last 100 loss values: 0.046953\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  6.03it/s]\n",
      "Finished epoch 37. Average of the last 100 loss values: 0.036648\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.44it/s]\n",
      "Finished epoch 38. Average of the last 100 loss values: 0.055937\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.95it/s]\n",
      "Finished epoch 39. Average of the last 100 loss values: 0.037346\n",
      "生成图片中(总共400张): 60it [04:50,  4.84s/it]\n",
      "Inception v3模型加载成功\n",
      "\n",
      "=== 计算FID分数 ===\n",
      "FID分数: 1.4899\n",
      "[W212 18:27:48.459475950 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
     ]
    }
   ],
   "source": [
    "!python 4.18_晋-基于9-文本编码器改为普通bert且不SFT.py --n_epochs 40 --train_mode fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d0cfd8d-7a03-43ed-8ea2-b40dc0c0d0c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "已放开 BERT 的最后3层 encoder 和 pooler 进行训练\n",
      "/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.19_明夷-基于18-文本编码器改为普通bert且轻SFT.py:243: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "检测到 train_mode=fresh，忽略已有模型并从头开始训练。\n",
      "  0%|                                                   | 0/260 [00:00<?, ?it/s]/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.19_明夷-基于18-文本编码器改为普通bert且轻SFT.py:331: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.23it/s]\n",
      "Finished epoch 0. Average of the last 100 loss values: 0.118281\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.91it/s]\n",
      "Finished epoch 1. Average of the last 100 loss values: 0.078173\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.38it/s]\n",
      "Finished epoch 2. Average of the last 100 loss values: 0.070845\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.88it/s]\n",
      "Finished epoch 3. Average of the last 100 loss values: 0.059008\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.85it/s]\n",
      "Finished epoch 4. Average of the last 100 loss values: 0.064161\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.21it/s]\n",
      "Finished epoch 5. Average of the last 100 loss values: 0.057212\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.90it/s]\n",
      "Finished epoch 6. Average of the last 100 loss values: 0.058811\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.32it/s]\n",
      "Finished epoch 7. Average of the last 100 loss values: 0.048723\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.89it/s]\n",
      "Finished epoch 8. Average of the last 100 loss values: 0.050483\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.30it/s]\n",
      "Finished epoch 9. Average of the last 100 loss values: 0.055595\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.92it/s]\n",
      "Finished epoch 10. Average of the last 100 loss values: 0.046764\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.33it/s]\n",
      "Finished epoch 11. Average of the last 100 loss values: 0.050821\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.77it/s]\n",
      "Finished epoch 12. Average of the last 100 loss values: 0.044214\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.22it/s]\n",
      "Finished epoch 13. Average of the last 100 loss values: 0.070713\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.88it/s]\n",
      "Finished epoch 14. Average of the last 100 loss values: 0.048972\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.29it/s]\n",
      "Finished epoch 15. Average of the last 100 loss values: 0.040708\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.92it/s]\n",
      "Finished epoch 16. Average of the last 100 loss values: 0.033560\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.86it/s]\n",
      "Finished epoch 17. Average of the last 100 loss values: 0.044540\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.36it/s]\n",
      "Finished epoch 18. Average of the last 100 loss values: 0.039662\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.93it/s]\n",
      "Finished epoch 19. Average of the last 100 loss values: 0.041217\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.21it/s]\n",
      "Finished epoch 20. Average of the last 100 loss values: 0.060804\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.83it/s]\n",
      "Finished epoch 21. Average of the last 100 loss values: 0.056418\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.25it/s]\n",
      "Finished epoch 22. Average of the last 100 loss values: 0.061522\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.85it/s]\n",
      "Finished epoch 23. Average of the last 100 loss values: 0.037442\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.37it/s]\n",
      "Finished epoch 24. Average of the last 100 loss values: 0.036505\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.86it/s]\n",
      "Finished epoch 25. Average of the last 100 loss values: 0.038123\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.29it/s]\n",
      "Finished epoch 26. Average of the last 100 loss values: 0.047947\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.92it/s]\n",
      "Finished epoch 27. Average of the last 100 loss values: 0.032680\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.32it/s]\n",
      "Finished epoch 28. Average of the last 100 loss values: 0.036592\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.78it/s]\n",
      "Finished epoch 29. Average of the last 100 loss values: 0.035002\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.83it/s]\n",
      "Finished epoch 30. Average of the last 100 loss values: 0.044363\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.34it/s]\n",
      "Finished epoch 31. Average of the last 100 loss values: 0.036547\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.89it/s]\n",
      "Finished epoch 32. Average of the last 100 loss values: 0.034472\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.33it/s]\n",
      "Finished epoch 33. Average of the last 100 loss values: 0.031272\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.86it/s]\n",
      "Finished epoch 34. Average of the last 100 loss values: 0.048481\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.36it/s]\n",
      "Finished epoch 35. Average of the last 100 loss values: 0.041397\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.91it/s]\n",
      "Finished epoch 36. Average of the last 100 loss values: 0.042721\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.22it/s]\n",
      "Finished epoch 37. Average of the last 100 loss values: 0.049587\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.81it/s]\n",
      "Finished epoch 38. Average of the last 100 loss values: 0.052491\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.09it/s]\n",
      "Finished epoch 39. Average of the last 100 loss values: 0.043749\n",
      "生成图片中(总共400张): 60it [04:50,  4.85s/it]\n",
      "Inception v3模型加载成功\n",
      "\n",
      "=== 计算FID分数 ===\n",
      "FID分数: 2.7140\n",
      "[W212 19:01:30.526166200 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
     ]
    }
   ],
   "source": [
    "!python 4.19_明夷-基于18-文本编码器改为普通bert且轻SFT.py --n_epochs 40  --train_mode fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d45a4695-828e-4427-ade5-55bb038b2e63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "已放开 BERT 的所有层进行训练\n",
      "/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.20_家人-基于18-文本编码器改为普通bert且重SFT.py:237: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "检测到 train_mode=fresh，忽略已有模型并从头开始训练。\n",
      "  0%|                                                   | 0/260 [00:00<?, ?it/s]/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.20_家人-基于18-文本编码器改为普通bert且重SFT.py:325: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "100%|█████████████████████████████████████████| 260/260 [00:46<00:00,  5.58it/s]\n",
      "Finished epoch 0. Average of the last 100 loss values: 0.108607\n",
      "100%|█████████████████████████████████████████| 260/260 [00:48<00:00,  5.34it/s]\n",
      "Finished epoch 1. Average of the last 100 loss values: 0.092867\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.71it/s]\n",
      "Finished epoch 2. Average of the last 100 loss values: 0.083382\n",
      "100%|█████████████████████████████████████████| 260/260 [00:47<00:00,  5.48it/s]\n",
      "Finished epoch 3. Average of the last 100 loss values: 0.060776\n",
      "100%|█████████████████████████████████████████| 260/260 [00:48<00:00,  5.33it/s]\n",
      "Finished epoch 4. Average of the last 100 loss values: 0.069148\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.69it/s]\n",
      "Finished epoch 5. Average of the last 100 loss values: 0.076540\n",
      "100%|█████████████████████████████████████████| 260/260 [00:49<00:00,  5.28it/s]\n",
      "Finished epoch 6. Average of the last 100 loss values: 0.059228\n",
      "100%|█████████████████████████████████████████| 260/260 [00:46<00:00,  5.63it/s]\n",
      "Finished epoch 7. Average of the last 100 loss values: 0.058929\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.67it/s]\n",
      "Finished epoch 8. Average of the last 100 loss values: 0.073193\n",
      "100%|█████████████████████████████████████████| 260/260 [00:48<00:00,  5.32it/s]\n",
      "Finished epoch 9. Average of the last 100 loss values: 0.059418\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.70it/s]\n",
      "Finished epoch 10. Average of the last 100 loss values: 0.050513\n",
      "100%|█████████████████████████████████████████| 260/260 [00:49<00:00,  5.29it/s]\n",
      "Finished epoch 11. Average of the last 100 loss values: 0.048503\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.69it/s]\n",
      "Finished epoch 12. Average of the last 100 loss values: 0.072397\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.67it/s]\n",
      "Finished epoch 13. Average of the last 100 loss values: 0.043765\n",
      "100%|█████████████████████████████████████████| 260/260 [00:49<00:00,  5.29it/s]\n",
      "Finished epoch 14. Average of the last 100 loss values: 0.058045\n",
      "100%|█████████████████████████████████████████| 260/260 [00:46<00:00,  5.63it/s]\n",
      "Finished epoch 15. Average of the last 100 loss values: 0.052819\n",
      "100%|█████████████████████████████████████████| 260/260 [00:49<00:00,  5.30it/s]\n",
      "Finished epoch 16. Average of the last 100 loss values: 0.030750\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.69it/s]\n",
      "Finished epoch 17. Average of the last 100 loss values: 0.037585\n",
      "100%|█████████████████████████████████████████| 260/260 [00:46<00:00,  5.65it/s]\n",
      "Finished epoch 18. Average of the last 100 loss values: 0.042849\n",
      "100%|█████████████████████████████████████████| 260/260 [00:48<00:00,  5.34it/s]\n",
      "Finished epoch 19. Average of the last 100 loss values: 0.066341\n",
      "100%|█████████████████████████████████████████| 260/260 [00:46<00:00,  5.64it/s]\n",
      "Finished epoch 20. Average of the last 100 loss values: 0.036365\n",
      "100%|█████████████████████████████████████████| 260/260 [00:46<00:00,  5.63it/s]\n",
      "Finished epoch 21. Average of the last 100 loss values: 0.035214\n",
      "100%|█████████████████████████████████████████| 260/260 [00:49<00:00,  5.29it/s]\n",
      "Finished epoch 22. Average of the last 100 loss values: 0.041849\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.66it/s]\n",
      "Finished epoch 23. Average of the last 100 loss values: 0.045879\n",
      "100%|█████████████████████████████████████████| 260/260 [00:48<00:00,  5.32it/s]\n",
      "Finished epoch 24. Average of the last 100 loss values: 0.028372\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.71it/s]\n",
      "Finished epoch 25. Average of the last 100 loss values: 0.041378\n",
      "100%|█████████████████████████████████████████| 260/260 [00:46<00:00,  5.63it/s]\n",
      "Finished epoch 26. Average of the last 100 loss values: 0.035835\n",
      "100%|█████████████████████████████████████████| 260/260 [00:48<00:00,  5.36it/s]\n",
      "Finished epoch 27. Average of the last 100 loss values: 0.058950\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.68it/s]\n",
      "Finished epoch 28. Average of the last 100 loss values: 0.047777\n",
      "100%|█████████████████████████████████████████| 260/260 [00:49<00:00,  5.24it/s]\n",
      "Finished epoch 29. Average of the last 100 loss values: 0.029355\n",
      "100%|█████████████████████████████████████████| 260/260 [00:46<00:00,  5.64it/s]\n",
      "Finished epoch 30. Average of the last 100 loss values: 0.031876\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.67it/s]\n",
      "Finished epoch 31. Average of the last 100 loss values: 0.025109\n",
      "100%|█████████████████████████████████████████| 260/260 [00:48<00:00,  5.33it/s]\n",
      "Finished epoch 32. Average of the last 100 loss values: 0.035368\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.67it/s]\n",
      "Finished epoch 33. Average of the last 100 loss values: 0.039818\n",
      "100%|█████████████████████████████████████████| 260/260 [00:48<00:00,  5.31it/s]\n",
      "Finished epoch 34. Average of the last 100 loss values: 0.042466\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.72it/s]\n",
      "Finished epoch 35. Average of the last 100 loss values: 0.035297\n",
      "100%|█████████████████████████████████████████| 260/260 [00:49<00:00,  5.29it/s]\n",
      "Finished epoch 36. Average of the last 100 loss values: 0.027276\n",
      "100%|█████████████████████████████████████████| 260/260 [00:46<00:00,  5.62it/s]\n",
      "Finished epoch 37. Average of the last 100 loss values: 0.030974\n",
      "100%|█████████████████████████████████████████| 260/260 [00:46<00:00,  5.60it/s]\n",
      "Finished epoch 38. Average of the last 100 loss values: 0.024918\n",
      "100%|█████████████████████████████████████████| 260/260 [00:48<00:00,  5.31it/s]\n",
      "Finished epoch 39. Average of the last 100 loss values: 0.036868\n",
      "生成图片中(总共400张): 60it [04:50,  4.84s/it]\n",
      "Inception v3模型加载成功\n",
      "\n",
      "=== 计算FID分数 ===\n",
      "FID分数: 0.6340\n",
      "[W212 19:38:03.943227835 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
     ]
    }
   ],
   "source": [
    "!python 4.20_家人-基于18-文本编码器改为普通bert且重SFT.py --n_epochs 40 --train_mode fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bbecdc2-bd2f-43ee-b30f-127db08ac3c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.18s/it]\n",
      "已开启 text_encoder 梯度检查点 (Gradient Checkpointing)\n",
      "使用 Qwen 文本编码器并应用 LoRA，隐藏维度为 2048\n",
      "/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.21_睽-基于15-尝试transfusion.py:355: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "检测到 train_mode=fresh，忽略已有模型并从头开始训练。\n",
      "  0%|                                                   | 0/260 [00:00<?, ?it/s]/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.21_睽-基于15-尝试transfusion.py:443: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.73it/s]\n",
      "Finished epoch 0. Average of the last 100 loss values: 1.069768\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.98it/s]\n",
      "Finished epoch 1. Average of the last 100 loss values: 1.021672\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.12it/s]\n",
      "Finished epoch 2. Average of the last 100 loss values: 0.924468\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.39it/s]\n",
      "Finished epoch 3. Average of the last 100 loss values: 0.655183\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.08it/s]\n",
      "Finished epoch 4. Average of the last 100 loss values: 0.893481\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.59it/s]\n",
      "Finished epoch 5. Average of the last 100 loss values: 0.858776\n",
      "100%|█████████████████████████████████████████| 260/260 [00:56<00:00,  4.62it/s]\n",
      "Finished epoch 6. Average of the last 100 loss values: 0.960788\n",
      "100%|█████████████████████████████████████████| 260/260 [00:51<00:00,  5.06it/s]\n",
      "Finished epoch 7. Average of the last 100 loss values: 0.958066\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.54it/s]\n",
      "Finished epoch 8. Average of the last 100 loss values: 1.076620\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.13it/s]\n",
      "Finished epoch 9. Average of the last 100 loss values: 0.826052\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.10it/s]\n",
      "Finished epoch 10. Average of the last 100 loss values: 0.840441\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.46it/s]\n",
      "Finished epoch 11. Average of the last 100 loss values: 0.993514\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.07it/s]\n",
      "Finished epoch 12. Average of the last 100 loss values: 0.891887\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.51it/s]\n",
      "Finished epoch 13. Average of the last 100 loss values: 0.779125\n",
      "100%|█████████████████████████████████████████| 260/260 [00:55<00:00,  4.65it/s]\n",
      "Finished epoch 14. Average of the last 100 loss values: 0.839458\n",
      "100%|█████████████████████████████████████████| 260/260 [00:51<00:00,  5.07it/s]\n",
      "Finished epoch 15. Average of the last 100 loss values: 0.881125\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.68it/s]\n",
      "Finished epoch 16. Average of the last 100 loss values: 0.839448\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.96it/s]\n",
      "Finished epoch 17. Average of the last 100 loss values: 0.814566\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.63it/s]\n",
      "Finished epoch 18. Average of the last 100 loss values: 0.612693\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.80it/s]\n",
      "Finished epoch 19. Average of the last 100 loss values: 0.755446\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.55it/s]\n",
      "Finished epoch 20. Average of the last 100 loss values: 0.635022\n",
      "100%|█████████████████████████████████████████| 260/260 [00:52<00:00,  4.94it/s]\n",
      "Finished epoch 21. Average of the last 100 loss values: 0.764956\n",
      "100%|█████████████████████████████████████████| 260/260 [00:54<00:00,  4.78it/s]\n",
      "Finished epoch 22. Average of the last 100 loss values: 0.658313\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.99it/s]\n",
      "Finished epoch 23. Average of the last 100 loss values: 0.779049\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.85it/s]\n",
      "Finished epoch 24. Average of the last 100 loss values: 0.772809\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.65it/s]\n",
      "Finished epoch 25. Average of the last 100 loss values: 0.800837\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.72it/s]\n",
      "Finished epoch 26. Average of the last 100 loss values: 0.726227\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.52it/s]\n",
      "Finished epoch 27. Average of the last 100 loss values: 0.618517\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.14it/s]\n",
      "Finished epoch 28. Average of the last 100 loss values: 0.619570\n",
      "100%|█████████████████████████████████████████| 260/260 [00:53<00:00,  4.89it/s]\n",
      "Finished epoch 29. Average of the last 100 loss values: 0.531942\n",
      "100%|█████████████████████████████████████████| 260/260 [00:51<00:00,  5.03it/s]\n",
      "Finished epoch 30. Average of the last 100 loss values: 0.470476\n",
      "100%|█████████████████████████████████████████| 260/260 [00:46<00:00,  5.64it/s]\n",
      "Finished epoch 31. Average of the last 100 loss values: 0.441273\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.31it/s]\n",
      "Finished epoch 32. Average of the last 100 loss values: 0.373670\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.20it/s]\n",
      "Finished epoch 33. Average of the last 100 loss values: 0.252135\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.96it/s]\n",
      "Finished epoch 34. Average of the last 100 loss values: 0.310700\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.54it/s]\n",
      "Finished epoch 35. Average of the last 100 loss values: 0.304544\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.14it/s]\n",
      "Finished epoch 36. Average of the last 100 loss values: 0.283985\n",
      "100%|█████████████████████████████████████████| 260/260 [00:51<00:00,  5.05it/s]\n",
      "Finished epoch 37. Average of the last 100 loss values: 0.244670\n",
      "100%|█████████████████████████████████████████| 260/260 [00:52<00:00,  4.95it/s]\n",
      "Finished epoch 38. Average of the last 100 loss values: 0.172474\n",
      "100%|█████████████████████████████████████████| 260/260 [00:46<00:00,  5.61it/s]\n",
      "Finished epoch 39. Average of the last 100 loss values: 0.209353\n",
      "生成图片中(总共400张): 0it [00:00, ?it/s]/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "生成图片中(总共400张): 60it [00:11,  5.37it/s]\n",
      "Inception v3模型加载成功\n",
      "\n",
      "=== 计算FID分数 ===\n",
      "FID分数: 2.4078\n",
      "[W212 20:10:14.493096744 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
     ]
    }
   ],
   "source": [
    "!python 4.21_睽-基于15-尝试transfusion.py --n_epochs 40 --train_mode fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6918f1a9-7590-402a-b7ae-65eb824e4596",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:12<00:00,  6.09s/it]\n",
      "已开启 text_encoder 梯度检查点 (Gradient Checkpointing)\n",
      "使用 Qwen 文本编码器并应用 LoRA，隐藏维度为 2048\n",
      "/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.21_睽_1-基于21-尝试修复马赛克的问题.py:363: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "检测到 train_mode=fresh，忽略已有模型并从头开始训练。\n",
      "  0%|                                                   | 0/260 [00:00<?, ?it/s]/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.21_睽_1-基于21-尝试修复马赛克的问题.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.25it/s]\n",
      "Finished epoch 0. Average of the last 100 loss values: 0.970093\n",
      "100%|█████████████████████████████████████████| 260/260 [00:51<00:00,  5.05it/s]\n",
      "Finished epoch 1. Average of the last 100 loss values: 0.922162\n",
      "100%|█████████████████████████████████████████| 260/260 [00:51<00:00,  5.05it/s]\n",
      "Finished epoch 2. Average of the last 100 loss values: 0.792607\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.16it/s]\n",
      "Finished epoch 3. Average of the last 100 loss values: 0.924561\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.82it/s]\n",
      "Finished epoch 4. Average of the last 100 loss values: 0.855433\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.24it/s]\n",
      "Finished epoch 5. Average of the last 100 loss values: 0.946718\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.58it/s]\n",
      "Finished epoch 6. Average of the last 100 loss values: 0.859093\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.06it/s]\n",
      "Finished epoch 7. Average of the last 100 loss values: 0.843131\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.61it/s]\n",
      "Finished epoch 8. Average of the last 100 loss values: 0.739639\n",
      "100%|█████████████████████████████████████████| 260/260 [00:48<00:00,  5.34it/s]\n",
      "Finished epoch 9. Average of the last 100 loss values: 0.962957\n",
      "100%|█████████████████████████████████████████| 260/260 [00:51<00:00,  5.04it/s]\n",
      "Finished epoch 10. Average of the last 100 loss values: 0.987189\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.72it/s]\n",
      "Finished epoch 11. Average of the last 100 loss values: 0.854784\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.72it/s]\n",
      "Finished epoch 12. Average of the last 100 loss values: 0.999955\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.34it/s]\n",
      "Finished epoch 13. Average of the last 100 loss values: 0.840600\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.32it/s]\n",
      "Finished epoch 14. Average of the last 100 loss values: 0.801746\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.30it/s]\n",
      "Finished epoch 15. Average of the last 100 loss values: 0.833208\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.23it/s]\n",
      "Finished epoch 16. Average of the last 100 loss values: 0.878559\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.75it/s]\n",
      "Finished epoch 17. Average of the last 100 loss values: 0.959274\n",
      "100%|█████████████████████████████████████████| 260/260 [00:53<00:00,  4.90it/s]\n",
      "Finished epoch 18. Average of the last 100 loss values: 0.965800\n",
      "100%|█████████████████████████████████████████| 260/260 [00:47<00:00,  5.43it/s]\n",
      "Finished epoch 19. Average of the last 100 loss values: 0.869076\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.35it/s]\n",
      "Finished epoch 20. Average of the last 100 loss values: 0.845905\n",
      "100%|█████████████████████████████████████████| 260/260 [00:39<00:00,  6.54it/s]\n",
      "Finished epoch 21. Average of the last 100 loss values: 0.754497\n",
      "100%|█████████████████████████████████████████| 260/260 [00:44<00:00,  5.88it/s]\n",
      "Finished epoch 22. Average of the last 100 loss values: 0.879606\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.27it/s]\n",
      "Finished epoch 23. Average of the last 100 loss values: 1.117952\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.14it/s]\n",
      "Finished epoch 24. Average of the last 100 loss values: 0.892750\n",
      "100%|█████████████████████████████████████████| 260/260 [00:52<00:00,  4.91it/s]\n",
      "Finished epoch 25. Average of the last 100 loss values: 0.823253\n",
      "100%|█████████████████████████████████████████| 260/260 [00:48<00:00,  5.35it/s]\n",
      "Finished epoch 26. Average of the last 100 loss values: 0.819595\n",
      "100%|█████████████████████████████████████████| 260/260 [00:46<00:00,  5.59it/s]\n",
      "Finished epoch 27. Average of the last 100 loss values: 0.987330\n",
      "100%|█████████████████████████████████████████| 260/260 [00:40<00:00,  6.45it/s]\n",
      "Finished epoch 28. Average of the last 100 loss values: 0.977912\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.31it/s]\n",
      "Finished epoch 29. Average of the last 100 loss values: 0.955821\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.06it/s]\n",
      "Finished epoch 30. Average of the last 100 loss values: 0.730698\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.29it/s]\n",
      "Finished epoch 31. Average of the last 100 loss values: 0.809467\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.23it/s]\n",
      "Finished epoch 32. Average of the last 100 loss values: 0.935646\n",
      "100%|█████████████████████████████████████████| 260/260 [00:53<00:00,  4.90it/s]\n",
      "Finished epoch 33. Average of the last 100 loss values: 0.910921\n",
      "100%|█████████████████████████████████████████| 260/260 [00:49<00:00,  5.22it/s]\n",
      "Finished epoch 34. Average of the last 100 loss values: 0.879731\n",
      "100%|█████████████████████████████████████████| 260/260 [00:47<00:00,  5.48it/s]\n",
      "Finished epoch 35. Average of the last 100 loss values: 0.831905\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.31it/s]\n",
      "Finished epoch 36. Average of the last 100 loss values: 0.670682\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.33it/s]\n",
      "Finished epoch 37. Average of the last 100 loss values: 0.844546\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.98it/s]\n",
      "Finished epoch 38. Average of the last 100 loss values: 0.747873\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.31it/s]\n",
      "Finished epoch 39. Average of the last 100 loss values: 0.764533\n",
      "生成图片中(总共400张): 0it [00:00, ?it/s]/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "生成图片中(总共400张): 60it [00:16,  3.65it/s]\n",
      "Inception v3模型加载成功\n",
      "\n",
      "=== 计算FID分数 ===\n",
      "FID分数: 1.1961\n",
      "[W212 21:07:27.037979779 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
     ]
    }
   ],
   "source": [
    "!python 4.21_睽_1-基于21-尝试修复马赛克的问题.py --n_epochs 40 --train_mode fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "128bb236-a0ee-43a4-af01-b1c9142e286c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:12<00:00,  6.34s/it]\n",
      "已开启 text_encoder 梯度检查点 (Gradient Checkpointing)\n",
      "使用 Qwen 文本编码器并应用 LoRA，隐藏维度为 2048\n",
      "/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.22_蹇-基于15-增加lrscheduler.py:377: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "检测到 train_mode=fresh，忽略已有模型并从头开始训练。\n",
      "  0%|                                                   | 0/260 [00:00<?, ?it/s]/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.22_蹇-基于15-增加lrscheduler.py:472: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "100%|█████████████████████████████████████████| 260/260 [01:56<00:00,  2.24it/s]\n",
      "Finished epoch 0. Average of the last 100 loss values: 0.480235\n",
      "Current LR: 0.0001\n",
      "100%|█████████████████████████████████████████| 260/260 [01:53<00:00,  2.28it/s]\n",
      "Finished epoch 1. Average of the last 100 loss values: 0.230325\n",
      "Current LR: 0.0001\n",
      "100%|█████████████████████████████████████████| 260/260 [01:54<00:00,  2.28it/s]\n",
      "Finished epoch 2. Average of the last 100 loss values: 0.195225\n",
      "Current LR: 0.0001\n",
      "100%|█████████████████████████████████████████| 260/260 [01:54<00:00,  2.27it/s]\n",
      "Finished epoch 3. Average of the last 100 loss values: 0.152610\n",
      "Current LR: 0.0001\n",
      "100%|█████████████████████████████████████████| 260/260 [01:53<00:00,  2.28it/s]\n",
      "Finished epoch 4. Average of the last 100 loss values: 0.194166\n",
      "Current LR: 0.0001\n",
      "100%|█████████████████████████████████████████| 260/260 [01:54<00:00,  2.27it/s]\n",
      "Finished epoch 5. Average of the last 100 loss values: 0.117149\n",
      "Current LR: 0.0001\n",
      "100%|█████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "Finished epoch 6. Average of the last 100 loss values: 0.115802\n",
      "Current LR: 0.0001\n",
      "100%|█████████████████████████████████████████| 260/260 [01:34<00:00,  2.75it/s]\n",
      "Finished epoch 7. Average of the last 100 loss values: 0.110129\n",
      "Current LR: 0.0001\n",
      "100%|█████████████████████████████████████████| 260/260 [01:38<00:00,  2.63it/s]\n",
      "Finished epoch 8. Average of the last 100 loss values: 0.145554\n",
      "Current LR: 0.0001\n",
      "100%|█████████████████████████████████████████| 260/260 [01:00<00:00,  4.31it/s]\n",
      "Finished epoch 9. Average of the last 100 loss values: 0.114465\n",
      "Current LR: 0.0001\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.11it/s]\n",
      "Finished epoch 10. Average of the last 100 loss values: 0.128138\n",
      "Current LR: 0.0001\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  6.01it/s]\n",
      "Finished epoch 11. Average of the last 100 loss values: 0.158547\n",
      "Current LR: 0.0001\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.12it/s]\n",
      "Finished epoch 12. Average of the last 100 loss values: 0.071383\n",
      "Current LR: 0.0001\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.11it/s]\n",
      "Finished epoch 13. Average of the last 100 loss values: 0.064350\n",
      "Current LR: 0.0001\n",
      "100%|█████████████████████████████████████████| 260/260 [00:56<00:00,  4.57it/s]\n",
      "Finished epoch 14. Average of the last 100 loss values: 0.113800\n",
      "Current LR: 0.0001\n",
      "100%|█████████████████████████████████████████| 260/260 [00:51<00:00,  5.07it/s]\n",
      "Finished epoch 15. Average of the last 100 loss values: 0.075141\n",
      "Current LR: 0.0001\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  6.02it/s]\n",
      "Finished epoch 16. Average of the last 100 loss values: 0.084932\n",
      "Current LR: 0.0001\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.09it/s]\n",
      "Finished epoch 17. Average of the last 100 loss values: 0.112130\n",
      "Current LR: 0.0001\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.11it/s]\n",
      "Finished epoch 18. Average of the last 100 loss values: 0.081680\n",
      "Current LR: 0.0001\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.99it/s]\n",
      "Finished epoch 19. Average of the last 100 loss values: 0.096950\n",
      "Current LR: 5e-05\n",
      "100%|█████████████████████████████████████████| 260/260 [00:46<00:00,  5.60it/s]\n",
      "Finished epoch 20. Average of the last 100 loss values: 0.088749\n",
      "Current LR: 5e-05\n",
      "100%|█████████████████████████████████████████| 260/260 [00:52<00:00,  4.92it/s]\n",
      "Finished epoch 21. Average of the last 100 loss values: 0.078780\n",
      "Current LR: 5e-05\n",
      "100%|█████████████████████████████████████████| 260/260 [00:57<00:00,  4.53it/s]\n",
      "Finished epoch 22. Average of the last 100 loss values: 0.064123\n",
      "Current LR: 5e-05\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  5.91it/s]\n",
      "Finished epoch 23. Average of the last 100 loss values: 0.051881\n",
      "Current LR: 5e-05\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.07it/s]\n",
      "Finished epoch 24. Average of the last 100 loss values: 0.063568\n",
      "Current LR: 5e-05\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.12it/s]\n",
      "Finished epoch 25. Average of the last 100 loss values: 0.082838\n",
      "Current LR: 5e-05\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.07it/s]\n",
      "Finished epoch 26. Average of the last 100 loss values: 0.065432\n",
      "Current LR: 5e-05\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  6.02it/s]\n",
      "Finished epoch 27. Average of the last 100 loss values: 0.057570\n",
      "Current LR: 5e-05\n",
      "100%|█████████████████████████████████████████| 260/260 [00:50<00:00,  5.17it/s]\n",
      "Finished epoch 28. Average of the last 100 loss values: 0.087861\n",
      "Current LR: 5e-05\n",
      "100%|█████████████████████████████████████████| 260/260 [00:51<00:00,  5.07it/s]\n",
      "Finished epoch 29. Average of the last 100 loss values: 0.105674\n",
      "Current LR: 2.5e-05\n",
      "100%|█████████████████████████████████████████| 260/260 [00:45<00:00,  5.70it/s]\n",
      "Finished epoch 30. Average of the last 100 loss values: 0.076902\n",
      "Current LR: 2.5e-05\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  6.02it/s]\n",
      "Finished epoch 31. Average of the last 100 loss values: 0.077796\n",
      "Current LR: 2.5e-05\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.05it/s]\n",
      "Finished epoch 32. Average of the last 100 loss values: 0.076092\n",
      "Current LR: 2.5e-05\n",
      "100%|█████████████████████████████████████████| 260/260 [00:41<00:00,  6.21it/s]\n",
      "Finished epoch 33. Average of the last 100 loss values: 0.066424\n",
      "Current LR: 2.5e-05\n",
      "100%|█████████████████████████████████████████| 260/260 [00:42<00:00,  6.19it/s]\n",
      "Finished epoch 34. Average of the last 100 loss values: 0.062298\n",
      "Current LR: 2.5e-05\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  6.03it/s]\n",
      "Finished epoch 35. Average of the last 100 loss values: 0.106336\n",
      "Current LR: 1.25e-05\n",
      "100%|█████████████████████████████████████████| 260/260 [00:48<00:00,  5.31it/s]\n",
      "Finished epoch 36. Average of the last 100 loss values: 0.084031\n",
      "Current LR: 1.25e-05\n",
      "100%|█████████████████████████████████████████| 260/260 [00:51<00:00,  5.08it/s]\n",
      "Finished epoch 37. Average of the last 100 loss values: 0.055459\n",
      "Current LR: 1.25e-05\n",
      "100%|█████████████████████████████████████████| 260/260 [00:46<00:00,  5.60it/s]\n",
      "Finished epoch 38. Average of the last 100 loss values: 0.068113\n",
      "Current LR: 1.25e-05\n",
      "100%|█████████████████████████████████████████| 260/260 [00:43<00:00,  6.04it/s]\n",
      "Finished epoch 39. Average of the last 100 loss values: 0.081871\n",
      "Current LR: 1.25e-05\n",
      "生成图片中(总共400张): 0it [00:00, ?it/s]/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "生成图片中(总共400张): 60it [00:23,  2.54it/s]\n",
      "Inception v3模型加载成功\n",
      "\n",
      "=== 计算FID分数 ===\n",
      "FID分数: 0.1931\n",
      "[W214 12:58:34.106773559 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
     ]
    }
   ],
   "source": [
    "!python 4.22_蹇-基于15-增加lrscheduler.py --n_epochs 40 --train_mode fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29558891-d6b9-43a3-8441-97500f3ae3a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:23<00:00, 11.63s/it]\n",
      "已开启 text_encoder 梯度检查点 (Gradient Checkpointing)\n",
      "使用 Qwen 文本编码器并应用 LoRA，隐藏维度为 2048\n",
      "/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.23_解-基于22-用别的方式调scheduler.py:382: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "检测到 train_mode=fresh，忽略已有模型并从头开始训练。\n",
      "  0%|                                                   | 0/260 [00:00<?, ?it/s]/mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/4.23_解-基于22-用别的方式调scheduler.py:477: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "100%|█████████████████████████████████████████| 260/260 [00:47<00:00,  5.42it/s]\n",
      "Finished epoch 0. Average of the last 100 loss values: 0.517147\n",
      "Current LR: 8.888888888888889e-05\n",
      " 91%|█████████████████████████████████████▎   | 237/260 [00:39<00:03,  6.15it/s]"
     ]
    }
   ],
   "source": [
    "!python 4.23_解-基于22-用别的方式调scheduler.py --n_epochs 5 --train_mode fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec12a520-0d25-4d17-889b-4f1a51a669b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4b74b3-89fd-44e7-99a7-14f8b1de7ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae225199-c144-47ec-8f04-2f1020e70508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ce394c6-7da6-430e-a4dd-296c0b65216c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在扫描文件夹 (目标文件: page_6.html)...\n",
      "处理: 4.10_颐-基于9_txt和img用attn融合 ... 找到 10 张图片\n",
      "处理: 4.11_大过-基于9-去掉ema ... 找到 10 张图片\n",
      "处理: 4.12_坎-基于9-去掉snr ... 找到 10 张图片\n",
      "处理: 4.13_离-基于9-损失函数不用velocity ... 找到 10 张图片\n",
      "处理: 4.14_咸-基于9-将预训练DDPM改为UViT ... 找到 10 张图片\n",
      "处理: 4.15_恒-基于14-去掉其中的MoE架构 ... 找到 10 张图片\n",
      "处理: 4.16_遁-基于14-将UViT改为普通结构 ... 找到 10 张图片\n",
      "处理: 4.17_大壮-基于14-去掉MoE和UViT ... 找到 10 张图片\n",
      "处理: 4.18_晋-基于9-文本编码器改为普通bert且不SFT ... 找到 10 张图片\n",
      "处理: 4.19_明夷-基于18-文本编码器改为普通bert且轻SFT ... 找到 10 张图片\n",
      "处理: 4.20_家人-基于18-文本编码器改为普通bert且重SFT ... 找到 10 张图片\n",
      "处理: 4.21_睽-基于15-尝试transfusion ... 找到 10 张图片\n",
      "处理: 4.21_睽_1-基于21-尝试修复马赛克的问题 ... 找到 10 张图片\n",
      "处理: 4.9_大畜-基于8_文本利用率提升_增加额外通道 ... 找到 10 张图片\n",
      "对比文件已生成: /mnt/d/forCoding_code/Tianchi_MUGE/ECommerce-T2I/plan_4_1/comparison_result.html\n"
     ]
    }
   ],
   "source": [
    "!python x-横向对比生成图片.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f635a1-87fd-46f6-835d-3d99ae4a2883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7daefc-c80a-4052-8c9e-9f178af942d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "0d0657d4-7270-4995-a76d-ec877c55def1",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "!python 4.10_颐-基于9_txt和img用attn融合.py --n_epochs 2 # --train_mode \n",
    "!python 4.10_颐-基于9_txt和img用attn融合.py --n_epochs 2 # --train_mode \n",
    "!python 4.10_颐-基于9_txt和img用attn融合.py --n_epochs 2 # --train_mode "
   ]
  },
  {
   "cell_type": "raw",
   "id": "c197ff85-e595-4b21-8a5d-b407e137aa89",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "!python 4.11_大过-基于9-去掉ema.py --n_epochs 2 # --train_mode \n",
    "!python 4.11_大过-基于9-去掉ema.py --n_epochs 2 # --train_mode \n",
    "!python 4.11_大过-基于9-去掉ema.py --n_epochs 2 # --train_mode "
   ]
  },
  {
   "cell_type": "raw",
   "id": "17f2339a-4afc-4ca6-ab1d-3337850dbba4",
   "metadata": {},
   "source": [
    "# !mv /mnt/d/forCoding_data/Tianchi_MUGE/plan_4_1/trained_models/4.11_大畜-基于9-去掉ema_model.pth /mnt/d/forCoding_data/Tianchi_MUGE/plan_4_1/trained_models/4.11_大过-基于9-去掉ema_model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3b711f-2c18-45b8-a1c3-2aa04c25b572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
