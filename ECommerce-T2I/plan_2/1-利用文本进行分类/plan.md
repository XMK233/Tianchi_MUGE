# 文本分类与物品识别规划方案

本方案旨在利用预训练的 BERT 模型对电商商品文本描述进行无监督聚类分析，自动发现商品类别，并建立文本-图片-类别的映射关系。

## 1. 目标
针对 `ECommerce-T2I` 数据集中的文本描述（`T2I_train.txt.tsv`），在不预设类别标签的前提下，利用深度学习模型理解文本语义，将其自动归类为尽可能少的几个核心商品类别（如“上衣”、“裤子”、“鞋子”等）。

## 2. 核心流程

### 2.1 数据加载与预处理
- **数据源**: 读取 `/mnt/d/forCoding_data/Tianchi_MUGE/originalData/ECommerce-T2I/T2I_train.text.tsv`（根据 README 路径推断）。
- **格式**: `img_id \t description`。
- **预处理**: 去除特殊符号，保留主要文本内容。

### 2.2 特征提取 (Feature Extraction)
使用预训练模型将文本转换为语义向量。
- **模型**: `bert-base-chinese`
- **模型路径**: `/mnt/d/ModelScopeModels/google-bert/bert-base-chinese/`
- **方法**: 
    1. 将文本输入 BERT 模型。
    2. 提取 `[CLS]` 标记的输出向量，或取最后一层隐藏状态的平均值 (Mean Pooling)，作为该文本的语义表示 (Embedding)。
    3. 最终获得一个 `N x 768` 的特征矩阵（N为样本数）。

### 2.3 无监督聚类 (Clustering)
利用特征向量的相似性将文本分组。
- **算法**: K-Means 聚类。
- **类别数确定 (Crucial Step)**:
    - 不预先指定 K 值，而是通过**轮廓系数 (Silhouette Score)** 或 **Elbow Method (肘部法则)** 自动寻找最优的 K 值。
    - 目标是将商品归类为“尽可能少”的类别，因此会倾向于选择较小的 K 值（例如 5-20 之间），只要能区分出大的品类即可。
- **降维**: 在聚类前可使用 PCA 或 t-SNE 将 768 维向量降至 20-50 维，以提高聚类效果和速度。

### 2.4 类别标签生成 (Label Generation)
聚类后，我们需要知道每一类到底是什么。
- **关键词提取**: 对每个聚类簇内的所有文本进行分词（使用 `jieba`）和词性标注。
- **名词统计**: 统计每个簇中出现频率最高的名词（Top-N Nouns）。
- **自动命名**: 选取最具代表性的名词作为该类的标签（例如，某类中“连衣裙”、“裙子”出现频率极高，则命名为“裙装”）。

### 2.5 结果输出
生成包含以下字段的映射列表：
- `text_id` / `img_id`
- `text_content` (原始文本)
- `cluster_id` (聚类编号)
- `predicted_label` (自动生成的类别名称)
- `image_path` (关联的图片路径/Base64)

## 3. 技术栈
- **Python**: 3.8+
- **Transformers**: Hugging Face (用于加载 BERT)
- **Scikit-learn**: 用于 K-Means, PCA, 轮廓系数计算
- **Jieba**: 用于中文分词和关键词提取
- **Pandas**: 用于数据处理

## 4. 预期产出
1. **Python 脚本**: 实现上述流程的完整代码。
2. **分类报告**: 包含最优类别数、每一类的核心关键词。
3. **映射文件**: `text_image_category_mapping.json` 或 `.csv`。

## 5. 实施步骤
1. **开发特征提取模块**: 编写代码加载 BERT 并批量提取文本特征。
2. **开发聚类分析模块**: 编写代码尝试不同的 K 值并计算评估指标，确定最佳分类数。
3. **开发标签定义模块**: 分析聚类结果，自动生成人类可读的标签。
4. **整合与输出**: 生成最终的对应列表文件。
