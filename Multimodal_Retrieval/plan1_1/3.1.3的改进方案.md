**实验方向概览**
- 围绕 `TextFeatureExtractor`、`ImageFeatureExtractor`、`OptimizedMLPProjector`、`FeatureFusion`、`SimilarityCalculator`、`CrossModalRetrievalModel` 和 `info_nce_loss` 做架构级替换或组合；保持训练流程不变，确保可复现对比。

**文本编码器变体**
- 更换骨干：把 `bert-base-chinese` 替换为 `hfl/chinese-roberta-wwm-ext` 或 `hfl/chinese-macbert-base`，保持同样的池化与输出维度，以观察不同中文预训练模型的影响。
- 池化策略对比：在 `TextFeatureExtractor` 中对比 `mean-pooling`（当前基线）与 `CLS` 池化，以及加入轻量 `attentive-pooling`（单线性层做注意力权重）三种方案。
- 层冻结策略：使用 `unfreeze_text_top_layers(last_n_layers)`，分别对比仅解冻顶层 `last_n_layers=2/4/8` 与全解冻对性能与稳定性的影响。

**图像编码器变体**
- 更换骨干：将 `ImageFeatureExtractor` 的 `resnet50` 替换为 `resnet101`、`convnext-tiny` 或 `vit-base-patch16`，保持输出特征维度与投影头输入一致。
- 特征读取层：对比 `global average pooling` 后的 `fc` 前特征与 `fc` 后特征作为输入，观察下游投影头对不同表征的适配能力。
- 解冻策略：使用 `unfreeze_image_top_block()` 仅解冻顶层 block 与全解冻两种设置，结合 LLRD 学习率分层，比较收敛与检索效果。

**投影头与融合**
- 投影头对比：将 `OptimizedMLPProjector` 与 `optimized_two_layer_mlp.py` 的两层 MLP 进行对比；额外尝试“带残差/门控”的变体（输出=MLP输出+线性残差或门控加权）。
- 模态融合位置：对比“后融合”（分别编码、投影后用 `SimilarityCalculator`）与“早融合”（`FeatureFusion` 做拼接后再统一投影）对检索表现的影响。
- 共享 vs 独立投影：比较共享一个投影头（文本和图像权重同构）与各自独立投影头（当前基线）的差异。

**相似度与温度**
- 相似度函数：对比 `cosine` 与 `dot` 两种相似度实现，观察其对 InfoNCE 的影响。
- 温度项：使用固定温度与“可学习温度”（单参数或分模态两参数），比较对训练稳定性与最终召回率的影响。

**损失与负样本策略**
- 损失形式：对比当前 `info_nce_loss` 的双向对齐（文本→图像、图像→文本）与单向对齐，仅优化一侧的效果差异。
- 负样本来源：在仅用“批内负样本”的基础上，增加“难例挖掘”（根据当前相似度选Top-hard负样本）或“记忆队列”（跨批的负样本缓存），观察提升幅度与训练成本。

**训练与调度（架构配套）**
- 学习率分层：对比 `build_optimizer` 与 `build_llrd_optimizer`（分层学习率），在不同解冻深度下的稳定性与指标表现。
- 调度器：对比 `warmup_cosine` 的不同 `warmup_ratio`、`min_lr_ratio`，保持架构相同，评估对检索效果的影响。
- AMP 与梯度检查点：开启/关闭 `use_amp` 与 `use_grad_checkpoint` 组合，观察训练速度、稳定性与最终指标权衡（在确保复现性条件下）。

**检索管线与索引**
- FAISS 索引策略：对比精确检索（暴力相似度计算）与 FAISS 的 `Flat`、`IVF-PQ` 索引，保持编码架构一致，观察端到端检索延迟与指标差异。
- top-k 与重排：固定架构，比较不同 `top-k` 检索与可选的轻量重排（例如再跑一次高精度相似度）对最终准确率的影响。

**数据侧增强（架构鲁棒性验证）**
- 图像增强：对比“无增强”、轻量增强（随机裁剪/翻转/色偏）与特定增强（旋转、轻微仿射），评估不同图像编码器的鲁棒性差异。
- 文本增强：同义替换、随机删除/打乱词级别（保持语义），考察不同文本编码器对噪声的适应性。

**推荐组合对比矩阵（示例）**
- 组合 A：`bert-base-chinese + resnet50 + OptimizedMLPProjector + cosine + 固定温度`（基线）
- 组合 B：`macbert-base + resnet50 + 两层MLP + cosine + 可学习温度`
- 组合 C：`roberta-wwm-ext + convnext-tiny + OptimizedMLPProjector(残差) + dot + 固定温度`
- 组合 D：`bert-base-chinese + vit-base-patch16 + 两层MLP + cosine + 可学习温度 + 早融合`
- 组合 E：`macbert-base + resnet101 + OptimizedMLPProjector + cosine + 固定温度 + 难例挖掘`

**评估与复现建议**
- 指标：`R@1/5/10`、`mAP`、`NDCG`，辅以训练 `avg_loss` 与学习率曲线；记录推理时延与显存占用。
- 复现：固定全局种子与 `DataLoader` worker 种子、禁用非确定性算子；每个组合保持相同训练步数与调度参数，便于公平对比。
- 日志：将每次实验的配置（文本/图像骨干、投影类型、相似度、温度、解冻层数、优化器/调度器、增强与索引）写入一行配置摘要，方便后续复盘。

如果你更倾向先比较“文本侧”或“图像侧”，我可以把上述矩阵拆分成最小可变单元的 4–6 次有序实验，确保资源占用和对比成本在可控范围内。
        