{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 步骤 2.3-3：改用 Mean-Pooling 文本特征 + AMP/FAISS (屯)\n",
    "\n",
    "在 `step_2_3-2_坤-解冻轻量微调-v2_amp_faiss.ipynb` 的基础上，\n",
    "将文本特征从 [CLS] 向量改为基于 `attention_mask` 的 mean-pooling，\n",
    "以提高句向量稳定性。保留 AMP 加速与 FAISS 检索加速，并保持训练/评估流程一致。\n",
    "\n",
    "xmk: pooling的方法还有很多，见： https://blog.csdn.net/fengdu78/article/details/128059894 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "from typing import List, Dict, Tuple\n",
    "import torch\n",
    "import timm\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import importlib\n",
    "\n",
    "# 可选：Faiss 加速检索（安全导入，避免 NumPy 版本问题导致报错中断）\n",
    "HAS_FAISS = False\n",
    "faiss = None\n",
    "try:\n",
    "    spec = importlib.util.find_spec('faiss')\n",
    "    if spec is not None:\n",
    "        faiss = importlib.import_module('faiss')\n",
    "        HAS_FAISS = True\n",
    "except BaseException as e:\n",
    "    print(f'Faiss unavailable: {e.__class__.__name__}')\n",
    "    HAS_FAISS = False\n",
    "\n",
    "# 设置环境变量（与基线一致，按需修改为本地镜像/缓存）\n",
    "cache_dir = \"/mnt/d/HuggingFaceModels/\"\n",
    "os.environ['TORCH_HOME'] = cache_dir\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"1\"\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['all_proxy'] = 'socks5://127.0.0.1:7890'\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ['CURL_CA_BUNDLE'] = \"\"\n",
    "os.environ['HF_ENDPOINT'] = \"https://hf-mirror.com\"\n",
    "\n",
    "# 导入数据加载器（使用 plan1_1/data_loader.py）\n",
    "sys.path.append(os.path.abspath(os.path.join('.', 'Multimodal_Retrieval', 'plan1_1')))\n",
    "from data_loader import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型与特征模块\n",
    "文本特征使用基于 `attention_mask` 的 mean-pooling（排除 padding），相比仅用 [CLS] 更稳健。训练时允许梯度。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextFeatureExtractor:\n",
    "    def __init__(self, model_name='bert-base-chinese', device='cpu', cache_dir=None):\n",
    "        self.device = device\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name, cache_dir=cache_dir, local_files_only=True)\n",
    "        self.model = BertModel.from_pretrained(model_name, cache_dir=cache_dir, local_files_only=True).to(device)\n",
    "        # 默认 eval，训练时将对子模块单独切换 train\n",
    "        self.model.eval()\n",
    "        \n",
    "    def encode_with_grad(self, texts: List[str]) -> torch.Tensor:\n",
    "        if not texts:\n",
    "            return torch.empty((0, 768), dtype=torch.float32, device=self.device)\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "        inputs = self.tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=128).to(self.device)\n",
    "        outputs = self.model(**inputs)\n",
    "        token_embeddings = outputs.last_hidden_state  # [B, L, 768]\n",
    "        attention_mask = inputs.get('attention_mask', None)\n",
    "        if attention_mask is None:\n",
    "            # 兜底：无 mask 时退化为 CLS\n",
    "            return token_embeddings[:, 0, :]\n",
    "        mask = attention_mask.unsqueeze(-1).type_as(token_embeddings)  # [B, L, 1]\n",
    "        summed = (token_embeddings * mask).sum(dim=1)  # [B, 768]\n",
    "        lengths = mask.sum(dim=1).clamp(min=1)        # [B, 1]\n",
    "        mean_pooled = summed / lengths\n",
    "        return mean_pooled\n",
    "\n",
    "class ImageFeatureExtractor:\n",
    "    def __init__(self, model_name='resnet50', device='cpu', cache_dir=None):\n",
    "        self.device = device\n",
    "        self.model = timm.create_model(\n",
    "            model_name, pretrained=True, num_classes=0,\n",
    "            cache_dir=cache_dir\n",
    "        ).to(device)\n",
    "        self.model.eval()\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    def encode_with_grad(self, images: List[Image.Image]) -> torch.Tensor:\n",
    "        if not images:\n",
    "            return torch.empty((0, 2048), dtype=torch.float32, device=self.device)\n",
    "        tensors = torch.stack([self.transform(img.convert('RGB')) for img in images]).to(self.device)\n",
    "        feats = self.model(tensors)\n",
    "        return feats\n",
    "\n",
    "class FeatureFusion:\n",
    "    def __init__(self, fusion_method='projection', projection_dim=512, device=None):\n",
    "        self.fusion_method = fusion_method\n",
    "        self.projection_dim = projection_dim\n",
    "        self.device = device if device is not None else torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        if fusion_method == 'projection':\n",
    "            self.text_projector = torch.nn.Linear(768, projection_dim).to(self.device)\n",
    "            self.image_projector = torch.nn.Linear(2048, projection_dim).to(self.device)\n",
    "    def fuse_text_features(self, text_features: torch.Tensor) -> torch.Tensor:\n",
    "        return self.text_projector(text_features) if self.fusion_method == 'projection' else text_features\n",
    "    def fuse_image_features(self, image_features: torch.Tensor) -> torch.Tensor:\n",
    "        return self.image_projector(image_features) if self.fusion_method == 'projection' else image_features\n",
    "\n",
    "class SimilarityCalculator:\n",
    "    def __init__(self, similarity_type='cosine'):\n",
    "        self.similarity_type = similarity_type\n",
    "    def normalize_features(self, features: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.nn.functional.normalize(features, p=2, dim=1)\n",
    "    def calculate_similarity(self, text_features: torch.Tensor, image_features: torch.Tensor) -> torch.Tensor:\n",
    "        if self.similarity_type == 'cosine':\n",
    "            t_n = self.normalize_features(text_features)\n",
    "            i_n = self.normalize_features(image_features)\n",
    "            return torch.mm(t_n, i_n.t())\n",
    "        return torch.mm(text_features, image_features.t())\n",
    "\n",
    "class CrossModalRetrievalModel:\n",
    "    def __init__(self, text_extractor, image_extractor, fusion_method='projection', projection_dim=512, similarity_type='cosine', normalize_features=True, device=None):\n",
    "        self.text_extractor = text_extractor\n",
    "        self.image_extractor = image_extractor\n",
    "        self.fusion = FeatureFusion(fusion_method, projection_dim, device)\n",
    "        self.sim = SimilarityCalculator(similarity_type)\n",
    "        self.normalize_features = normalize_features\n",
    "        self.device = device if device is not None else torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    def _norm(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.nn.functional.normalize(x, p=2, dim=1) if self.normalize_features else x\n",
    "    def extract_and_fuse_text_features(self, texts: List[str]) -> torch.Tensor:\n",
    "        with torch.no_grad():\n",
    "            t = self.text_extractor.encode_with_grad(texts)\n",
    "        return self._norm(self.fusion.fuse_text_features(t))\n",
    "    def extract_and_fuse_image_features(self, images: List[Image.Image]) -> torch.Tensor:\n",
    "        with torch.no_grad():\n",
    "            i = self.image_extractor.encode_with_grad(images)\n",
    "        return self._norm(self.fusion.fuse_image_features(i))\n",
    "    def build_image_index(self, images_dict: Dict[str, Image.Image], batch_size: int = 32) -> Dict[str, torch.Tensor]:\n",
    "        feats = {}\n",
    "        keys = list(images_dict.keys())\n",
    "        for s in range(0, len(keys), batch_size):\n",
    "            batch_ids = keys[s:s+batch_size]\n",
    "            batch_imgs = [images_dict[k] for k in batch_ids if images_dict[k] is not None]\n",
    "            valid_ids = [k for k in batch_ids if images_dict[k] is not None]\n",
    "            if not batch_imgs:\n",
    "                continue\n",
    "            bf = self.extract_and_fuse_image_features(batch_imgs)\n",
    "            for j, img_id in enumerate(valid_ids):\n",
    "                feats[img_id] = bf[j].detach().cpu()\n",
    "        return feats\n",
    "\n",
    "def info_nce_loss(text_feats: torch.Tensor, image_feats: torch.Tensor, temp: float) -> torch.Tensor:\n",
    "    logits = torch.mm(text_feats, image_feats.t()) / temp\n",
    "    labels = torch.arange(logits.size(0), device=logits.device)\n",
    "    loss_t = torch.nn.functional.cross_entropy(logits, labels)\n",
    "    loss_i = torch.nn.functional.cross_entropy(logits.t(), labels)\n",
    "    return (loss_t + loss_i) * 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 顶层解冻与优化器分组\n",
    "仅解冻顶层，降低学习率，控制训练稳定性。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze_text_top_layers(text_extractor: TextFeatureExtractor, last_n_layers: int = 2):\n",
    "    for p in text_extractor.model.parameters():\n",
    "        p.requires_grad = False\n",
    "    enc = text_extractor.model.encoder\n",
    "    total_layers = len(enc.layer)\n",
    "    for i in range(total_layers - last_n_layers, total_layers):\n",
    "        for p in enc.layer[i].parameters():\n",
    "            p.requires_grad = True\n",
    "        enc.layer[i].train()\n",
    "    if hasattr(text_extractor.model, 'pooler') and text_extractor.model.pooler is not None:\n",
    "        for p in text_extractor.model.pooler.parameters():\n",
    "            p.requires_grad = True\n",
    "        text_extractor.model.pooler.train()\n",
    "    text_extractor.model.eval()\n",
    "\n",
    "def unfreeze_image_top_block(image_extractor: ImageFeatureExtractor, unfreeze_layer4: bool = True):\n",
    "    for p in image_extractor.model.parameters():\n",
    "        p.requires_grad = False\n",
    "    if unfreeze_layer4 and hasattr(image_extractor.model, 'layer4'):\n",
    "        for p in image_extractor.model.layer4.parameters():\n",
    "            p.requires_grad = True\n",
    "        image_extractor.model.layer4.train()\n",
    "    image_extractor.model.eval()\n",
    "\n",
    "def build_optimizer(model: CrossModalRetrievalModel, text_extractor: TextFeatureExtractor, image_extractor: ImageFeatureExtractor,\n",
    "                   lr_proj: float = 1e-3, lr_text_top: float = 5e-5, lr_img_top: float = 1e-4, weight_decay: float = 1e-4):\n",
    "    params = []\n",
    "    params.append({\n",
    "        'params': list(model.fusion.text_projector.parameters()) + list(model.fusion.image_projector.parameters()),\n",
    "        'lr': lr_proj,\n",
    "        'weight_decay': weight_decay\n",
    "    })\n",
    "    text_top_params = []\n",
    "    enc = text_extractor.model.encoder\n",
    "    for mod in enc.layer[-2:]:\n",
    "        text_top_params += list(mod.parameters())\n",
    "    if hasattr(text_extractor.model, 'pooler') and text_extractor.model.pooler is not None:\n",
    "        text_top_params += list(text_extractor.model.pooler.parameters())\n",
    "    params.append({\n",
    "        'params': [p for p in text_top_params if p.requires_grad],\n",
    "        'lr': lr_text_top,\n",
    "        'weight_decay': 0.0\n",
    "    })\n",
    "    img_top_params = []\n",
    "    if hasattr(image_extractor.model, 'layer4'):\n",
    "        img_top_params += list(image_extractor.model.layer4.parameters())\n",
    "    params.append({\n",
    "        'params': [p for p in img_top_params if p.requires_grad],\n",
    "        'lr': lr_img_top,\n",
    "        'weight_decay': 0.0\n",
    "    })\n",
    "    optimizer = torch.optim.Adam(params)\n",
    "    return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据加载与训练参数\n",
    "保持与基线一致的查询数据加载；图片按批次流式以控制显存。默认使用较小批次以便顺利运行。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 18:51:44,129 - INFO - 初始化数据加载器，数据目录: /mnt/d/forCoding_data/Tianchi_MUGE/originalData/Multimodal_Retrieval\n",
      "2025-11-08 18:51:44,133 - INFO - 加载train查询数据: /mnt/d/forCoding_data/Tianchi_MUGE/originalData/Multimodal_Retrieval/MR_train_queries.jsonl\n",
      "加载train查询数据: 248786it [00:01, 213593.85it/s]\n",
      "2025-11-08 18:51:45,384 - INFO - 成功加载train查询数据，共248786条\n",
      "2025-11-08 18:51:45,396 - INFO - 加载valid查询数据: /mnt/d/forCoding_data/Tianchi_MUGE/originalData/Multimodal_Retrieval/MR_valid_queries.jsonl\n",
      "加载valid查询数据: 5008it [00:00, 200130.29it/s]\n",
      "2025-11-08 18:51:45,426 - INFO - 成功加载valid查询数据，共5008条\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader()\n",
    "train_df = loader.load_queries(split='train')\n",
    "valid_df = loader.load_queries(split='valid')\n",
    "\n",
    "# # 训练与流式参数（默认较小，确保可运行）\n",
    "# train_image_batch_size = 500  # 一个大batch的图片数量\n",
    "# max_train_batches = 1         # 加载多少个大batch\n",
    "# epochs_per_batch = 1          # 每个大batch的训练轮数\n",
    "# train_step_batch_size = 32    # 训练时的小 batch size\n",
    "\n",
    "# 训练与流式参数（按需调整）：实际用\n",
    "train_image_batch_size = 15000 ## 一个大batch有这么多图片样本。\n",
    "max_train_batches = 10 ## 总共加载多少个大batch。\n",
    "epochs_per_batch = 5 ## 每个大batch训练几个epoch。\n",
    "train_step_batch_size = 32 ## 每个大batch里面训练的时候的小batch_size是多少。\n",
    "\n",
    "use_amp = True\n",
    "temperature = 0.07\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化模型并执行顶层解冻\n",
    "解冻文本最后2层与池化；解冻图像 `layer4`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 18:51:45,678 - INFO - Loading pretrained weights from Hugging Face hub (timm/resnet50.a1_in1k)\n",
      "2025-11-08 18:51:46,466 - INFO - [timm/resnet50.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optim groups: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1967/1887567262.py:13: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=(device.type == 'cuda' and use_amp))\n"
     ]
    }
   ],
   "source": [
    "image_extractor = ImageFeatureExtractor(device=device, cache_dir=cache_dir)\n",
    "text_extractor = TextFeatureExtractor(device=device, cache_dir=cache_dir)\n",
    "model = CrossModalRetrievalModel(\n",
    "    text_extractor, image_extractor, \n",
    "    fusion_method='projection', projection_dim=512, similarity_type='cosine', normalize_features=True, device=device\n",
    ")\n",
    "\n",
    "unfreeze_text_top_layers(text_extractor, last_n_layers=2)\n",
    "unfreeze_image_top_block(image_extractor, unfreeze_layer4=True)\n",
    "\n",
    "optim = build_optimizer(model, text_extractor, image_extractor,\n",
    "                        lr_proj=1e-3, lr_text_top=5e-5, lr_img_top=1e-4, weight_decay=1e-4)\n",
    "scaler = GradScaler(enabled=(device.type == 'cuda' and use_amp))\n",
    "print('Optim groups:', len(optim.param_groups))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练循环：按批次流式构建配对并微调顶层\n",
    "仅使用配对中的第一张可用图片；文本与图像编码器顶层参与反向传播。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 18:51:52,626 - INFO - 批量加载train图片数据: /mnt/d/forCoding_data/Tianchi_MUGE/originalData/Multimodal_Retrieval/MR_train_imgs.tsv\n",
      "实际加载train图片数据:  11%|█████▊                                             | 14784/129380 [00:06<00:47, 2393.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: images=15000, usable_pairs=29127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1967/1914774025.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "实际加载train图片数据:  11%|█████▊                                             | 14784/129380 [00:19<00:47, 2393.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: avg loss=1.4942\n",
      "Epoch 2/5: avg loss=0.6086\n",
      "Epoch 3/5: avg loss=0.2039\n",
      "Epoch 4/5: avg loss=0.0802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "实际加载train图片数据:  12%|█████▉                                             | 15000/129380 [03:15<7:42:02,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: avg loss=0.0463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "实际加载train图片数据:  23%|███████████▋                                       | 29797/129380 [03:20<00:33, 2979.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2: images=15000, usable_pairs=28909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "实际加载train图片数据:  23%|███████████▋                                       | 29797/129380 [03:39<00:33, 2979.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: avg loss=1.2430\n",
      "Epoch 2/5: avg loss=0.3849\n",
      "Epoch 3/5: avg loss=0.1131\n",
      "Epoch 4/5: avg loss=0.0518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "实际加载train图片数据:  23%|███████████▊                                       | 30000/129380 [06:15<5:16:27,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: avg loss=0.0532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "实际加载train图片数据:  35%|█████████████████▋                                 | 44728/129380 [06:20<00:28, 2962.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3: images=15000, usable_pairs=28595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "实际加载train图片数据:  35%|█████████████████▋                                 | 44728/129380 [06:39<00:28, 2962.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: avg loss=1.1801\n",
      "Epoch 2/5: avg loss=0.3575\n",
      "Epoch 3/5: avg loss=0.1046\n",
      "Epoch 4/5: avg loss=0.0507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "实际加载train图片数据:  35%|█████████████████▋                                 | 45000/129380 [09:14<4:09:34,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: avg loss=0.0519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "实际加载train图片数据:  46%|███████████████████████▌                           | 59713/129380 [09:18<00:21, 3178.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4: images=15000, usable_pairs=29155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "实际加载train图片数据:  46%|███████████████████████▌                           | 59713/129380 [09:29<00:21, 3178.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: avg loss=1.1550\n",
      "Epoch 2/5: avg loss=0.3363\n",
      "Epoch 3/5: avg loss=0.0963\n",
      "Epoch 4/5: avg loss=0.0470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "实际加载train图片数据:  46%|███████████████████████▋                           | 60000/129380 [12:15<3:15:42,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: avg loss=0.0512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "实际加载train图片数据:  58%|█████████████████████████████▍                     | 74705/129380 [12:20<00:16, 3247.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5: images=15000, usable_pairs=29347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "实际加载train图片数据:  58%|█████████████████████████████▍                     | 74705/129380 [12:39<00:16, 3247.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: avg loss=1.1236\n",
      "Epoch 2/5: avg loss=0.3077\n",
      "Epoch 3/5: avg loss=0.0886\n",
      "Epoch 4/5: avg loss=0.0439\n",
      "Epoch 5/5: avg loss=0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "实际加载train图片数据:  69%|███████████████████████████████████▍               | 89790/129380 [15:25<00:11, 3312.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6: images=15000, usable_pairs=29191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "实际加载train图片数据:  69%|███████████████████████████████████▍               | 89790/129380 [15:39<00:11, 3312.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: avg loss=1.0916\n",
      "Epoch 2/5: avg loss=0.2929\n",
      "Epoch 3/5: avg loss=0.0875\n",
      "Epoch 4/5: avg loss=0.0422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "实际加载train图片数据:  70%|███████████████████████████████████▍               | 90000/129380 [18:24<1:59:46,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: avg loss=0.0404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "实际加载train图片数据:  81%|████████████████████████████████████████▍         | 104776/129380 [18:29<00:07, 3284.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7: images=15000, usable_pairs=28504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "实际加载train图片数据:  81%|████████████████████████████████████████▍         | 104776/129380 [18:49<00:07, 3284.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: avg loss=1.0757\n",
      "Epoch 2/5: avg loss=0.2729\n",
      "Epoch 3/5: avg loss=0.0775\n",
      "Epoch 4/5: avg loss=0.0374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "实际加载train图片数据:  81%|████████████████████████████████████████▌         | 105000/129380 [21:23<1:09:55,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: avg loss=0.0332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "实际加载train图片数据:  93%|██████████████████████████████████████████████▎   | 119830/129380 [21:28<00:03, 3148.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8: images=15000, usable_pairs=28894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "实际加载train图片数据:  93%|██████████████████████████████████████████████▎   | 119830/129380 [21:39<00:03, 3148.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: avg loss=1.0543\n",
      "Epoch 2/5: avg loss=0.2620\n",
      "Epoch 3/5: avg loss=0.0742\n",
      "Epoch 4/5: avg loss=0.0368\n",
      "Epoch 5/5: avg loss=0.0318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "实际加载train图片数据: 100%|████████████████████████████████████████████████████| 129380/129380 [24:26<00:00, 88.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9: images=9380, usable_pairs=18432\n",
      "Epoch 1/5: avg loss=1.0653\n",
      "Epoch 2/5: avg loss=0.1987\n",
      "Epoch 3/5: avg loss=0.0567\n",
      "Epoch 4/5: avg loss=0.0323\n",
      "Epoch 5/5: avg loss=0.0251\n"
     ]
    }
   ],
   "source": [
    "def build_batch_pairs(train_df, img_dict: Dict[str, Image.Image]) -> List[Tuple[str, Image.Image, str]]:\n",
    "    pairs = []\n",
    "    if 'item_ids' in train_df.columns:\n",
    "        for _, row in train_df.iterrows():\n",
    "            q = row.get('query_text', None)\n",
    "            ids = row.get('item_ids', [])\n",
    "            if not q or not isinstance(ids, list) or not ids:\n",
    "                continue\n",
    "            chosen_img = None\n",
    "            chosen_id = None\n",
    "            for iid in ids:\n",
    "                sid = str(iid)\n",
    "                if sid in img_dict and img_dict[sid] is not None:\n",
    "                    chosen_img = img_dict[sid]\n",
    "                    chosen_id = sid\n",
    "                    break\n",
    "            if chosen_img is not None:\n",
    "                pairs.append((q, chosen_img, chosen_id))\n",
    "    return pairs\n",
    "\n",
    "def train_one_batch(pairs: List[Tuple[str, Image.Image, str]], epochs: int, step_bs: int):\n",
    "    model.fusion.text_projector.train()\n",
    "    model.fusion.image_projector.train()\n",
    "    text_extractor.model.encoder.layer[-1].train()\n",
    "    text_extractor.model.encoder.layer[-2].train()\n",
    "    if hasattr(text_extractor.model, 'pooler') and text_extractor.model.pooler is not None:\n",
    "        text_extractor.model.pooler.train()\n",
    "    if hasattr(image_extractor.model, 'layer4'):\n",
    "        image_extractor.model.layer4.train()\n",
    "\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        steps = 0\n",
    "        for s in range(0, len(pairs), step_bs):\n",
    "            batch = pairs[s:s+step_bs]\n",
    "            if not batch:\n",
    "                continue\n",
    "            texts = [t for (t, _, _) in batch]\n",
    "            imgs = [im for (_, im, _) in batch]\n",
    "\n",
    "            optim.zero_grad()\n",
    "            if use_amp and device.type == 'cuda':\n",
    "                with autocast(enabled=True):\n",
    "                    t_feats = text_extractor.encode_with_grad(texts)\n",
    "                    i_feats = image_extractor.encode_with_grad(imgs)\n",
    "                    t_proj = model._norm(model.fusion.fuse_text_features(t_feats))\n",
    "                    i_proj = model._norm(model.fusion.fuse_image_features(i_feats))\n",
    "                    loss = info_nce_loss(t_proj, i_proj, temp=temperature)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optim)\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    list(model.fusion.text_projector.parameters()) + list(model.fusion.image_projector.parameters()),\n",
    "                    max_norm=5.0\n",
    "                )\n",
    "                scaler.step(optim)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                t_feats = text_extractor.encode_with_grad(texts)\n",
    "                i_feats = image_extractor.encode_with_grad(imgs)\n",
    "                t_proj = model._norm(model.fusion.fuse_text_features(t_feats))\n",
    "                i_proj = model._norm(model.fusion.fuse_image_features(i_feats))\n",
    "                loss = info_nce_loss(t_proj, i_proj, temp=temperature)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    list(model.fusion.text_projector.parameters()) + list(model.fusion.image_projector.parameters()),\n",
    "                    max_norm=5.0\n",
    "                )\n",
    "                optim.step()\n",
    "            running_loss += loss.item()\n",
    "            steps += 1\n",
    "        print(f\"Epoch {e+1}/{epochs}: avg loss={running_loss/max(steps,1):.4f}\")\n",
    "\n",
    "# 流式加载图片与训练\n",
    "batch_idx = 0\n",
    "for image_batch in loader.load_images_batch(split='train', batch_size=train_image_batch_size, max_batches=max_train_batches):\n",
    "    batch_idx += 1\n",
    "    img_map = {item['img_id']: item['image'] for item in image_batch}\n",
    "    pairs = build_batch_pairs(train_df, img_map)\n",
    "    print(f\"Batch {batch_idx}: images={len(img_map)}, usable_pairs={len(pairs)}\")\n",
    "    if not pairs:\n",
    "        del img_map\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "        continue\n",
    "    train_one_batch(pairs, epochs=epochs_per_batch, step_bs=train_step_batch_size)\n",
    "    del img_map\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存：投影层 + 已解冻顶层 + 优化器\n",
    "保存 BERT 的最后2层 + pooler、ResNet50 的 layer4、投影层、优化器。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/weights/step_2_3_3_mean_pool_checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/mnt/d/forCoding_data/Tianchi_MUGE/trained_models/weights'\n",
    "save_path = os.path.join(save_dir, 'step_2_3_3_mean_pool_checkpoint.pth')\n",
    "\n",
    "def save_unfreeze_checkpoint(model: CrossModalRetrievalModel, text_extractor: TextFeatureExtractor, image_extractor: ImageFeatureExtractor,\n",
    "                             optimizer: torch.optim.Optimizer, save_path: str, last_n_layers: int):\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    ckpt = {\n",
    "        'projection_dim': model.fusion.projection_dim,\n",
    "        'last_n_layers': last_n_layers,\n",
    "        'fusion': {\n",
    "            'text_projector': model.fusion.text_projector.state_dict(),\n",
    "            'image_projector': model.fusion.image_projector.state_dict(),\n",
    "        },\n",
    "        'text_unfrozen': {},\n",
    "        'image_unfrozen': {},\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }\n",
    "    enc = text_extractor.model.encoder\n",
    "    total_layers = len(enc.layer)\n",
    "    start_idx = max(0, total_layers - last_n_layers)\n",
    "    for i in range(start_idx, total_layers):\n",
    "        ckpt['text_unfrozen'][f'encoder_layer_{i}'] = enc.layer[i].state_dict()\n",
    "    if hasattr(text_extractor.model, 'pooler') and text_extractor.model.pooler is not None:\n",
    "        ckpt['text_unfrozen']['pooler'] = text_extractor.model.pooler.state_dict()\n",
    "    if hasattr(image_extractor.model, 'layer4'):\n",
    "        ckpt['image_unfrozen']['layer4'] = image_extractor.model.layer4.state_dict()\n",
    "    torch.save(ckpt, save_path)\n",
    "    print(f\"Checkpoint saved to: {save_path}\")\n",
    "\n",
    "# 保存一次\n",
    "save_unfreeze_checkpoint(model, text_extractor, image_extractor, optim, save_path, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载：恢复解冻顶层与投影层权重，继续训练\n",
    "加载后会自动再次执行顶层解冻，并恢复优化器状态（如提供）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/weights/step_2_3_3_mean_pool_checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "def load_unfreeze_checkpoint(model: CrossModalRetrievalModel, text_extractor: TextFeatureExtractor, image_extractor: ImageFeatureExtractor,\n",
    "                             optimizer: torch.optim.Optimizer, load_path: str):\n",
    "    ckpt = torch.load(load_path, map_location='cpu')\n",
    "    model.fusion.text_projector.load_state_dict(ckpt['fusion']['text_projector'])\n",
    "    model.fusion.image_projector.load_state_dict(ckpt['fusion']['image_projector'])\n",
    "    ln = ckpt.get('last_n_layers', 2)\n",
    "    unfreeze_text_top_layers(text_extractor, last_n_layers=ln)\n",
    "    unfreeze_image_top_block(image_extractor, unfreeze_layer4=True)\n",
    "    enc = text_extractor.model.encoder\n",
    "    for k, v in ckpt['text_unfrozen'].items():\n",
    "        if k.startswith('encoder_layer_'):\n",
    "            idx = int(k.split('_')[-1])\n",
    "            if 0 <= idx < len(enc.layer):\n",
    "                enc.layer[idx].load_state_dict(v)\n",
    "    if 'pooler' in ckpt['text_unfrozen'] and hasattr(text_extractor.model, 'pooler') and text_extractor.model.pooler is not None:\n",
    "        text_extractor.model.pooler.load_state_dict(ckpt['text_unfrozen']['pooler'])\n",
    "    if 'layer4' in ckpt['image_unfrozen'] and hasattr(image_extractor.model, 'layer4'):\n",
    "        image_extractor.model.layer4.load_state_dict(ckpt['image_unfrozen']['layer4'])\n",
    "    if optimizer is not None and 'optimizer' in ckpt:\n",
    "        optimizer.load_state_dict(ckpt['optimizer'])\n",
    "    print(f\"Checkpoint loaded from: {load_path}\")\n",
    "\n",
    "# 测试加载\n",
    "load_unfreeze_checkpoint(model, text_extractor, image_extractor, optim, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证评估：Recall@1/5/10 与 MeanRecall\n",
    "- 基于验证集构建图像索引\n",
    "- 对每条查询计算相似度并统计召回（优先使用 FAISS；不可用则 Torch 回退）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 19:18:27,294 - INFO - 批量加载valid图片数据: /mnt/d/forCoding_data/Tianchi_MUGE/originalData/Multimodal_Retrieval/MR_valid_imgs.tsv\n",
      "实际加载valid图片数据: 100%|████████████████████████████████████████████████████| 29806/29806 [00:12<00:00, 2365.20it/s]\n",
      "2025-11-08 19:18:42,754 - INFO - 成功创建valid图片映射字典，共29806张图片\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usable valid queries: 5008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate: 100%|████████████████████████████████████████████████████████████████████| 5008/5008 [00:39<00:00, 125.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1=0.0571, Recall@5=0.1905, Recall@10=0.2927, MeanRecall=0.1801 (N=5008)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "valid_imgs = loader.create_img_id_to_image_dict(\n",
    "    split='valid', \n",
    "    max_samples=50000,\n",
    "    batch_size=3000,\n",
    "    max_batches=10\n",
    ")\n",
    "\n",
    "valid_queries = []\n",
    "if 'item_ids' in valid_df.columns:\n",
    "    for _, row in valid_df.iterrows():\n",
    "        q = row.get('query_text', None)\n",
    "        ids = [str(i) for i in row.get('item_ids', [])] if isinstance(row.get('item_ids', []), list) else []\n",
    "        if q and ids:\n",
    "            valid_queries.append((q, ids))\n",
    "print(f'Usable valid queries: {len(valid_queries)}')\n",
    "\n",
    "image_index = model.build_image_index(valid_imgs, batch_size=32)\n",
    "all_image_ids = list(image_index.keys())\n",
    "all_image_feats = torch.stack([image_index[i] for i in all_image_ids]) if all_image_ids else torch.empty((0, 512))\n",
    "faiss_index = None\n",
    "if HAS_FAISS and all_image_feats.size(0) > 0:\n",
    "    d = all_image_feats.size(1)\n",
    "    faiss_index = faiss.IndexFlatIP(d)\n",
    "    feats_np = all_image_feats.detach().cpu().numpy().astype('float32')\n",
    "    faiss_index.add(feats_np)\n",
    "\n",
    "all_image_feats = all_image_feats.to(device)\n",
    "\n",
    "def compute_recall_at_k(k_values, queries):\n",
    "    recalls = {k: 0 for k in k_values}\n",
    "    total = 0\n",
    "    for q_text, gt_ids in tqdm(queries, desc='Evaluate'):\n",
    "        if all_image_feats.size(0) == 0:\n",
    "            continue\n",
    "        q_feat = model.extract_and_fuse_text_features([q_text])\n",
    "        if faiss_index is not None:\n",
    "            q_np = q_feat.detach().cpu().numpy().astype('float32')\n",
    "            _, I = faiss_index.search(q_np, max(k_values))\n",
    "            top_idx = I[0].tolist()\n",
    "            top_ids = [all_image_ids[i] for i in top_idx]\n",
    "        else:\n",
    "            sims = model.sim.calculate_similarity(q_feat, all_image_feats)\n",
    "            _, top_idx = torch.topk(sims[0], k=max(k_values))\n",
    "            top_ids = [all_image_ids[i] for i in top_idx.tolist()]\n",
    "        total += 1\n",
    "        for k in k_values:\n",
    "            if any(g in set(top_ids[:k]) for g in gt_ids):\n",
    "                recalls[k] += 1\n",
    "    return {k: (recalls[k] / total if total > 0 else 0.0) for k in k_values}, total\n",
    "\n",
    "rec, total_q = compute_recall_at_k([1,5,10], valid_queries)\n",
    "mean_recall = (rec.get(1,0)+rec.get(5,0)+rec.get(10,0))/3 if total_q>0 else 0.0\n",
    "print(f'Recall@1={rec.get(1,0):.4f}, Recall@5={rec.get(5,0):.4f}, Recall@10={rec.get(10,0):.4f}, MeanRecall={mean_recall:.4f} (N={total_q})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 训练5轮：\n",
    "## Recall@1=0.0571, Recall@5=0.1905, Recall@10=0.2927, MeanRecall=0.1801 (N=5008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 上一版本测试结果：\n",
    "## Recall@1=0.0056, Recall@5=0.0202, Recall@10=0.0375, MeanRecall=0.0211 (N=5008)\n",
    "## 上一版实际跑结果：\n",
    "## Recall@1=0.0487, Recall@5=0.1753, Recall@10=0.2708, MeanRecall=0.1649 (N=5008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
