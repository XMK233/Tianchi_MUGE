{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b9815ed-2f51-4afa-a653-9a20d547c17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from PIL import Image\n",
    "\n",
    "# 设置环境变量\n",
    "cache_dir = \"/mnt/d/HuggingFaceModels/\"\n",
    "os.environ['TORCH_HOME'] = cache_dir\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"1\"\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['all_proxy'] = 'socks5://127.0.0.1:7890'\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# 添加项目路径\n",
    "# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '.')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcecf24e-ab8e-4182-b43d-b9c649694c1f",
   "metadata": {},
   "source": [
    "# 定义特征提取器：文本和图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d52cd9d0-1c14-45bc-a9d7-43129792ee02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 如果导入失败，我们在这里定义完整的特征提取器\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import timm\n",
    "from torchvision import transforms\n",
    "\n",
    "class TextFeatureExtractor:\n",
    "    \"\"\"\n",
    "    文本特征提取器，使用BERT模型提取文本特征\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name='bert-base-chinese', device='cpu', cache_dir=None):\n",
    "        \"\"\"\n",
    "        初始化文本特征提取器\n",
    "        \n",
    "        Args:\n",
    "            model_name: 预训练模型名称\n",
    "            device: 运行设备\n",
    "            cache_dir: 模型缓存目录\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\n",
    "            model_name, cache_dir=cache_dir,\n",
    "            local_files_only=False\n",
    "        )\n",
    "        self.model = BertModel.from_pretrained(\n",
    "            model_name, cache_dir=cache_dir,\n",
    "            local_files_only=False\n",
    "        ).to(device)\n",
    "        self.model.eval()\n",
    "        print(f\"文本模型 {model_name} 加载完成。\")\n",
    "    \n",
    "    def extract_text_features(self, texts):\n",
    "        \"\"\"\n",
    "        提取文本特征\n",
    "        \n",
    "        Args:\n",
    "            texts: 文本列表\n",
    "            \n",
    "        Returns:\n",
    "            文本特征张量\n",
    "        \"\"\"\n",
    "        # 输入验证\n",
    "        if not texts:\n",
    "            return torch.tensor([], dtype=torch.float32, device=self.device)\n",
    "        \n",
    "        # 处理单个文本的情况\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "        \n",
    "        inputs = self.tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=128).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        return outputs.last_hidden_state[:, 0, :]\n",
    "    \n",
    "    # 兼容接口\n",
    "    def extract_features(self, texts):\n",
    "        return self.extract_text_features(texts)\n",
    "\n",
    "class ImageFeatureExtractor:\n",
    "    \"\"\"\n",
    "    图像特征提取器，使用ResNet模型提取图像特征\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name='resnet50', device='cpu', cache_dir=None):\n",
    "        \"\"\"\n",
    "        初始化图像特征提取器\n",
    "        \n",
    "        Args:\n",
    "            model_name: 预训练模型名称\n",
    "            device: 运行设备\n",
    "            cache_dir: 模型缓存目录\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.model = timm.create_model(\n",
    "            model_name, pretrained=True, num_classes=0,\n",
    "            cache_dir=cache_dir\n",
    "        ).to(device)\n",
    "        self.model.eval()\n",
    "        print(f\"图像模型 {model_name} 加载完成。\")\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def extract_image_features(self, images):\n",
    "        \"\"\"\n",
    "        提取图像特征\n",
    "        \n",
    "        Args:\n",
    "            images: PIL图像列表\n",
    "            \n",
    "        Returns:\n",
    "            图像特征张量\n",
    "        \"\"\"\n",
    "        # 输入验证\n",
    "        if not images:\n",
    "            return torch.tensor([], dtype=torch.float32, device=self.device)\n",
    "        \n",
    "        # 处理单个图像的情况\n",
    "        if not isinstance(images, list):\n",
    "            images = [images]\n",
    "        \n",
    "        # 确保输入是PIL图像或可以转换为PIL图像的对象\n",
    "        image_tensors = []\n",
    "        for img in images:\n",
    "            # 确保是PIL图像\n",
    "            if not isinstance(img, Image.Image):\n",
    "                img = Image.fromarray(img) if isinstance(img, np.ndarray) else Image.open(img)\n",
    "            img = img.convert('RGB')  # 确保是RGB格式\n",
    "            image_tensors.append(self.transform(img))\n",
    "        \n",
    "        image_tensors = torch.stack(image_tensors).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            features = self.model(image_tensors)\n",
    "        return features\n",
    "    \n",
    "    # 兼容接口\n",
    "    def extract_features(self, images):\n",
    "        return self.extract_image_features(images)\n",
    "\n",
    "# 特征提取器适配器，将特征提取器适配为检索模型使用的格式\n",
    "class FeatureExtractorAdapter:\n",
    "    \"\"\"\n",
    "    特征提取器适配器，使特征提取器兼容检索模型接口\n",
    "    \"\"\"\n",
    "    def __init__(self, extractor, feature_type='text'):\n",
    "        \"\"\"\n",
    "        初始化特征提取器适配器\n",
    "        \n",
    "        Args:\n",
    "            extractor: 特征提取器实例\n",
    "            feature_type: 特征类型，'text'或'image'\n",
    "        \"\"\"\n",
    "        self.extractor = extractor\n",
    "        self.feature_type = feature_type\n",
    "    \n",
    "    def extract_features(self, inputs):\n",
    "        \"\"\"\n",
    "        提取特征的统一接口\n",
    "        \n",
    "        Args:\n",
    "            inputs: 文本列表或图像列表\n",
    "            \n",
    "        Returns:\n",
    "            特征张量\n",
    "        \"\"\"\n",
    "        if self.feature_type == 'text':\n",
    "            return self.extractor.extract_text_features(inputs)\n",
    "        elif self.feature_type == 'image':\n",
    "            return self.extractor.extract_image_features(inputs)\n",
    "        else:\n",
    "            raise ValueError(f\"不支持的特征类型: {self.feature_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a8c9f6-d376-4e4f-8ba7-ec409287dbfd",
   "metadata": {},
   "source": [
    "# 特征融合策略：决定是否要将文本和图像投影到同一个投影空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a09c832-9bc3-42c1-b46c-697a2c32bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 特征融合策略\n",
    "class FeatureFusion:\n",
    "    \"\"\"\n",
    "    实现多种跨模态特征融合策略\n",
    "    \"\"\"\n",
    "    def __init__(self, fusion_method='projection', projection_dim=512, device=None):\n",
    "        \"\"\"\n",
    "        初始化特征融合器\n",
    "        \n",
    "        Args:\n",
    "            fusion_method: 融合方法，支持 'projection'(投影到共享空间)、'concatenation'(拼接)\n",
    "            projection_dim: 共享投影空间的维度\n",
    "            device: 运行设备\n",
    "        \"\"\"\n",
    "        self.fusion_method = fusion_method\n",
    "        self.projection_dim = projection_dim\n",
    "        self.device = device if device is not None else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # 初始化投影层（如果需要）\n",
    "        if fusion_method == 'projection':\n",
    "            # 假设文本特征维度为768（BERT输出），图像特征维度为2048（ResNet50输出）\n",
    "            self.text_projector = torch.nn.Linear(768, projection_dim).to(self.device)\n",
    "            self.image_projector = torch.nn.Linear(2048, projection_dim).to(self.device)\n",
    "    \n",
    "    def fuse_text_features(self, text_features):\n",
    "        \"\"\"\n",
    "        处理文本特征\n",
    "        \n",
    "        Args:\n",
    "            text_features: 文本特征张量 [batch_size, text_feature_dim]\n",
    "            \n",
    "        Returns:\n",
    "            融合后的文本特征\n",
    "        \"\"\"\n",
    "        if self.fusion_method == 'projection':\n",
    "            # 投影到共享空间\n",
    "            return self.text_projector(text_features)\n",
    "        else:\n",
    "            # 直接返回原始特征\n",
    "            return text_features\n",
    "    \n",
    "    def fuse_image_features(self, image_features):\n",
    "        \"\"\"\n",
    "        处理图像特征\n",
    "        \n",
    "        Args:\n",
    "            image_features: 图像特征张量 [batch_size, image_feature_dim]\n",
    "            \n",
    "        Returns:\n",
    "            融合后的图像特征\n",
    "        \"\"\"\n",
    "        if self.fusion_method == 'projection':\n",
    "            # 投影到共享空间\n",
    "            return self.image_projector(image_features)\n",
    "        else:\n",
    "            # 直接返回原始特征\n",
    "            return image_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3fcf1e-ad97-4f5d-9f09-1de3bff22c53",
   "metadata": {},
   "source": [
    "# 相似度计算方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7e389bd-c50b-476d-96b6-7334f317882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 相似度计算\n",
    "class SimilarityCalculator:\n",
    "    \"\"\"\n",
    "    计算文本特征和图像特征之间的相似度\n",
    "    \"\"\"\n",
    "    def __init__(self, similarity_type='cosine'):\n",
    "        \"\"\"\n",
    "        初始化相似度计算器\n",
    "        \n",
    "        Args:\n",
    "            similarity_type: 相似度类型，支持 'cosine'(余弦相似度)、'dot'(点积)、'euclidean'(欧几里得距离)、'manhattan'(曼哈顿距离)\n",
    "        \"\"\"\n",
    "        self.similarity_type = similarity_type\n",
    "    \n",
    "    def normalize_features(self, features):\n",
    "        \"\"\"\n",
    "        对特征进行L2归一化\n",
    "        \n",
    "        Args:\n",
    "            features: 特征张量\n",
    "            \n",
    "        Returns:\n",
    "            归一化后的特征\n",
    "        \"\"\"\n",
    "        return torch.nn.functional.normalize(features, p=2, dim=1)\n",
    "    \n",
    "    def calculate_similarity(self, text_features, image_features):\n",
    "        \"\"\"\n",
    "        计算文本特征和图像特征之间的相似度矩阵\n",
    "        \n",
    "        Args:\n",
    "            text_features: 文本特征张量 [text_batch_size, feature_dim]\n",
    "            image_features: 图像特征张量 [image_batch_size, feature_dim]\n",
    "            \n",
    "        Returns:\n",
    "            相似度矩阵 [text_batch_size, image_batch_size]\n",
    "            注意：对于距离度量（如欧几里得、曼哈顿），返回的是负距离，以便与相似度排序逻辑保持一致\n",
    "        \"\"\"\n",
    "        if self.similarity_type == 'cosine':\n",
    "            # 余弦相似度 = 归一化后的点积\n",
    "            text_features_normalized = self.normalize_features(text_features)\n",
    "            image_features_normalized = self.normalize_features(image_features)\n",
    "            return torch.mm(text_features_normalized, image_features_normalized.t())\n",
    "        elif self.similarity_type == 'dot':\n",
    "            # 直接计算点积\n",
    "            return torch.mm(text_features, image_features.t())\n",
    "        elif self.similarity_type == 'euclidean':\n",
    "            # 计算欧几里得距离（返回负距离，以便与相似度排序逻辑保持一致）\n",
    "            # 使用广播计算每个文本特征与所有图像特征的距离\n",
    "            text_batch_size = text_features.size(0)\n",
    "            image_batch_size = image_features.size(0)\n",
    "            \n",
    "            # 扩展维度以便广播\n",
    "            text_features_expanded = text_features.unsqueeze(1).expand(text_batch_size, image_batch_size, -1)\n",
    "            image_features_expanded = image_features.unsqueeze(0).expand(text_batch_size, image_batch_size, -1)\n",
    "            \n",
    "            # 计算欧几里得距离\n",
    "            distances = torch.sqrt(torch.sum((text_features_expanded - image_features_expanded) ** 2, dim=2))\n",
    "            \n",
    "            # 返回负距离，因为我们希望相似度高的排在前面\n",
    "            return -distances\n",
    "        elif self.similarity_type == 'manhattan':\n",
    "            # 计算曼哈顿距离（返回负距离，以便与相似度排序逻辑保持一致）\n",
    "            text_batch_size = text_features.size(0)\n",
    "            image_batch_size = image_features.size(0)\n",
    "            \n",
    "            # 扩展维度以便广播\n",
    "            text_features_expanded = text_features.unsqueeze(1).expand(text_batch_size, image_batch_size, -1)\n",
    "            image_features_expanded = image_features.unsqueeze(0).expand(text_batch_size, image_batch_size, -1)\n",
    "            \n",
    "            # 计算曼哈顿距离\n",
    "            distances = torch.sum(torch.abs(text_features_expanded - image_features_expanded), dim=2)\n",
    "            \n",
    "            # 返回负距离，因为我们希望相似度高的排在前面\n",
    "            return -distances\n",
    "        else:\n",
    "            raise ValueError(f\"不支持的相似度类型: {self.similarity_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9d1e75-1129-4090-be16-b32cee58ddde",
   "metadata": {},
   "source": [
    "# 检索模型：以文检图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83668651-7172-4cbb-9be7-f759882d561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 检索模型\n",
    "class CrossModalRetrievalModel:\n",
    "    \"\"\"\n",
    "    跨模态检索模型，整合特征提取、融合和相似度计算，将文本和图像映射到同一嵌入空间\n",
    "    \"\"\"\n",
    "    def __init__(self, text_extractor, image_extractor, fusion_method='projection', \n",
    "                 projection_dim=512, similarity_type='cosine', normalize_features=True, device=None):\n",
    "        \"\"\"\n",
    "        初始化检索模型\n",
    "        \n",
    "        Args:\n",
    "            text_extractor: 文本特征提取器\n",
    "            image_extractor: 图像特征提取器\n",
    "            fusion_method: 特征融合方法\n",
    "            projection_dim: 投影空间维度\n",
    "            similarity_type: 相似度计算类型\n",
    "            normalize_features: 是否在融合后对特征进行标准化\n",
    "            device: 运行设备\n",
    "        \"\"\"\n",
    "        self.text_extractor = text_extractor\n",
    "        self.image_extractor = image_extractor\n",
    "        self.fusion = FeatureFusion(fusion_method, projection_dim, device)\n",
    "        self.similarity_calculator = SimilarityCalculator(similarity_type)\n",
    "        self.normalize_features = normalize_features\n",
    "        self.device = device if device is not None else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # 记录特征维度信息\n",
    "        self.text_feature_dim = None\n",
    "        self.image_feature_dim = None\n",
    "        self.common_space_dim = projection_dim if fusion_method == 'projection' else None\n",
    "    \n",
    "    def _normalize(self, features):\n",
    "        \"\"\"\n",
    "        对特征进行标准化\n",
    "        \n",
    "        Args:\n",
    "            features: 特征张量\n",
    "            \n",
    "        Returns:\n",
    "            标准化后的特征\n",
    "        \"\"\"\n",
    "        if self.normalize_features:\n",
    "            return torch.nn.functional.normalize(features, p=2, dim=1)\n",
    "        return features\n",
    "    \n",
    "    def extract_and_fuse_text_features(self, texts, record_dim=True):\n",
    "        \"\"\"\n",
    "        提取并融合文本特征\n",
    "        \n",
    "        Args:\n",
    "            texts: 文本列表\n",
    "            record_dim: 是否记录特征维度\n",
    "            \n",
    "        Returns:\n",
    "            融合后的文本特征\n",
    "        \"\"\"\n",
    "        # 提取文本特征\n",
    "        text_features = self.text_extractor.extract_features(texts)\n",
    "        \n",
    "        # 记录特征维度（首次调用时）\n",
    "        if record_dim and self.text_feature_dim is None:\n",
    "            self.text_feature_dim = text_features.shape[1]\n",
    "        \n",
    "        # 融合特征\n",
    "        fused_features = self.fusion.fuse_text_features(text_features)\n",
    "        \n",
    "        # 标准化（如果需要）\n",
    "        return self._normalize(fused_features)\n",
    "    \n",
    "    def extract_and_fuse_image_features(self, images, record_dim=True):\n",
    "        \"\"\"\n",
    "        提取并融合图像特征\n",
    "        \n",
    "        Args:\n",
    "            images: 图像列表\n",
    "            record_dim: 是否记录特征维度\n",
    "            \n",
    "        Returns:\n",
    "            融合后的图像特征\n",
    "        \"\"\"\n",
    "        # 提取图像特征\n",
    "        image_features = self.image_extractor.extract_features(images)\n",
    "        \n",
    "        # 记录特征维度（首次调用时）\n",
    "        if record_dim and self.image_feature_dim is None:\n",
    "            self.image_feature_dim = image_features.shape[1]\n",
    "        \n",
    "        # 融合特征\n",
    "        fused_features = self.fusion.fuse_image_features(image_features)\n",
    "        \n",
    "        # 标准化（如果需要）\n",
    "        return self._normalize(fused_features)\n",
    "    \n",
    "    def build_image_index(self, images_dict, batch_size=32, show_progress=False):\n",
    "        \"\"\"\n",
    "        为图像集合构建特征索引\n",
    "        \n",
    "        Args:\n",
    "            images_dict: 图像ID到PIL图像的映射字典\n",
    "            batch_size: 批处理大小\n",
    "            show_progress: 是否显示处理进度\n",
    "            \n",
    "        Returns:\n",
    "            图像ID到特征的映射字典\n",
    "        \"\"\"\n",
    "        image_features_dict = {}\n",
    "        image_ids = list(images_dict.keys())\n",
    "        total_batches = (len(image_ids) + batch_size - 1) // batch_size\n",
    "        \n",
    "        # 批量处理图像以节省内存\n",
    "        for i in range(0, len(image_ids), batch_size):\n",
    "            if show_progress:\n",
    "                print(f\"处理批次 {i//batch_size + 1}/{total_batches}\")\n",
    "            \n",
    "            batch_ids = image_ids[i:i+batch_size]\n",
    "            batch_images = [images_dict[img_id] for img_id in batch_ids]\n",
    "            \n",
    "            # 提取并融合图像特征\n",
    "            batch_features = self.extract_and_fuse_image_features(batch_images)\n",
    "            \n",
    "            # 存储特征\n",
    "            for j, img_id in enumerate(batch_ids):\n",
    "                image_features_dict[img_id] = batch_features[j]\n",
    "        \n",
    "        return image_features_dict\n",
    "    \n",
    "    def retrieve_images(self, query_texts, image_features_dict, top_k=10, return_scores=False):\n",
    "        \"\"\"\n",
    "        根据查询文本检索相关图像\n",
    "        \n",
    "        Args:\n",
    "            query_texts: 查询文本列表\n",
    "            image_features_dict: 图像ID到特征的映射字典\n",
    "            top_k: 返回前k个结果\n",
    "            return_scores: 是否返回相似度分数\n",
    "            \n",
    "        Returns:\n",
    "            如果return_scores=True: 每个查询对应的检索结果列表 [(query_idx, [(image_id, similarity), ...]), ...]\n",
    "            否则: 每个查询对应的图像ID列表 [[image_id1, image_id2, ...], ...]\n",
    "        \"\"\"\n",
    "        # 获取所有图像ID和特征\n",
    "        image_ids = list(image_features_dict.keys())\n",
    "        all_image_features = torch.stack([image_features_dict[img_id] for img_id in image_ids])\n",
    "        \n",
    "        # 提取并融合查询文本特征\n",
    "        text_features = self.extract_and_fuse_text_features(query_texts)\n",
    "        \n",
    "        # 计算相似度\n",
    "        similarities = self.similarity_calculator.calculate_similarity(text_features, all_image_features)\n",
    "        \n",
    "        # 获取Top-k结果\n",
    "        results = []\n",
    "        for i, query_sims in enumerate(similarities):\n",
    "            # 按相似度降序排序\n",
    "            top_indices = torch.topk(query_sims, min(top_k, len(image_ids))).indices\n",
    "            \n",
    "            if return_scores:\n",
    "                query_results = [(image_ids[idx], query_sims[idx].item()) for idx in top_indices]\n",
    "                results.append((i, query_results))\n",
    "            else:\n",
    "                query_results = [image_ids[idx] for idx in top_indices]\n",
    "                results.append(query_results)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def batch_retrieve(self, query_texts, image_features_dict, top_k=10, batch_size=32):\n",
    "        \"\"\"\n",
    "        批量检索图像，处理大量查询时更高效\n",
    "        \n",
    "        Args:\n",
    "            query_texts: 查询文本列表\n",
    "            image_features_dict: 图像ID到特征的映射字典\n",
    "            top_k: 返回前k个结果\n",
    "            batch_size: 查询批处理大小\n",
    "            \n",
    "        Returns:\n",
    "            每个查询对应的图像ID列表 [[image_id1, image_id2, ...], ...]\n",
    "        \"\"\"\n",
    "        # 获取所有图像ID和特征\n",
    "        image_ids = list(image_features_dict.keys())\n",
    "        all_image_features = torch.stack([image_features_dict[img_id] for img_id in image_ids])\n",
    "        \n",
    "        results = []\n",
    "        # 批量处理查询\n",
    "        for i in range(0, len(query_texts), batch_size):\n",
    "            batch_texts = query_texts[i:i+batch_size]\n",
    "            \n",
    "            # 提取并融合查询文本特征\n",
    "            text_features = self.extract_and_fuse_text_features(batch_texts)\n",
    "            \n",
    "            # 计算相似度\n",
    "            similarities = self.similarity_calculator.calculate_similarity(text_features, all_image_features)\n",
    "            \n",
    "            # 获取Top-k结果\n",
    "            for query_sims in similarities:\n",
    "                # 按相似度降序排序\n",
    "                top_indices = torch.topk(query_sims, min(top_k, len(image_ids))).indices\n",
    "                query_results = [image_ids[idx] for idx in top_indices]\n",
    "                results.append(query_results)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_feature_spaces_info(self):\n",
    "        \"\"\"\n",
    "        获取特征空间信息\n",
    "        \n",
    "        Returns:\n",
    "            包含特征维度信息的字典\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"text_feature_dim\": self.text_feature_dim,\n",
    "            \"image_feature_dim\": self.image_feature_dim,\n",
    "            \"common_space_dim\": self.common_space_dim,\n",
    "            \"fusion_method\": self.fusion.fusion_method,\n",
    "            \"normalize_features\": self.normalize_features\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956c1330-bbc6-40e7-898d-f12f3b65af39",
   "metadata": {},
   "source": [
    "# 用以评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f488b54c-1f1a-4945-9833-6382812b702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 评估函数\n",
    "def evaluate_retrieval(model, queries_df, images_dict, top_k_list=[1, 5, 10]):\n",
    "    \"\"\"\n",
    "    评估检索模型性能\n",
    "    \n",
    "    Args:\n",
    "        model: 检索模型\n",
    "        queries_df: 包含查询文本和对应商品ID的DataFrame\n",
    "        images_dict: 图像ID到PIL图像的映射字典\n",
    "        top_k_list: 评估的K值列表\n",
    "        \n",
    "    Returns:\n",
    "        各K值对应的Recall指标字典\n",
    "    \"\"\"\n",
    "    # 构建图像特征索引\n",
    "    print(\"正在构建图像特征索引...\")\n",
    "    image_features_dict = model.build_image_index(images_dict)\n",
    "    \n",
    "    # 准备查询文本\n",
    "    query_texts = queries_df['query_text'].tolist()\n",
    "    \n",
    "    # 获取最大的top_k\n",
    "    max_top_k = max(top_k_list)\n",
    "    \n",
    "    # 执行检索\n",
    "    print(f\"正在执行检索，获取Top-{max_top_k}结果...\")\n",
    "    retrieval_results = model.retrieve_images(query_texts, image_features_dict, top_k=max_top_k)\n",
    "    \n",
    "    # 计算Recall指标\n",
    "    recalls = {f'Recall@{k}': 0.0 for k in top_k_list}\n",
    "    total_queries = len(queries_df)\n",
    "    \n",
    "    for i, (query_idx, top_results) in enumerate(retrieval_results):\n",
    "        # 获取当前查询的真实商品ID\n",
    "        ground_truth_ids = [str(id) for id in queries_df.iloc[query_idx]['item_ids']]\n",
    "        # 获取检索结果中的图像ID\n",
    "        retrieved_ids = [str(result[0]) for result in top_results]\n",
    "        \n",
    "        # 对每个top_k计算Recall\n",
    "        for k in top_k_list:\n",
    "            top_retrieved = retrieved_ids[:k]\n",
    "            # 检查前k个结果中是否包含至少一个真实ID\n",
    "            if any(gt_id in top_retrieved for gt_id in ground_truth_ids):\n",
    "                recalls[f'Recall@{k}'] += 1.0\n",
    "    \n",
    "    # 计算最终Recall值\n",
    "    for k in top_k_list:\n",
    "        recalls[f'Recall@{k}'] /= total_queries\n",
    "    \n",
    "    # 计算MeanRecall\n",
    "    recalls['MeanRecall'] = sum(recalls.values()) / (len(recalls) - 1)  # 减去MeanRecall本身\n",
    "    \n",
    "    return recalls\n",
    "\n",
    "def evaluate_retrieval_results(retrieval_results, ground_truth, k_values=[1, 5, 10]):\n",
    "    \"\"\"\n",
    "    评估检索结果\n",
    "    \n",
    "    Args:\n",
    "        retrieval_results: 检索结果列表，每个元素是一个检索到的ID列表\n",
    "        ground_truth: 真实匹配关系，字典格式 {查询ID: [相关图像ID列表]}\n",
    "        k_values: 评估不同的top-k值\n",
    "        \n",
    "    Returns:\n",
    "        包含不同评估指标的字典\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    for k in k_values:\n",
    "        precision_scores = []\n",
    "        recall_scores = []\n",
    "        map_scores = []  # 平均准确率\n",
    "        \n",
    "        for query_idx, retrieved_ids in enumerate(retrieval_results):\n",
    "            retrieved_ids_k = retrieved_ids[:k]\n",
    "            relevant_ids = ground_truth.get(query_idx, [])\n",
    "            \n",
    "            if not relevant_ids:\n",
    "                continue\n",
    "            \n",
    "            # 计算精确率\n",
    "            relevant_retrieved = len(set(retrieved_ids_k) & set(relevant_ids))\n",
    "            precision = relevant_retrieved / k if k > 0 else 0\n",
    "            precision_scores.append(precision)\n",
    "            \n",
    "            # 计算召回率\n",
    "            recall = relevant_retrieved / len(relevant_ids) if len(relevant_ids) > 0 else 0\n",
    "            recall_scores.append(recall)\n",
    "            \n",
    "            # 计算平均准确率（MAP@k）\n",
    "            ap = 0\n",
    "            hits = 0\n",
    "            for i, retrieved_id in enumerate(retrieved_ids_k):\n",
    "                if retrieved_id in relevant_ids:\n",
    "                    hits += 1\n",
    "                    ap += hits / (i + 1)\n",
    "            ap = ap / min(len(relevant_ids), k) if relevant_ids else 0\n",
    "            map_scores.append(ap)\n",
    "        \n",
    "        # 计算平均值\n",
    "        metrics[f'precision@{k}'] = sum(precision_scores) / len(precision_scores) if precision_scores else 0\n",
    "        metrics[f'recall@{k}'] = sum(recall_scores) / len(recall_scores) if recall_scores else 0\n",
    "        metrics[f'map@{k}'] = sum(map_scores) / len(map_scores) if map_scores else 0\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5c4d3c0-65b7-4555-b946-3686d6af9f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_data(num_texts=10, num_images=50, num_relevant=3):\n",
    "    \"\"\"\n",
    "    创建测试数据\n",
    "    \n",
    "    Args:\n",
    "        num_texts: 测试文本数量\n",
    "        num_images: 测试图像数量\n",
    "        num_relevant: 每个文本相关的图像数量\n",
    "        \n",
    "    Returns:\n",
    "        测试文本列表、图像字典和真实匹配关系\n",
    "    \"\"\"\n",
    "    # 创建测试文本\n",
    "    test_texts = [f\"测试文本 {i}\" for i in range(num_texts)]\n",
    "    \n",
    "    # 创建模拟图像（使用PIL创建空白图像）\n",
    "    test_images = {}\n",
    "    for i in range(num_images):\n",
    "        # 创建一个简单的PIL图像对象\n",
    "        img = Image.new('RGB', (224, 224), color=(73, 109, 137))\n",
    "        test_images[f\"image_{i}\"] = img\n",
    "    \n",
    "    # 创建真实匹配关系\n",
    "    ground_truth = {}\n",
    "    for i in range(num_texts):\n",
    "        # 为每个文本随机选择相关图像\n",
    "        relevant_indices = np.random.choice(range(num_images), size=num_relevant, replace=False)\n",
    "        ground_truth[i] = [f\"image_{idx}\" for idx in relevant_indices]\n",
    "    \n",
    "    return test_texts, test_images, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a86ac55c-f580-4d86-82b2-347e4928e474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_retrieval_model(fusion_method='projection', projection_dim=512, \n",
    "                          similarity_type='cosine', normalize_features=True, device=None):\n",
    "    \"\"\"\n",
    "    创建检索模型的工厂函数\n",
    "    \n",
    "    Args:\n",
    "        fusion_method: 特征融合方法\n",
    "        projection_dim: 投影空间维度\n",
    "        similarity_type: 相似度计算类型\n",
    "        normalize_features: 是否标准化特征\n",
    "        device: 运行设备\n",
    "        \n",
    "    Returns:\n",
    "        初始化的检索模型\n",
    "    \"\"\"\n",
    "    # 使用自定义的特征提取器\n",
    "    text_extractor = TextFeatureExtractor(device=device, cache_dir=cache_dir)\n",
    "    image_extractor = ImageFeatureExtractor(device=device, cache_dir=cache_dir)\n",
    "    \n",
    "    # 创建检索模型\n",
    "    model = CrossModalRetrievalModel(\n",
    "        text_extractor=text_extractor,\n",
    "        image_extractor=image_extractor,\n",
    "        fusion_method=fusion_method,\n",
    "        projection_dim=projection_dim,\n",
    "        similarity_type=similarity_type,\n",
    "        normalize_features=normalize_features,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3fcea4a-7c77-4db5-a335-3871ad172d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_feature_extraction(model, test_texts, test_images):\n",
    "    \"\"\"\n",
    "    测试特征提取功能\n",
    "    \n",
    "    Args:\n",
    "        model: 检索模型\n",
    "        test_texts: 测试文本列表\n",
    "        test_images: 测试图像字典\n",
    "    \"\"\"\n",
    "    print(\"\\n=== 测试特征提取 ===\")\n",
    "    \n",
    "    # 提取文本特征\n",
    "    text_features = model.extract_and_fuse_text_features(test_texts[:3])\n",
    "    print(f\"文本特征形状: {text_features.shape}\")\n",
    "    \n",
    "    # 提取图像特征\n",
    "    sample_images = list(test_images.values())[:3]\n",
    "    image_features = model.extract_and_fuse_image_features(sample_images)\n",
    "    print(f\"图像特征形状: {image_features.shape}\")\n",
    "    \n",
    "    # 检查特征空间信息\n",
    "    space_info = model.get_feature_spaces_info()\n",
    "    print(f\"特征空间信息: {space_info}\")\n",
    "\n",
    "def test_similarity_calculation(model, test_texts, test_images):\n",
    "    \"\"\"\n",
    "    测试相似度计算功能\n",
    "    \n",
    "    Args:\n",
    "        model: 检索模型\n",
    "        test_texts: 测试文本列表\n",
    "        test_images: 测试图像字典\n",
    "    \"\"\"\n",
    "    print(\"\\n=== 测试相似度计算 ===\")\n",
    "    \n",
    "    # 提取特征\n",
    "    text_features = model.extract_and_fuse_text_features(test_texts[:5])\n",
    "    sample_images = list(test_images.values())[:5]\n",
    "    image_features = model.extract_and_fuse_image_features(sample_images)\n",
    "    \n",
    "    # 计算相似度\n",
    "    similarities = model.similarity_calculator.calculate_similarity(text_features, image_features)\n",
    "    print(f\"相似度矩阵形状: {similarities.shape}\")\n",
    "    print(f\"相似度矩阵示例:\\n{similarities[:3, :3]}\")\n",
    "\n",
    "def test_retrieval_functionality(model, test_texts, test_images, ground_truth):\n",
    "    \"\"\"\n",
    "    测试检索功能\n",
    "    \n",
    "    Args:\n",
    "        model: 检索模型\n",
    "        test_texts: 测试文本列表\n",
    "        test_images: 测试图像字典\n",
    "        ground_truth: 真实匹配关系\n",
    "    \"\"\"\n",
    "    print(\"\\n=== 测试检索功能 ===\")\n",
    "    \n",
    "    # 构建图像索引\n",
    "    print(\"构建图像索引...\")\n",
    "    image_index = model.build_image_index(test_images, batch_size=16, show_progress=True)\n",
    "    print(f\"图像索引包含 {len(image_index)} 个图像特征\")\n",
    "    \n",
    "    # 进行检索\n",
    "    print(\"执行检索...\")\n",
    "    retrieval_results = model.retrieve_images(test_texts[:5], image_index, top_k=10)\n",
    "    print(f\"检索结果数量: {len(retrieval_results)}\")\n",
    "    \n",
    "    # 显示一些检索结果\n",
    "    for i, results in enumerate(retrieval_results[:3]):\n",
    "        print(f\"查询 {i} 的前5个结果: {results[:5]}\")\n",
    "    \n",
    "    # 评估检索性能\n",
    "    print(\"\\n=== 评估检索性能 ===\")\n",
    "    metrics = evaluate_retrieval_results(retrieval_results, ground_truth)\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"{metric_name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a2e8850-c211-4f2d-8c0b-aede433f718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_different_methods(test_texts, test_images, ground_truth, device=None):\n",
    "    \"\"\"\n",
    "    比较不同的融合方法和相似度计算方法\n",
    "    \n",
    "    Args:\n",
    "        test_texts: 测试文本列表\n",
    "        test_images: 测试图像字典\n",
    "        ground_truth: 真实匹配关系\n",
    "        device: 运行设备\n",
    "    \"\"\"\n",
    "    print(\"\\n=== 比较不同方法 ===\")\n",
    "    \n",
    "    # 测试不同的融合方法\n",
    "    fusion_methods = ['projection', 'concatenation']\n",
    "    similarity_types = ['cosine', 'dot']\n",
    "    \n",
    "    comparison_results = []\n",
    "    \n",
    "    for fusion_method in fusion_methods:\n",
    "        for similarity_type in similarity_types:\n",
    "            print(f\"\\n测试融合方法: {fusion_method}, 相似度类型: {similarity_type}\")\n",
    "            \n",
    "            # 创建模型\n",
    "            model = create_retrieval_model(\n",
    "                fusion_method=fusion_method,\n",
    "                similarity_type=similarity_type,\n",
    "                device=device\n",
    "            )\n",
    "            \n",
    "            # 构建图像索引\n",
    "            image_index = model.build_image_index(test_images, batch_size=16)\n",
    "            \n",
    "            # 进行检索\n",
    "            retrieval_results = model.retrieve_images(test_texts[:5], image_index, top_k=10)\n",
    "            \n",
    "            # 评估\n",
    "            metrics = evaluate_retrieval_results(retrieval_results, ground_truth)\n",
    "            metrics['fusion_method'] = fusion_method\n",
    "            metrics['similarity_type'] = similarity_type\n",
    "            \n",
    "            comparison_results.append(metrics)\n",
    "            \n",
    "            print(f\"map@10: {metrics.get('map@10', 0):.4f}\")\n",
    "    \n",
    "    return comparison_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b932ac-0efd-47bd-b092-a8c1c462f1bc",
   "metadata": {},
   "source": [
    "# 实际跑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "767f459d-6d30-40b4-8d5a-88277ea92908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== 跨模态检索模型测试 ====\n",
      "使用设备: cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"==== 跨模态检索模型测试 ====\")\n",
    "\n",
    "# 检查是否有可用的GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "733d75f1-6d4f-41ec-86ab-69c474345ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建测试数据...\n",
      "创建了 20 条测试文本和 100 张测试图像\n"
     ]
    }
   ],
   "source": [
    "# 创建测试数据\n",
    "print(\"创建测试数据...\")\n",
    "test_texts, test_images, ground_truth = create_test_data(num_texts=20, num_images=100)\n",
    "print(f\"创建了 {len(test_texts)} 条测试文本和 {len(test_images)} 张测试图像\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0927e62-97dc-4d56-afd8-28c70c134690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建检索模型...\n",
      "文本模型 bert-base-chinese 加载完成。\n",
      "图像模型 resnet50 加载完成。\n"
     ]
    }
   ],
   "source": [
    "# 创建检索模型\n",
    "print(\"创建检索模型...\")\n",
    "model = create_retrieval_model(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32ae2079-536a-4b94-92c1-4128a54063bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 测试特征提取 ===\n",
      "文本特征形状: torch.Size([3, 512])\n",
      "图像特征形状: torch.Size([3, 512])\n",
      "特征空间信息: {'text_feature_dim': 768, 'image_feature_dim': 2048, 'common_space_dim': 512, 'fusion_method': 'projection', 'normalize_features': True}\n",
      "\n",
      "=== 测试相似度计算 ===\n",
      "相似度矩阵形状: torch.Size([5, 5])\n",
      "相似度矩阵示例:\n",
      "tensor([[0.1116, 0.1116, 0.1116],\n",
      "        [0.1233, 0.1233, 0.1233],\n",
      "        [0.1226, 0.1226, 0.1226]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "\n",
      "=== 测试检索功能 ===\n",
      "构建图像索引...\n",
      "处理批次 1/7\n",
      "处理批次 2/7\n",
      "处理批次 3/7\n",
      "处理批次 4/7\n",
      "处理批次 5/7\n",
      "处理批次 6/7\n",
      "处理批次 7/7\n",
      "图像索引包含 100 个图像特征\n",
      "执行检索...\n",
      "检索结果数量: 5\n",
      "查询 0 的前5个结果: ['image_97', 'image_96', 'image_98', 'image_99', 'image_3']\n",
      "查询 1 的前5个结果: ['image_97', 'image_96', 'image_98', 'image_99', 'image_3']\n",
      "查询 2 的前5个结果: ['image_97', 'image_96', 'image_98', 'image_99', 'image_3']\n",
      "\n",
      "=== 评估检索性能 ===\n",
      "precision@1: 0.0000\n",
      "recall@1: 0.0000\n",
      "map@1: 0.0000\n",
      "precision@5: 0.0400\n",
      "recall@5: 0.0667\n",
      "map@5: 0.0222\n",
      "precision@10: 0.0200\n",
      "recall@10: 0.0667\n",
      "map@10: 0.0222\n"
     ]
    }
   ],
   "source": [
    "# 运行各项测试\n",
    "test_feature_extraction(model, test_texts, test_images)\n",
    "test_similarity_calculation(model, test_texts, test_images)\n",
    "test_retrieval_functionality(model, test_texts, test_images, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5d3977-c63c-49f1-86b3-cd7307637bab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031569b8-dfb7-4e15-8d39-f626c5866cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc48b58-6411-4eb8-aee9-a4351a528f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5400ca41-b878-4122-afc1-bc45cd2a15ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b710eb62-212d-4584-acb6-f6caaa690ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f382f1ab-250c-457a-8d3c-a29555b6b80c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369014d4-a0a4-42f9-86b9-092b4b5051bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e9d04d-fbc7-48ae-b25c-2641797ca25a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47248d62-8d6c-41cc-996e-e67b436cfcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4516d2-55de-4e03-b137-ec0c2eb81409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a364f96a-3d3b-47f2-beec-1785d31890bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d03b20c6-644e-4fb9-b01f-518d1982b9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python step_2_2-特征融合与匹配机制.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7cd78b-9e37-4aa2-91f1-31516705e790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d42d406-4427-4714-aae8-855b2ae2748a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e122e62-ddd2-4341-841d-d018c5fad0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aeceee-9d12-4fd4-923a-eee35733336c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5fe8ec-ec20-42d0-93b6-3b22f93e7ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283895d7-a708-417d-a5c3-779f5e42dacd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3eea43-644b-4f7f-bbfa-ce2c6f10bb80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
