{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1fd3f7d-4a04-45cb-8b58-859c6a4683bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoProcessor, TrainingArguments, Trainer, Qwen2_5_VLForConditionalGeneration, Qwen2_5_VLProcessor\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f28dbecc-b649-4c8d-a4a6-fcb36583e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 基础工具\n",
    "def decode_base64_to_image(base64_str: str) -> Image.Image:\n",
    "    img_data = base64.urlsafe_b64decode(base64_str)\n",
    "    return Image.open(BytesIO(img_data)).convert(\"RGB\")\n",
    "\n",
    "def chinese_char_tokenize(text: str) -> list:\n",
    "    \"\"\"\n",
    "    中文按字切分，连续字母/数字视为一个 token\n",
    "    示例: \"V领包臀裙80后\" → [\"V\", \"领\", \"包\", \"臀\", \"裙\", \"80\", \"后\"]\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    i = 0\n",
    "    while i < len(text):\n",
    "        if re.match(r'[a-zA-Z0-9]', text[i]):\n",
    "            j = i\n",
    "            while j < len(text) and re.match(r'[a-zA-Z0-9]', text[j]):\n",
    "                j += 1\n",
    "            tokens.append(text[i:j])\n",
    "            i = j\n",
    "        else:\n",
    "            tokens.append(text[i])\n",
    "            i += 1\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e8a10c7-57ec-401e-8ad7-c75c7d1010d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECommerceCaptionDataset(Dataset):\n",
    "    def __init__(self, tsv_path, jsonl_path, processor, max_length=512, nrows=2):\n",
    "        self.processor = processor\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # 加载图像 base64\n",
    "        df_img = pd.read_csv(tsv_path, sep='\\t', header=None, names=['img_id', 'img_b64'], nrows = nrows)\n",
    "        self.img_dict = dict(zip(df_img['img_id'], df_img['img_b64']))\n",
    "        \n",
    "        # 加载 caption\n",
    "        self.samples = []\n",
    "        with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line.strip())\n",
    "                img_id = data['image_id']\n",
    "                if img_id in self.img_dict:\n",
    "                    # 随机选一条作为 target（SFT 阶段）\n",
    "                    target = np.random.choice(data['text'])\n",
    "                    self.samples.append((img_id, target, data['text']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id, target_caption, all_captions = self.samples[idx]\n",
    "        image = decode_base64_to_image(self.img_dict[img_id])\n",
    "        \n",
    "        # 构造对话格式（正确的多模态内容格式）\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"image\"},\n",
    "                {\"type\": \"text\", \"text\": \"请为这件商品生成一段吸引人的描述。\"}\n",
    "            ]},\n",
    "            {\"role\": \"assistant\", \"content\": target_caption}\n",
    "        ]\n",
    "        prompt = self.processor.tokenizer.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=False\n",
    "        )\n",
    "        \n",
    "        inputs = self.processor(\n",
    "            images=image,\n",
    "            text=prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        # 生成 labels，将输入文本作为标签，忽略 pad_token\n",
    "        labels = inputs[\"input_ids\"].clone()\n",
    "        labels[labels == self.processor.tokenizer.pad_token_id] = -100  # 修正：使用 self.processor\n",
    "        inputs[\"labels\"] = labels\n",
    "        inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n",
    "        return inputs, all_captions  # all_captions 用于 SCST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "611d7af2-e5e1-46b2-ba45-5f3cbb612257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████| 2/2 [00:12<00:00,  6.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# 加载模型和 processor\n",
    "model_id = \"/mnt/d/HuggingFaceModels/models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3\"\n",
    "# 降低图像分辨率以减少内存使用\n",
    "processor = Qwen2_5_VLProcessor.from_pretrained(model_id, image_size=224)\n",
    "\n",
    "# 针对16GB GPU优化的模型加载配置\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"cuda\",  # 强制使用CUDA\n",
    "    dtype=torch.float16,  # 使用float16而不是bfloat16来减少内存使用\n",
    "    low_cpu_mem_usage=True,\n",
    "    # attn_implementation=\"flash_attention_2\"  # 若支持\n",
    ")\n",
    "\n",
    "# 添加gradient checkpointing以减少内存使用\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d1c1ed-8c1b-4222-8aeb-6bea32657fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,843,200 || all params: 3,756,466,176 || trainable%: 0.0491\n"
     ]
    }
   ],
   "source": [
    "# 注入 LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e768f98a-52ed-4fe9-9981-1a625e7836cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集\n",
    "base_dir = \"/mnt/d/forCoding_data/Tianchi_MUGE/originalData/ECommerce-IC/\"\n",
    "\n",
    "train_dataset = ECommerceCaptionDataset(\n",
    "    base_dir + \"IC_train.tsv\", \n",
    "    base_dir + \"IC_train.jsonl\", \n",
    "    processor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7cb84fd-7466-484e-9d1f-b8d226fc9b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据整理函数，确保正确合并batch - 特别处理Qwen2.5-VL需要的图像特征\n",
    "def data_collator(batch):\n",
    "    # 从batch中提取所有inputs\n",
    "    inputs_list = [item[0] for item in batch]\n",
    "    \n",
    "    # 合并inputs字典\n",
    "    merged_inputs = {}\n",
    "    for key in inputs_list[0].keys():\n",
    "        if key == \"pixel_values\":\n",
    "            # 图像像素值需要特殊处理，使用torch.stack\n",
    "            merged_inputs[key] = torch.stack([item[key] for item in inputs_list])\n",
    "        elif key == \"input_ids\" or key == \"attention_mask\" or key == \"labels\":\n",
    "            # 对于序列数据，使用pad_sequence来确保长度一致\n",
    "            merged_inputs[key] = torch.nn.utils.rnn.pad_sequence(\n",
    "                [item[key] for item in inputs_list],\n",
    "                batch_first=True,\n",
    "                padding_value=processor.tokenizer.pad_token_id\n",
    "            )\n",
    "        else:\n",
    "            # 其他类型的数据默认处理\n",
    "            merged_inputs[key] = torch.stack([item[key] for item in inputs_list])\n",
    "    \n",
    "    return merged_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e727d8e-7dcc-4e44-baa8-05dd7447af5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练参数 - 针对16GB GPU优化batch大小\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"sft_qwen25vl_lora\",\n",
    "    per_device_train_batch_size=1,  # 减小batch size以适应16GB GPU\n",
    "    gradient_accumulation_steps=8,  # 增加gradient accumulation来弥补小batch\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,  # 使用混合精度训练以减少内存使用\n",
    "    remove_unused_columns=False,\n",
    "    dataloader_pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ac268c1-200d-483d-8097-856157b45887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./sft_qwen25vl_lora\",\n",
    "#     per_device_train_batch_size=1,\n",
    "#     gradient_accumulation_steps=8,\n",
    "#     learning_rate=1e-4,          # LoRA 学习率可稍高\n",
    "#     num_train_epochs=3,\n",
    "#     logging_steps=20,\n",
    "#     save_strategy=\"epoch\",\n",
    "#     eval_strategy=\"epoch\",\n",
    "#     fp16=False,                  # bfloat16 已由 bnb 指定\n",
    "#     bf16=True,\n",
    "#     optim=\"paged_adamw_8bit\",    # 8-bit 优化器，省显存\n",
    "#     lr_scheduler_type=\"cosine\",\n",
    "#     warmup_ratio=0.03,\n",
    "#     remove_unused_columns=False,\n",
    "#     dataloader_pin_memory=True,\n",
    "#     report_to=\"none\",\n",
    "#     ddp_find_unused_parameters=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ef543-22bc-4709-a383-60258eb61345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义 Trainer 类来实现自定义 loss\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs[\"labels\"]\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        shift_logits = logits[..., :-1, :].contiguous()\n",
    "        shift_labels = labels[..., 1:].contiguous()\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-100)\n",
    "        loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=data_collator,  # 使用自定义的data_collator\n",
    ")\n",
    "\n",
    "# 检查是否已经存在训练好的模型\n",
    "model_dir = \"sft_qwen25vl_lora\"\n",
    "final_model_dir = os.path.join(model_dir, \"final\")\n",
    "checkpoint_exists = False\n",
    "\n",
    "# 检查是否存在final模型目录\n",
    "if os.path.exists(final_model_dir):\n",
    "    print(f\"检测到已存在final模型目录: {final_model_dir}，跳过SFT训练\")\n",
    "    checkpoint_exists = True\n",
    "else:\n",
    "    # 检查是否存在checkpoint目录\n",
    "    import glob\n",
    "    checkpoint_dirs = glob.glob(os.path.join(model_dir, \"checkpoint-*\"))\n",
    "    if checkpoint_dirs:\n",
    "        print(f\"检测到已存在checkpoint目录: {checkpoint_dirs[0]}，跳过SFT训练\")\n",
    "        checkpoint_exists = True\n",
    "\n",
    "# 如果不存在模型，才进行训练\n",
    "if not checkpoint_exists:\n",
    "    trainer.train()\n",
    "else:\n",
    "    print(\"模型已存在，直接加载模型进行后续操作\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e18ea7c-56c7-4fe8-bf6e-48aa3b952aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 上面，不知为何，跑得很慢。\n",
    "## 可能是因为量化得不太到位？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91691d-76d7-4d5d-b744-ecba1c5dbdc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905de38f-7307-4ed2-ac32-8090d36e1b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754d7705-05fb-4a42-9601-29646f03004c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6981af2b-a38f-40bb-be9e-18092db64479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612dfd0e-f1a5-44e5-9f6c-f6c34361e11f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f69c6c2-c21a-46fe-bc63-742109938a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbe0d6a-650c-4226-985c-f67531921aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf312ad-ff32-40c6-9395-c4b71afec541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
