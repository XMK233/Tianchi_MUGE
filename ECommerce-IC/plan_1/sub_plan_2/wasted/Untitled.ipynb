{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27b41178-2484-41bf-b25e-21bfd23d5fe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/huggingface_hub/file_download.py:982: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
      "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
      "  warnings.warn(\n",
      "Fetching 19 files:   0%|                                 | 0/19 [00:00<?, ?it/s]\n",
      "comparison.png:   0%|                               | 0.00/1.53M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "configuration_bunny_phi.py: 11.6kB [00:00, 9.07MB/s]A\n",
      "\n",
      "\n",
      "config.json: 1.27kB [00:00, 8.92MB/s]A\n",
      "\n",
      "\n",
      "added_tokens.json: 1.08kB [00:00, 6.06MB/s]A\n",
      "\n",
      "\n",
      "generation_config.json: 119B [00:00, 580kB/s]A\u001b[A\n",
      "\n",
      "\n",
      "README.md: 3.51kB [00:00, 18.9MB/s]A\n",
      "\n",
      "\n",
      ".gitattributes: 1.56kB [00:00, 7.46MB/s]A\n",
      "Fetching 19 files:   5%|█▎                       | 1/19 [00:01<00:34,  1.92s/it]\n",
      "\n",
      "icon.png:   0%|                                      | 0.00/812k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "comparison.png: 100%|██████████████████████| 1.53M/1.53M [00:00<00:00, 1.56MB/s]\u001b[A\n",
      "Fetching 19 files:  21%|█████▎                   | 4/19 [00:02<00:07,  1.94it/s]\n",
      "\n",
      "icon.png: 100%|██████████████████████████████| 812k/812k [00:00<00:00, 1.49MB/s]\u001b[A\u001b[A\n",
      "Fetching 19 files:  42%|██████████▌              | 8/19 [00:02<00:02,  4.57it/s]\n",
      "example_2.png:   0%|                                | 0.00/74.6k [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "example_2.png: 100%|████████████████████████| 74.6k/74.6k [00:00<00:00, 774kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "example_1.png: 100%|█████████████████████████| 245k/245k [00:00<00:00, 1.20MB/s]\u001b[A\u001b[A\n",
      "Fetching 19 files:  53%|████████████▋           | 10/19 [00:03<00:01,  4.62it/s]\n",
      "merges.txt: 0.00B [00:00, ?B/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:   0%|             | 0.00/1.37G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|             | 0.00/4.99G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "merges.txt: 91.9kB [00:00, 746kB/s]\u001b[A\n",
      "merges.txt: 456kB [00:00, 1.57MB/s]\u001b[A\n",
      "\n",
      "model.safetensors.index.json: 88.7kB [00:00, 17.7MB/s]\n",
      "\n",
      "special_tokens_map.json: 441B [00:00, 2.48MB/s]\n",
      "\n",
      "modeling_bunny_phi.py: 102kB [00:00, 2.55MB/s]\n",
      "\n",
      "tokenizer_config.json: 7.34kB [00:00, 13.3MB/s]\n",
      "\n",
      "tokenizer.json: 0.00B [00:00, ?B/s]\u001b[A\n",
      "tokenizer.json: 229kB [00:00, 2.12MB/s]\u001b[A\n",
      "tokenizer.json: 590kB [00:00, 2.72MB/s]\u001b[A\n",
      "tokenizer.json: 1.22MB [00:00, 4.13MB/s]\u001b[A\n",
      "tokenizer.json: 1.79MB [00:00, 4.73MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "tokenizer.json: 2.11MB [00:00, 4.40MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vocab.json: 315kB [00:00, 3.00MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "vocab.json: 798kB [00:00, 3.34MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|    | 10.5M/4.99G [00:06<52:59, 1.57MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Fetching 19 files:  53%|████████████▋           | 10/19 [00:20<00:01,  4.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|    | 10.5M/4.99G [00:16<52:59, 1.57MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:   2%|    | 21.0M/1.37G [00:17<19:47, 1.14MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|  | 21.0M/4.99G [00:18<1:16:31, 1.08MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:   2%|     | 31.5M/1.37G [00:31<24:09, 926kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|   | 31.5M/4.99G [00:36<1:47:02, 772kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:   3%|▏    | 41.9M/1.37G [00:41<22:24, 991kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|   | 41.9M/4.99G [00:43<1:26:31, 953kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:   4%|▏   | 52.4M/1.37G [00:47<19:29, 1.13MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|  | 52.4M/4.99G [00:49<1:11:45, 1.15MB/s]\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "!HF_ENDPOINT=https://hf-mirror.com python your_script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ed55f-0365-4eb7-9fc5-65eb56219ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501262a5-e6cc-4146-a7ff-6f8c24bff9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "469628bd-5955-4e65-882d-c97dfdf4a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install modelscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ce21cbd-4486-4c28-b1d8-1940817ea3e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from modelscope import snapshot_download\n",
    "# model_dir = snapshot_download('BAAI/Bunny-v1.0-3B',cache_dir='/mnt/d/ModelScopeModels/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca275eea-9b32-4262-8400-071c0049d8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b131c4-1974-415b-87f4-a30c726ca5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 743\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from PIL import Image\n",
    "import warnings\n",
    "\n",
    "# disable some warnings\n",
    "transformers.logging.set_verbosity_error()\n",
    "transformers.logging.disable_progress_bar()\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# set device\n",
    "device = 'cuda'  # or cpu\n",
    "torch.set_default_device(device)\n",
    "\n",
    "# create model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    '/mnt/d/ModelScopeModels/BAAI/Bunny-v1___0-3B/',\n",
    "    trust_remote_code=True,\n",
    "        local_files_only=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3d281b3-3dc9-4bbf-b1ab-94ca4e37f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    '/mnt/d/ModelScopeModels/BAAI/Bunny-v1___0-3B/',\n",
    "    torch_dtype=torch.float16, # float32 for cpu\n",
    "    device_map='auto',\n",
    "    trust_remote_code=True,\n",
    "        local_files_only=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d74053e-76e2-4caf-b793-8d78353533ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
