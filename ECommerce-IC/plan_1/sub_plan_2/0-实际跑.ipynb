{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23cdaf4f-c757-4e9f-9953-24d1fd57d52e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !python pipeline_template.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472787d2-db61-4f14-bafa-aa4c55ac2244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47da0a59-12c8-411f-9c20-933520e6e414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python 1_蹇-单纯使用vl模型.py\n",
    "# !head /mnt/d/forCoding_data/Tianchi_MUGE/originalData/ECommerce-IC/v1.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94394afa-b3bf-4af2-9374-44fd8645a414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7786634a-ba7e-4a11-9bae-97e38dc24ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python 2_解-基于1_做sft.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd58aea3-9855-45ab-89a0-3256fe07271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python 3_损-基于2_能实际跑的版本.py --mode infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e30c16f-67dc-4d95-9f7f-371be6ed4a73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  self.setter(val)\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:00<00:00,  6.96it/s]\n",
      "INFO:pipeline_template:[Train] Resuming from latest ckpt: round 11 @ /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_11\n",
      "INFO:pipeline_template:[LoRA] 可训练参数: 9,288,192 | 参数内存约: 35.43 MB | 训练期显存估算: ~141.73 MB\n",
      "INFO:pipeline_template:[GPU0] allocated=0.00 MB | reserved=18.00 MB\n",
      "[W1202 21:56:19.357446041 socket.cpp:209] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n",
      "INFO:pipeline_template:[DS] initialized with stage=2, world_size=1, micro_bs=8, grad_acc=1\n",
      "INFO:pipeline_template:[Train] Round 12/50 | lines: 1000 @ start 11000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [00:47<00:00, 21.20img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2281.28match/s]\n",
      "Loading images...:   9%|█▉                   | 90/1000 [00:00<00:05, 175.63it/s]INFO:data_loader:[DataLoader] try-block failed in _decode_base64_image\n",
      "WARNING:data_loader:Failed to decode base64 image: image file is truncated (7 bytes not processed)\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 184.38it/s]\n",
      "INFO:pipeline_template:[Train] Round 12: loaded 999 images -> expanded to 999 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 999 samples\n",
      "Epoch 1/1:   0%|                                        | 0/125 [00:00<?, ?it/s]/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [00:54<00:00,  2.31it/s]\n",
      "INFO:pipeline_template:[Train] step=125, loss=2.3021\n",
      "Captioning images, with ``generate``:   0%|               | 0/1 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['牛仔半身裙，穿出你的小女人味', '精致的包包，让你更优雅迷人']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_12/index.html\n",
      "INFO:pipeline_template:[Train] Round 12 final sample count: 999\n",
      "INFO:pipeline_template:[Train] Saved round 12 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_12\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10341.86 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 13/50 | lines: 1000 @ start 12000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [00:50<00:00, 19.88img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2151.12match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 178.76it/s]\n",
      "INFO:pipeline_template:[Train] Round 13: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [01:10<00:00,  1.76it/s]\n",
      "INFO:pipeline_template:[Train] step=250, loss=2.6800\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['实木餐边柜，打造温馨厨房空间', '优雅连衣裙，气质女神范儿']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_13/index.html\n",
      "INFO:pipeline_template:[Train] Round 13 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 13 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_13\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=9533.25 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 14/50 | lines: 1000 @ start 13000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [00:53<00:00, 18.86img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2293.94match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 179.19it/s]\n",
      "INFO:pipeline_template:[Train] Round 14: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [00:55<00:00,  2.23it/s]\n",
      "INFO:pipeline_template:[Train] step=375, loss=2.1893\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['高腰牛仔半身裙，显瘦又时髦', '气质名媛连衣裙，穿出优雅女神范儿']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_14/index.html\n",
      "INFO:pipeline_template:[Train] Round 14 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 14 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_14\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10288.81 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 15/50 | lines: 1000 @ start 14000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [00:56<00:00, 17.77img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2291.30match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 188.27it/s]\n",
      "INFO:pipeline_template:[Train] Round 15: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [00:54<00:00,  2.31it/s]\n",
      "INFO:pipeline_template:[Train] step=500, loss=3.2245\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['吃白萝卜，补气养血又健脾', '宝宝睡袋，让睡眠更安全']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_15/index.html\n",
      "INFO:pipeline_template:[Train] Round 15 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 15 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_15\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10288.38 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 16/50 | lines: 1000 @ start 15000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [01:01<00:00, 16.17img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2159.38match/s]\n",
      "Loading images...:  99%|███████████████████▊| 992/1000 [00:05<00:00, 185.55it/s]INFO:data_loader:[DataLoader] try-block failed in _decode_base64_image\n",
      "WARNING:data_loader:Failed to decode base64 image: image file is truncated (12 bytes not processed)\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 171.53it/s]\n",
      "INFO:pipeline_template:[Train] Round 16: loaded 999 images -> expanded to 999 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 999 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [00:57<00:00,  2.17it/s]\n",
      "INFO:pipeline_template:[Train] step=625, loss=2.8191\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['针织开衫，让你轻松穿出时髦感', '时尚连衣裙，让你美得与众不同']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_16/index.html\n",
      "INFO:pipeline_template:[Train] Round 16 final sample count: 999\n",
      "INFO:pipeline_template:[Train] Saved round 16 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_16\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10235.44 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 17/50 | lines: 1000 @ start 16000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [01:02<00:00, 16.00img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2247.36match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:06<00:00, 161.32it/s]\n",
      "INFO:pipeline_template:[Train] Round 17: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [01:11<00:00,  1.74it/s]\n",
      "INFO:pipeline_template:[Train] step=750, loss=2.8428\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['睡觉时，你是否也想拥有一只毛绒玩具陪伴？', '时尚凉拖鞋，让你的脚丫子更美']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_17/index.html\n",
      "INFO:pipeline_template:[Train] Round 17 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 17 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_17\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=9675.31 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 18/50 | lines: 1000 @ start 17000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [01:07<00:00, 14.77img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2294.48match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 182.43it/s]\n",
      "INFO:pipeline_template:[Train] Round 18: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [00:56<00:00,  2.19it/s]\n",
      "INFO:pipeline_template:[Train] step=875, loss=2.5401\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  2.05it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['陶瓷花瓶，让家充满艺术气息', '精致的首饰，让女人更美']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_18/index.html\n",
      "INFO:pipeline_template:[Train] Round 18 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 18 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_18\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=9803.31 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 19/50 | lines: 1000 @ start 18000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [01:14<00:00, 13.50img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2282.60match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:06<00:00, 162.14it/s]\n",
      "INFO:pipeline_template:[Train] Round 19: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [01:05<00:00,  1.89it/s]\n",
      "INFO:pipeline_template:[Train] step=1000, loss=2.6833\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.41it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['时尚腰带，让你的身材更完美', '北欧风，让家更温馨舒适']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_19/index.html\n",
      "INFO:pipeline_template:[Train] Round 19 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 19 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_19\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10079.56 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 20/50 | lines: 1000 @ start 19000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [01:12<00:00, 13.83img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2272.00match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 169.37it/s]\n",
      "INFO:pipeline_template:[Train] Round 20: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [00:59<00:00,  2.09it/s]\n",
      "INFO:pipeline_template:[Train] step=1125, loss=2.2729\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['创意餐具，让餐桌更美', '时尚尖头高跟鞋，让你美出新高度']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_20/index.html\n",
      "INFO:pipeline_template:[Train] Round 20 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 20 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_20\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=9904.23 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 21/50 | lines: 1000 @ start 20000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [01:18<00:00, 12.77img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2136.10match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 174.52it/s]\n",
      "INFO:pipeline_template:[Train] Round 21: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n",
      "INFO:pipeline_template:[Train] step=1250, loss=2.4697\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:02<00:00,  2.28s/it]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['优雅连衣裙，让你美出新高度', '夏日出游，草帽是必不可少的单品之一。无论是海边度假还是城市出行，一顶时尚百搭的帽子都能让你成为焦点。']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_21/index.html\n",
      "INFO:pipeline_template:[Train] Round 21 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 21 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_21\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=9970.14 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 22/50 | lines: 1000 @ start 21000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [01:21<00:00, 12.25img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2160.63match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:06<00:00, 164.15it/s]\n",
      "INFO:pipeline_template:[Train] Round 22: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [00:56<00:00,  2.23it/s]\n",
      "INFO:pipeline_template:[Train] step=1375, loss=3.0261\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['打造卧室小天地，梳妆台来帮忙', '创意地垫，让家更温馨']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_22/index.html\n",
      "INFO:pipeline_template:[Train] Round 22 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 22 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_22\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10190.33 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 23/50 | lines: 1000 @ start 22000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [01:26<00:00, 11.52img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2350.61match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 176.85it/s]\n",
      "INFO:pipeline_template:[Train] Round 23: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [00:56<00:00,  2.21it/s]\n",
      "INFO:pipeline_template:[Train] step=1500, loss=2.3460\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.96it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['飘窗垫，让生活更美好', '白色系的连衣裙，清新又温柔']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_23/index.html\n",
      "INFO:pipeline_template:[Train] Round 23 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 23 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_23\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10192.33 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 24/50 | lines: 1000 @ start 23000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [01:32<00:00, 10.85img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2214.78match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 175.03it/s]\n",
      "INFO:pipeline_template:[Train] Round 24: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [01:09<00:00,  1.79it/s]\n",
      "INFO:pipeline_template:[Train] step=1625, loss=2.2087\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['牛仔短裤，穿出你的青春活力范儿', '复古碎花连衣裙，穿出优雅气质范儿']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_24/index.html\n",
      "INFO:pipeline_template:[Train] Round 24 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 24 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_24\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10298.70 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 25/50 | lines: 1000 @ start 24000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [01:31<00:00, 10.92img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2315.01match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:06<00:00, 162.50it/s]\n",
      "INFO:pipeline_template:[Train] Round 25: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [01:10<00:00,  1.78it/s]\n",
      "INFO:pipeline_template:[Train] step=1750, loss=2.2358\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.80it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['时尚运动鞋，让你轻松穿出型男范', '时尚打火机，点燃你的生活激情']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_25/index.html\n",
      "INFO:pipeline_template:[Train] Round 25 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 25 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_25\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10299.81 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 26/50 | lines: 1000 @ start 25000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [01:40<00:00,  9.96img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2065.96match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 173.49it/s]\n",
      "INFO:pipeline_template:[Train] Round 26: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [01:02<00:00,  2.01it/s]\n",
      "INFO:pipeline_template:[Train] step=1875, loss=2.3222\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['小个子女生穿连衣裙，显高又时髦', '时尚贝雷帽，让你的造型更出彩']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_26/index.html\n",
      "INFO:pipeline_template:[Train] Round 26 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 26 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_26\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=9665.68 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 27/50 | lines: 1000 @ start 26000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [01:40<00:00, 10.00img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2220.42match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 188.94it/s]\n",
      "INFO:pipeline_template:[Train] Round 27: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [06:13<00:00,  2.99s/it]\n",
      "INFO:pipeline_template:[Train] step=2000, loss=2.5388\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['时尚连体裤，让你轻松穿出女神范儿', '北欧风客厅，打造舒适小窝']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_27/index.html\n",
      "INFO:pipeline_template:[Train] Round 27 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 27 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_27\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=9828.68 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 28/50 | lines: 1000 @ start 27000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [01:44<00:00,  9.55img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2112.72match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:06<00:00, 159.32it/s]\n",
      "INFO:pipeline_template:[Train] Round 28: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [00:57<00:00,  2.18it/s]\n",
      "INFO:pipeline_template:[Train] step=2125, loss=2.6529\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['复古风连衣裙，穿出优雅女人味', '复古风包包，让你成为街头焦点']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_28/index.html\n",
      "INFO:pipeline_template:[Train] Round 28 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 28 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_28\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10223.99 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 29/50 | lines: 1000 @ start 28000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [01:47<00:00,  9.34img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2224.52match/s]\n",
      "Loading images...:  64%|████████████▋       | 637/1000 [00:03<00:02, 146.96it/s]/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/PIL/Image.py:1039: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 190.77it/s]\n",
      "INFO:pipeline_template:[Train] Round 29: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [00:56<00:00,  2.22it/s]\n",
      "INFO:pipeline_template:[Train] step=2250, loss=2.6494\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  2.11it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['小台灯，照亮你的生活空间', '时尚套装，穿出优雅气质范儿']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_29/index.html\n",
      "INFO:pipeline_template:[Train] Round 29 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 29 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_29\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10521.14 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 30/50 | lines: 1000 @ start 29000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [01:51<00:00,  8.99img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2123.87match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 175.19it/s]\n",
      "INFO:pipeline_template:[Train] Round 30: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [01:34<00:00,  1.32it/s]\n",
      "INFO:pipeline_template:[Train] step=2375, loss=2.5276\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.82it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['复古文艺风，宽松阔腿裤', '粉色系的外套，让你美得与众不同']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_30/index.html\n",
      "INFO:pipeline_template:[Train] Round 30 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 30 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_30\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10127.95 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 31/50 | lines: 1000 @ start 30000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [01:54<00:00,  8.73img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2210.83match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 171.60it/s]\n",
      "INFO:pipeline_template:[Train] Round 31: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [01:02<00:00,  1.99it/s]\n",
      "INFO:pipeline_template:[Train] step=2500, loss=2.6784\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  2.14it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['复古风，穿出你的优雅气质', '潮男休闲裤，穿出你的型']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_31/index.html\n",
      "INFO:pipeline_template:[Train] Round 31 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 31 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_31\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=9813.95 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 32/50 | lines: 1000 @ start 31000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [02:03<00:00,  8.08img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2076.14match/s]\n",
      "Loading images...:  83%|████████████████▌   | 829/1000 [00:04<00:01, 163.52it/s]/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/PIL/Image.py:3432: DecompressionBombWarning: Image size (96864964 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:06<00:00, 152.37it/s]\n",
      "INFO:pipeline_template:[Train] Round 32: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [01:00<00:00,  2.05it/s]\n",
      "INFO:pipeline_template:[Train] step=2625, loss=2.6912\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['时尚的毛呢大衣，让你轻松穿出优雅气质', '萌趣渔夫帽，让宝宝玩转夏日阳光']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_32/index.html\n",
      "INFO:pipeline_template:[Train] Round 32 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 32 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_32\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10205.61 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 33/50 | lines: 1000 @ start 32000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [02:03<00:00,  8.11img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2254.39match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 178.39it/s]\n",
      "INFO:pipeline_template:[Train] Round 33: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [01:01<00:00,  2.04it/s]\n",
      "INFO:pipeline_template:[Train] step=2750, loss=2.5271\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['清新香薰，让家充满自然气息', '针织连衣裙，穿出优雅女人味']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_33/index.html\n",
      "INFO:pipeline_template:[Train] Round 33 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 33 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_33\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10237.61 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 34/50 | lines: 1000 @ start 33000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [02:06<00:00,  7.91img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2167.21match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 166.99it/s]\n",
      "INFO:pipeline_template:[Train] Round 34: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [01:04<00:00,  1.93it/s]\n",
      "INFO:pipeline_template:[Train] step=2875, loss=2.9212\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['优雅连衣裙，让你美出新高度', '复古英伦风，小个子也能穿出大长腿']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_34/index.html\n",
      "INFO:pipeline_template:[Train] Round 34 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 34 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_34\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10355.61 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 35/50 | lines: 1000 @ start 34000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [02:14<00:00,  7.46img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 1896.75match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 182.06it/s]\n",
      "INFO:pipeline_template:[Train] Round 35: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [00:54<00:00,  2.29it/s]\n",
      "INFO:pipeline_template:[Train] step=3000, loss=2.2262\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.83it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['创意花瓶，让家充满艺术气息', '时尚的连衣裙，让你美得与众不同']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_35/index.html\n",
      "INFO:pipeline_template:[Train] Round 35 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 35 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_35\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10353.61 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 36/50 | lines: 1000 @ start 35000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [02:17<00:00,  7.25img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2122.63match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 177.23it/s]\n",
      "INFO:pipeline_template:[Train] Round 36: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [01:08<00:00,  1.81it/s]\n",
      "INFO:pipeline_template:[Train] step=3125, loss=2.4732\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['时尚休闲鞋，让你轻松出行', '夏日海边度假，穿条连衣裙去吧']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_36/index.html\n",
      "INFO:pipeline_template:[Train] Round 36 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 36 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_36\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10355.67 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 37/50 | lines: 1000 @ start 36000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [02:23<00:00,  6.98img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2032.89match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 171.91it/s]\n",
      "INFO:pipeline_template:[Train] Round 37: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [00:58<00:00,  2.13it/s]\n",
      "INFO:pipeline_template:[Train] step=3250, loss=2.4440\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['时尚套装，穿出你的气质女神范儿', '高筒靴，让你的腿更长更美']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_37/index.html\n",
      "INFO:pipeline_template:[Train] Round 37 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 37 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_37\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10272.95 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 38/50 | lines: 1000 @ start 37000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [02:27<00:00,  6.79img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2151.16match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 169.84it/s]\n",
      "INFO:pipeline_template:[Train] Round 38: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [00:56<00:00,  2.23it/s]\n",
      "INFO:pipeline_template:[Train] step=3375, loss=2.7855\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['T恤，穿出你的青春活力范儿', '竹编果盘，让水果更美味']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_38/index.html\n",
      "INFO:pipeline_template:[Train] Round 38 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 38 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_38\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=9814.95 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 39/50 | lines: 1000 @ start 38000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [02:29<00:00,  6.70img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2160.80match/s]\n",
      "Loading images...:  89%|█████████████████▋  | 887/1000 [00:04<00:00, 317.87it/s]INFO:data_loader:[DataLoader] try-block failed in _decode_base64_image\n",
      "WARNING:data_loader:Failed to decode base64 image: image file is truncated (23 bytes not processed)\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 188.74it/s]\n",
      "INFO:pipeline_template:[Train] Round 39: loaded 999 images -> expanded to 999 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 999 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [01:04<00:00,  1.94it/s]\n",
      "INFO:pipeline_template:[Train] step=3500, loss=2.8440\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['可爱小物，让生活充满乐趣', '复古风耳环，让你美得与众不同']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_39/index.html\n",
      "INFO:pipeline_template:[Train] Round 39 final sample count: 999\n",
      "INFO:pipeline_template:[Train] Saved round 39 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_39\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10190.95 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 40/50 | lines: 1000 @ start 39000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [02:51<00:00,  5.81img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 2040.42match/s]\n",
      "Loading images...:  77%|███████████████▍    | 773/1000 [00:04<00:01, 189.22it/s]INFO:data_loader:[DataLoader] try-block failed in _decode_base64_image\n",
      "WARNING:data_loader:Failed to decode base64 image: image file is truncated (5 bytes not processed)\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 176.35it/s]\n",
      "INFO:pipeline_template:[Train] Round 40: loaded 999 images -> expanded to 999 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 999 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [00:56<00:00,  2.23it/s]\n",
      "INFO:pipeline_template:[Train] step=3625, loss=2.9735\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['红烧羊排，香辣可口的美味佳肴', '秋冬毛衣，让你温暖过冬']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_40/index.html\n",
      "INFO:pipeline_template:[Train] Round 40 final sample count: 999\n",
      "INFO:pipeline_template:[Train] Saved round 40 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_40\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10456.95 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 41/50 | lines: 1000 @ start 40000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [02:55<00:00,  5.70img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 1775.66match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 170.00it/s]\n",
      "INFO:pipeline_template:[Train] Round 41: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [00:55<00:00,  2.25it/s]\n",
      "INFO:pipeline_template:[Train] step=3750, loss=2.3921\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.81it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['运动服，让你的健身更轻松', '时尚套装，让你轻松穿出时髦范儿']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_41/index.html\n",
      "INFO:pipeline_template:[Train] Round 41 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 41 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_41\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=9878.73 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 42/50 | lines: 1000 @ start 41000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [03:16<00:00,  5.08img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 1871.81match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:06<00:00, 164.77it/s]\n",
      "INFO:pipeline_template:[Train] Round 42: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [01:11<00:00,  1.75it/s]\n",
      "INFO:pipeline_template:[Train] step=3875, loss=3.1392\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.87it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['马丁靴，让你的腿更长更美', '帆布鞋，让你的青春更加有活力']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_42/index.html\n",
      "INFO:pipeline_template:[Train] Round 42 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 42 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_42\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10080.73 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 43/50 | lines: 1000 @ start 42000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [03:34<00:00,  4.66img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 1635.54match/s]\n",
      "Loading images...:  14%|██▊                 | 140/1000 [00:00<00:04, 181.90it/s]INFO:data_loader:[DataLoader] try-block failed in _decode_base64_image\n",
      "WARNING:data_loader:Failed to decode base64 image: image file is truncated (7 bytes not processed)\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:06<00:00, 165.79it/s]\n",
      "INFO:pipeline_template:[Train] Round 43: loaded 999 images -> expanded to 999 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 999 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [00:55<00:00,  2.26it/s]\n",
      "INFO:pipeline_template:[Train] step=4000, loss=2.9391\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['坚果零食，健康美味的代名词', '北欧风客厅，让家更温馨舒适']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_43/index.html\n",
      "INFO:pipeline_template:[Train] Round 43 final sample count: 999\n",
      "INFO:pipeline_template:[Train] Saved round 43 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_43\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10144.73 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 44/50 | lines: 1000 @ start 43000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [03:37<00:00,  4.59img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 1657.44match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 186.99it/s]\n",
      "INFO:pipeline_template:[Train] Round 44: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [00:55<00:00,  2.25it/s]\n",
      "INFO:pipeline_template:[Train] step=4125, loss=2.8303\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['小个子女生穿连衣裙，显高又气质', '高帮板鞋，让你的青春更加有活力']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_44/index.html\n",
      "INFO:pipeline_template:[Train] Round 44 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 44 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_44\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10286.73 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 45/50 | lines: 1000 @ start 44000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [03:45<00:00,  4.44img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 1872.19match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 177.98it/s]\n",
      "INFO:pipeline_template:[Train] Round 45: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n",
      "INFO:pipeline_template:[Train] step=4250, loss=2.8902\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  2.36it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['窗帘，让家更温馨', '创意地垫，让家更温馨']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_45/index.html\n",
      "INFO:pipeline_template:[Train] Round 45 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 45 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_45\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10192.73 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 46/50 | lines: 1000 @ start 45000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [03:49<00:00,  4.35img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 1846.75match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 188.41it/s]\n",
      "INFO:pipeline_template:[Train] Round 46: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [01:04<00:00,  1.93it/s]\n",
      "INFO:pipeline_template:[Train] step=4375, loss=2.7877\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['茶道，是中国人的一种生活方式。在快节奏的生活中，人们更需要一种慢下来的生活方式来放松自己、享受生活。茶道就是一种很好的选择。', '气质名媛风，穿出优雅女神范儿']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_46/index.html\n",
      "INFO:pipeline_template:[Train] Round 46 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 46 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_46\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=9754.54 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 47/50 | lines: 1000 @ start 46000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [04:06<00:00,  4.05img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 1559.01match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:04<00:00, 204.77it/s]\n",
      "INFO:pipeline_template:[Train] Round 47: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [00:59<00:00,  2.12it/s]\n",
      "INFO:pipeline_template:[Train] step=4500, loss=2.3184\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['简约钱包，让你的时尚更出众', '北欧风客厅，打造舒适惬意的居家生活']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_47/index.html\n",
      "INFO:pipeline_template:[Train] Round 47 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 47 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_47\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=9877.04 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 48/50 | lines: 1000 @ start 47000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [04:00<00:00,  4.16img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 1777.88match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 169.77it/s]\n",
      "INFO:pipeline_template:[Train] Round 48: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [01:07<00:00,  1.85it/s]\n",
      "INFO:pipeline_template:[Train] step=4625, loss=2.4450\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['居家拖鞋，舒适又时尚', '复古风，穿出文艺范儿']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_48/index.html\n",
      "INFO:pipeline_template:[Train] Round 48 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 48 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_48\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10059.16 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 49/50 | lines: 1000 @ start 48000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [04:06<00:00,  4.06img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 1809.02match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 171.51it/s]\n",
      "INFO:pipeline_template:[Train] Round 49: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [01:00<00:00,  2.06it/s]\n",
      "INFO:pipeline_template:[Train] step=4750, loss=2.9971\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['简约风卧室，打造舒适睡眠空间', '美甲，让指甲更美丽']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_49/index.html\n",
      "INFO:pipeline_template:[Train] Round 49 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 49 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_49\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10018.70 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] Round 50/50 | lines: 1000 @ start 49000\n",
      "TSV IC_train.tsv: 100%|████████████████████| 1000/1000 [04:09<00:00,  4.01img/s]\n",
      "JSONL IC_train.jsonl: 100%|████████████| 1000/1000 [00:00<00:00, 1737.17match/s]\n",
      "Loading images...: 100%|███████████████████| 1000/1000 [00:05<00:00, 177.96it/s]\n",
      "INFO:pipeline_template:[Train] Round 50: loaded 1000 images -> expanded to 1000 samples\n",
      "INFO:pipeline_template:[Train] Epoch 1/1 on 1000 samples\n",
      "Epoch 1/1: 100%|██████████████████████████████| 125/125 [00:58<00:00,  2.14it/s]\n",
      "INFO:pipeline_template:[Train] step=4875, loss=2.1512\n",
      "Captioning images, with ``generate``: 100%|███████| 1/1 [00:00<00:00,  2.16it/s]\n",
      "INFO:pipeline_template:[Train] Warmup inference (LoRA): ['冬季保暖神器，让你温暖过冬', '花椰菜，营养丰富又美味']\n",
      "INFO:preview_utils:[Train] Warmup preview saved: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/warmup_round_50/index.html\n",
      "INFO:pipeline_template:[Train] Round 50 final sample count: 1000\n",
      "INFO:pipeline_template:[Train] Saved round 50 ckpt to /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora/round_50\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10088.70 MB / total=16376.00 MB\n",
      "INFO:pipeline_template:[Train] LoRA adapter saved to: /mnt/d/forCoding_data/Tianchi_MUGE/trained_models/ECommerce-IC/outputs_v4_lora\n",
      "INFO:pipeline_template:[GPU0] after cleanup used=10146.70 MB / total=16376.00 MB\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python 4_益-基于3_训练时每张图只要少量标注.py --mode train #  --force_retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6921a345-a96c-4b5c-bfc8-60735384024d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6592e8d-4978-4b9f-a63b-1007c04b9db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fdd373-a9a9-4b99-a34a-4c2c23273268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b08407b-ac44-4484-b313-0190653cced7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8787337-9896-4c37-bfcc-97afb2b09cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cae7b0-e4fb-4c05-a6b0-4684d41ca36f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a9ead-7a12-4026-b572-56f29e8c8edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81e1b47-c071-4f7c-84c1-0597b39b00ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be8de11-9181-48d5-90da-a52cbd775031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ba137b-27bf-4474-8534-d118b7d6378c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dde28d-3051-46e6-a83f-926592c19e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50d3b63-926f-4c74-a1c8-89712aca8de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "945ba5a6-270e-401f-bffc-6d20d2072896",
   "metadata": {},
   "source": [
    "遇到困难：\n",
    "* 资源不足。--》分片加载数据并训练，清理缓存。还有一些其他的方法，全都搞清楚，我到底用了啥。下次做任务的时候就可以直接用，不要再让AI想了。\n",
    "* 生成结果的内容不断重复。可能是训练数据里面，一张图对应很多的text，于是让模型觉得也得生成很多条语句导致的。--》考虑只使用其中的一行？或者将这些都拼接起来训练？或者是将数据展开来训练？\n",
    "* 显卡使用率不是特别高。但是搞高了，速度也没有更快。说是可能是瓶颈在cpu这边。\n",
    "* 中间有一次，跑到第7轮的时候断了。后来我感觉改的比较有意义的地方是限定了文本的长度。所以你还是有必要查一下图片和文本的分布情况的。\n",
    "* 还是很有必要保存模型的中间训练结果的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650bd00d-e448-4ffe-ad0e-d135bd72c41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6dcc892-87e9-4839-b0cf-a3038db9b1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n",
      "223\n",
      "229\n",
      "235\n",
      "402\n",
      "495\n",
      "857\n",
      "895\n",
      "952\n",
      "991\n",
      "1054\n"
     ]
    }
   ],
   "source": [
    "# !python extract_branch_logs.py\n",
    "# 45\n",
    "# 128\n",
    "# 133\n",
    "# 136\n",
    "# 161\n",
    "# 167\n",
    "# 197\n",
    "# 207\n",
    "# 210\n",
    "# 358\n",
    "# 402\n",
    "# 412\n",
    "# 428\n",
    "# 444\n",
    "# 446\n",
    "# 449\n",
    "# 454\n",
    "# 456\n",
    "# 495\n",
    "# 745\n",
    "# 802\n",
    "# 213\n",
    "# 223\n",
    "# 229\n",
    "# 235\n",
    "# 402\n",
    "# 495\n",
    "# 857\n",
    "# 895\n",
    "# 952\n",
    "# 991\n",
    "# 1054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d4c7cf-57a9-44f9-a742-b789e35d27b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"img_id\": \"07716e4ca97d54b15b8b7dd54f4690d3\", \"text\": \"尖头高跟鞋，穿出优雅女人味\"}\n",
      "{\"img_id\": \"13288486a5a5470a4c2904e0c12133d3\", \"text\": \"窗帘，让家的温馨更上一层楼\"}\n",
      "{\"img_id\": \"2ee8a75ace450c59d7f9761eff532ff5\", \"text\": \"吊带背心，让你的夏天更加清凉\"}\n",
      "{\"img_id\": \"33f47fe67b9c16e284bbb61454293393\", \"text\": \"高腰短裤，显瘦又时髦\"}\n",
      "{\"img_id\": \"4466dd7d5754cf5edae9c056be2cd1b4\", \"text\": \"复古闹钟，唤醒你的美好时光\"}\n",
      "{\"img_id\": \"497a04c63f4bd0bdfab0ddabe2c92396\", \"text\": \"时尚休闲裤，穿出你的个性魅力\"}\n",
      "{\"img_id\": \"4c0ba9af9fe4483f862b870ba7c6a031\", \"text\": \"毛衣搭配，让你美得与众不同\"}\n",
      "{\"img_id\": \"56ce3778d12f5fa763495323edb58483\", \"text\": \"毛衣，让你的秋冬更加温暖舒适\"}\n",
      "{\"img_id\": \"69191eaae67a4ac3a1a1a321e77267be\", \"text\": \"连衣裙，让你美得与众不同\"}\n",
      "{\"img_id\": \"6d3b7e7cccc23108511c1bc42ee4bdcc\", \"text\": \"优雅半身裙，穿出你的气质美\"}\n"
     ]
    }
   ],
   "source": [
    "!head /mnt/d/forCoding_data/Tianchi_MUGE/originalData/ECommerce-IC/v2.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20ef28d-5362-45e8-a2dd-6ced7095ebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp -r /mnt/d/forCoding_data/Tianchi_MUGE/originalData/ECommerce-IC/outputs_v2_lora/warmup_round_1/ warmup_round_1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4796ba48-7e18-45d9-a5a4-2d2f2949d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data_loader import ICTsvJsonlDataset, load_ic_batch\n",
    "\n",
    "# import os\n",
    "# base_dir = \"/mnt/d/forCoding_data/Tianchi_MUGE/originalData/ECommerce-IC/\"\n",
    "# train_tsv = os.path.join(base_dir, \"IC_train.tsv\")\n",
    "# train_jsonl = os.path.join(base_dir, \"IC_train.jsonl\")\n",
    "# valid_tsv = os.path.join(base_dir, \"IC_valid.tsv\")\n",
    "# valid_jsonl = os.path.join(base_dir, \"IC_valid.jsonl\")\n",
    "# test_tsv = os.path.join(base_dir, \"IC_test.tsv\")\n",
    "# test_jsonl = os.path.join(base_dir, \"IC_test.jsonl\")\n",
    "\n",
    "# ds = load_ic_batch(\n",
    "#     train_tsv,\n",
    "#     train_jsonl,\n",
    "#     start_line=0,\n",
    "#     num_lines=10,\n",
    "#     image_size=224,\n",
    "#     show_progress=True,\n",
    "# )\n",
    "\n",
    "# for xx in ds:\n",
    "#     break\n",
    "# xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e719c9d-dfed-45cf-8cbc-76d94ab8bafc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1daa78-2246-431c-b8ba-a91765f239df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8e7d37-b591-4352-ad4a-6056bbfbe75f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091823b1-33c9-45e2-b54e-a43d0a0eb575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
